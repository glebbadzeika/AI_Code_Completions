[
    {
        "id": 0,
        "filename": "3.txt",
        "prefix": "def visualize_classes(data):\n\n    class_counts = count_classes(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_classes_v2(data):\n\n    class_counts = count_classes_v2(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_sample_images(data):\n    plt.figure(figsize=(24, 12))\n    for images, labels in data.take(1):\n        for i in range(32):\n            plt.subplot(4, 8, i + 1)\n            plt.imshow(np.array(images[i]).astype(\"uint8\"))\n            plt.title(class_names[labels[i]])\n            plt.axis(\"off\")\n\ndef count_classes(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for images, labels in data:\n        for label in labels:\n            class_name = class_names[label]\n            class_counts[class_name] += 1\n\n    return class_counts\n\n",
        "actual_middle": "def count_classes_v2(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for image,",
        "generated_middle": "def count_classes_v2(data):\n\n    class_counts = {class_name",
        "suffix": " label in data:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_in_predicted_labels(y_pred):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for label in y_pred:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 60.958508168944356,
            "bleu_score": 45.94258240359268,
            "rougeL_score": 0.6666666666666666,
            "levenshtein_ratio": 53.271028037383175
        }
    },
    {
        "id": 1,
        "filename": "3.txt",
        "prefix": "def visualize_classes(data):\n\n    class_counts = count_classes(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_classes_v2(data):\n\n    class_counts = count_classes_v2(data)\n\n    plt.figure(figsize=(10",
        "actual_middle": ", 6))\n ",
        "generated_middle": ", 6))\n    plt.bar(class_counts.keys(), class_counts.values",
        "suffix": "   plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_sample_images(data):\n    plt.figure(figsize=(24, 12))\n    for images, labels in data.take(1):\n        for i in range(32):\n            plt.subplot(4, 8, i + 1)\n            plt.imshow(np.array(images[i]).astype(\"uint8\"))\n            plt.title(class_names[labels[i]])\n            plt.axis(\"off\")\n\ndef count_classes(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for images, labels in data:\n        for label in labels:\n            class_name = class_names[label]\n            class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_v2(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for image, label in data:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_in_predicted_labels(y_pred):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for label in y_pred:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 20.840366922001568,
            "bleu_score": 11.369306152454815,
            "rougeL_score": 0.19999999999999998,
            "levenshtein_ratio": 12.06896551724138
        }
    },
    {
        "id": 2,
        "filename": "3.txt",
        "prefix": "def visualize_classes(data):\n\n    class_counts = count_classes(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_classes_v2(data):\n\n    class_counts = count_classes_v2(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_sample_images(data):\n    plt.figure(figsize=(24",
        "actual_middle": ", 1",
        "generated_middle": ", 24))\n    for image, label in tqdm(data, total=len(data",
        "suffix": "2))\n    for images, labels in data.take(1):\n        for i in range(32):\n            plt.subplot(4, 8, i + 1)\n            plt.imshow(np.array(images[i]).astype(\"uint8\"))\n            plt.title(class_names[labels[i]])\n            plt.axis(\"off\")\n\ndef count_classes(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for images, labels in data:\n        for label in labels:\n            class_name = class_names[label]\n            class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_v2(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for image, label in data:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_in_predicted_labels(y_pred):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for label in y_pred:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 4.716981132075472,
            "bleu_score": 2.1476912089159055,
            "rougeL_score": 0.0,
            "levenshtein_ratio": 3.57142857142857
        }
    },
    {
        "id": 3,
        "filename": "3.txt",
        "prefix": "def visualize_classes(data):\n\n    class_counts = count_classes(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_classes_v2(data):\n\n    class_counts = count_classes_v2(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_sample_images(data):\n   ",
        "actual_middle": " plt.figure(figsize=(24, 12))\n    for images, labels in data.take(1):\n        for i ",
        "generated_middle": "image_dimensions = (100, 100)\n    nrow = len(",
        "suffix": "in range(32):\n            plt.subplot(4, 8, i + 1)\n            plt.imshow(np.array(images[i]).astype(\"uint8\"))\n            plt.title(class_names[labels[i]])\n            plt.axis(\"off\")\n\ndef count_classes(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for images, labels in data:\n        for label in labels:\n            class_name = class_names[label]\n            class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_v2(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for image, label in data:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_in_predicted_labels(y_pred):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for label in y_pred:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 11.319946818617776,
            "bleu_score": 2.8578945586315685,
            "rougeL_score": 0.1,
            "levenshtein_ratio": 20.238095238095234
        }
    },
    {
        "id": 4,
        "filename": "3.txt",
        "prefix": "def visualize_classes(data):\n\n    class_counts = count_classes(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_classes_v2(data):\n\n    class_counts = count_classes_v2(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_sample_images(data):\n    plt.figure(figsize=(24, 12))\n    for images, labels in data.take(1):\n        for i in range(32):\n            plt.subplot(4, 8, i + 1)\n            plt.imshow(np.array(images[i]).astype(\"uint8\"))\n           ",
        "actual_middle": " plt.title(class_na",
        "generated_middle": "plt.axis(\"off\")\n\ndef visualize_sample_images_v2(data):",
        "suffix": "mes[labels[i]])\n            plt.axis(\"off\")\n\ndef count_classes(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for images, labels in data:\n        for label in labels:\n            class_name = class_names[label]\n            class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_v2(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for image, label in data:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_in_predicted_labels(y_pred):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for label in y_pred:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 15.944593194672017,
            "bleu_score": 4.553719184146073,
            "rougeL_score": 0.15384615384615383,
            "levenshtein_ratio": 20.370370370370374
        }
    },
    {
        "id": 5,
        "filename": "3.txt",
        "prefix": "def visualize_classes(data):\n\n    class_counts = count_classes(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_classes_v2(data):\n\n    class_counts = count_classes_v2(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n   ",
        "actual_middle": " plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_sample_images(data):\n    plt.figure(figsize=(24, 12))\n    for images, labels i",
        "generated_middle": "plt.xticks(rotation=45)\n    plt.show()\n\n\nimages, labels,",
        "suffix": "n data.take(1):\n        for i in range(32):\n            plt.subplot(4, 8, i + 1)\n            plt.imshow(np.array(images[i]).astype(\"uint8\"))\n            plt.title(class_names[labels[i]])\n            plt.axis(\"off\")\n\ndef count_classes(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for images, labels in data:\n        for label in labels:\n            class_name = class_names[label]\n            class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_v2(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for image, label in data:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_in_predicted_labels(y_pred):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for label in y_pred:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 43.325541376251245,
            "bleu_score": 21.735398839534835,
            "rougeL_score": 0.5714285714285715,
            "levenshtein_ratio": 41.35338345864662
        }
    },
    {
        "id": 6,
        "filename": "2.txt",
        "prefix": "import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder\nfeatures=pd.read_csv(\"features.csv\",index_col=0).to_numpy()\nlabels=pd.read_csv(\"labels.csv\",index_col=0).to_numpy()\n\ntarget_names = [BIOMES.get(int(label), str(label)) for label in labels]\n\n\nX_train, X_test, y_train, y_test = train_test_split(features, target_names, test_size=0.2, random_state=42)\nlabel_encoder = LabelEncoder()\n\n\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\nmodel = xgb.XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_train)))\nmodel.fit(X_train, y_train_encoded)\n\npredictions = model.predict(X_test)\npredictions = label_encoder.inverse_transform(predictions)\nreport = classification_report(y_test, predictions)\nprint(\"Classification Report:\\n\"",
        "actual_middle": ", report)",
        "generated_middle": "report)",
        "suffix": "",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 83.07482317905449,
            "bleu_score": 60.653065971263366,
            "rougeL_score": 1.0,
            "levenshtein_ratio": 77.77777777777779
        }
    },
    {
        "id": 7,
        "filename": "2.txt",
        "prefix": "import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder\nfeatures=pd.read_csv(\"features.csv\",index_col=0).to_numpy()\nlabels=pd.read_csv(\"labels.csv\",index_col=0).to_numpy",
        "actual_middle": "()\n\ntarget_names = [BIOMES.get(int(label), str(label)) for label in labels]\n\n\nX_train, X_test, y_train, y_test = train_test_split(features, targe",
        "generated_middle": "([0]*len(features))\ny_train = labels.astype(int)\nX",
        "suffix": "t_names, test_size=0.2, random_state=42)\nlabel_encoder = LabelEncoder()\n\n\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\nmodel = xgb.XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_train)))\nmodel.fit(X_train, y_train_encoded)\n\npredictions = model.predict(X_test)\npredictions = label_encoder.inverse_transform(predictions)\nreport = classification_report(y_test, predictions)\nprint(\"Classification Report:\\n\", report)",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 17.847363356587458,
            "bleu_score": 3.143096354852737,
            "rougeL_score": 0.11764705882352941,
            "levenshtein_ratio": 18.620689655172416
        }
    },
    {
        "id": 8,
        "filename": "2.txt",
        "prefix": "import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder\nfeatures=pd.read_csv(\"features.csv\",index_col=0).to_numpy()\nlabels=pd.read_csv(\"labels.csv\",index_col=0).to_numpy()\n\ntarget_names = [BIOMES.get(int(label)",
        "actual_middle": ", str(label)) for label in labels]\n\n\nX_train, X_test, y_train, y_test = train_test_split(features, ",
        "generated_middle": "+ 1) for label in",
        "suffix": "target_names, test_size=0.2, random_state=42)\nlabel_encoder = LabelEncoder()\n\n\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\nmodel = xgb.XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_train)))\nmodel.fit(X_train, y_train_encoded)\n\npredictions = model.predict(X_test)\npredictions = label_encoder.inverse_transform(predictions)\nreport = classification_report(y_test, predictions)\nprint(\"Classification Report:\\n\", report)",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 12.433967014461029,
            "bleu_score": 0.404470814299963,
            "rougeL_score": 0.27272727272727276,
            "levenshtein_ratio": 15.151515151515149
        }
    },
    {
        "id": 9,
        "filename": "2.txt",
        "prefix": "import xgboost as xgb\nfrom sklearn.model_selection ",
        "actual_middle": "import ",
        "generated_middle": "import",
        "suffix": "train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder\nfeatures=pd.read_csv(\"features.csv\",index_col=0).to_numpy()\nlabels=pd.read_csv(\"labels.csv\",index_col=0).to_numpy()\n\ntarget_names = [BIOMES.get(int(label), str(label)) for label in labels]\n\n\nX_train, X_test, y_train, y_test = train_test_split(features, target_names, test_size=0.2, random_state=42)\nlabel_encoder = LabelEncoder()\n\n\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\nmodel = xgb.XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_train)))\nmodel.fit(X_train, y_train_encoded)\n\npredictions = model.predict(X_test)\npredictions = label_encoder.inverse_transform(predictions)\nreport = classification_report(y_test, predictions)\nprint(\"Classification Report:\\n\", report)",
        "label": "correct",
        "metrics": {
            "exact_match": 1,
            "chrf_score": 100.0,
            "bleu_score": 100.00000000000004,
            "rougeL_score": 1.0,
            "levenshtein_ratio": 85.71428571428572
        }
    },
    {
        "id": 10,
        "filename": "2.txt",
        "prefix": "import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder\nfeatures=pd.read_csv(\"features.csv\",index_col=0).to_numpy()\nlabels=pd.read_csv(\"labels.csv\",index_col=0).to_numpy()\n\ntarget_names = [BIOMES.get(int(label), str(label)) for label in labels]\n\n\nX_train, X_test, y_train, y_test = train_test_split(features, target_names, test_size=0.2, random_state=42)\nlabel_encoder = LabelEncoder()\n\n\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded ",
        "actual_middle": "= label_encoder.transform(y_t",
        "generated_middle": "= label_encoder.transform(y_t",
        "suffix": "est)\n\nmodel = xgb.XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_train)))\nmodel.fit(X_train, y_train_encoded)\n\npredictions = model.predict(X_test)\npredictions = label_encoder.inverse_transform(predictions)\nreport = classification_report(y_test, predictions)\nprint(\"Classification Report:\\n\", report)",
        "label": "correct",
        "metrics": {
            "exact_match": 1,
            "chrf_score": 100.0,
            "bleu_score": 100.00000000000004,
            "rougeL_score": 1.0,
            "levenshtein_ratio": 100.0
        }
    },
    {
        "id": 11,
        "filename": "2.txt",
        "prefix": "import xgboost as ",
        "actual_middle": "xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfr",
        "generated_middle": "gb\nimport numpy as np\nfr",
        "suffix": "om sklearn.preprocessing import LabelEncoder\nfeatures=pd.read_csv(\"features.csv\",index_col=0).to_numpy()\nlabels=pd.read_csv(\"labels.csv\",index_col=0).to_numpy()\n\ntarget_names = [BIOMES.get(int(label), str(label)) for label in labels]\n\n\nX_train, X_test, y_train, y_test = train_test_split(features, target_names, test_size=0.2, random_state=42)\nlabel_encoder = LabelEncoder()\n\n\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\nmodel = xgb.XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_train)))\nmodel.fit(X_train, y_train_encoded)\n\npredictions = model.predict(X_test)\npredictions = label_encoder.inverse_transform(predictions)\nreport = classification_report(y_test, predictions)\nprint(\"Classification Report:\\n\", report)",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 7.257035358939769,
            "bleu_score": 0.6706844879852473,
            "rougeL_score": 0.18181818181818182,
            "levenshtein_ratio": 19.266055045871553
        }
    },
    {
        "id": 12,
        "filename": "1.txt",
        "prefix": "from flask import Flask, render_template\nfrom dotenv import find_dotenv, load_dotenv\nfrom telethon import TelegramClient\nfrom telethon.tl.types import (\n    MessageMediaPhoto,\n    MessageMediaDocument,\n    MessageMediaWebPage,\n    WebPageEmpty,\n    WebPage\n)\n\nimport os\nimport asyncio\nimport threading\nimport traceback\nimport json\n\n# Initialize the Flask app in the global scope\napp = Flask(__name__)\n\n\nclass ChannelViewer:\n    def __init__(self):\n        self.channel_username = 'onlinerby'  # Replace with the target channel's username\n        self.messages = []\n        self.messages_lock = threading.Lock()\n        self.load_environment_variables()\n\n        # Store API credentials\n        self.api_id = os.getenv('API_ID')\n        self.api_hash = os.getenv('API_HASH')\n\n        # Initialize variables\n        self.last_message_id = 0  # To keep track of the last processed message ID\n\n        # Load existing messages from file\n        self.load_messages()\n\n        # Start the background thread\n        self.start_fetching_messages()\n\n    def load_environment_variables(self):\n        \"\"\"\n        Load environment variables from a .env file.\n        \"\"\"\n        try:\n            dotenv_path = find_dotenv()\n            if not dotenv_path:\n                raise FileNotFoundError(\".env file not found\")\n            load_dotenv(dotenv_path)\n            print(f\"Environment variables loaded from {dotenv_path}\")\n        except Exception as e:\n            print(f\"Error loading .env file: {e}\")\n            raise\n\n    def load_messages(self):\n        \"\"\"\n        Load messages from 'messages.json' if it exists.\n        \"\"\"\n        try:\n            with open('messages.json', 'r', encoding='utf-8') as f:\n                self.messages = json.load(f)\n            if self.messages:\n                # Update last_message_id with the highest message ID\n                self.last_message_id = max(msg['id'] for msg in self.messages)\n            print(f\"Loaded {len(self.messages)} messages from messages.json.\")\n        except FileNotFoundError:\n            print(\"messages.json not found. Starting with an empty message list.\")\n        except Exception as e:\n            print(f\"Error loading messages: {e}\")\n\n    def save_messages(self):\n        \"\"\"\n        Save messages to 'messages.json'.\n        \"\"\"\n        try:\n            with open('messages.json', 'w', encoding='utf-8') as f:\n                json.dump(self.messages, f, ensure_ascii=False, indent=4)\n            print(f\"Saved {len(self.messages)} messages to messages.json.\")\n        except Exception as e:\n            print(f\"Error saving messages: {e}\")\n\n    def start_fetching_messages(self):\n        print('Starting background thread to fetch messages.')\n        fetch_thread = threading.Thread(target=self.fetch_messages)\n        fetch_thread.daemon = True  # Daemonize thread to exit when main program exits\n        fetch_thread.start()\n        print('Background thread started.')\n\n    def fetch_messages(self):\n        print('fetch_messages: Started fetching messages.')\n        # Set up a new event loop for this thread\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n\n        async def main():\n            try:\n                print('fetch_messages: Starting main function.')\n\n                # Initialize the Telegram client in this thread's event loop\n                self.client = TelegramClient('session_name', self.api_id, self.api_hash, loop=loop)\n\n                # Start the client (connect and authenticate)\n                await self.client.start()\n                print('Telegram client started in background thread.')\n\n                # Initialize variables\n                offset_id = 0  # Start from the latest message\n                limit = 50  # Number of messages to fetch in each batch\n\n                while True:\n                    print('Fetching new messages...')\n                    new_messages = []\n                    media_groups = {}\n\n                    # Fetch messages in batches\n                    messages = await self.client.get_messages(\n                        self.channel_username,\n                        limit=limit,\n                        offset_id=offset_id\n                    )\n\n                    if not messages:\n                        print('No new messages found.')\n                        await asyncio.sleep(5)  # Wait before checking again\n                        continue\n\n                    for message in reversed(messages):  # Process from oldest to newest\n                        print(f'Processing message ID {message.id}')\n                        message_data = {\n                            'id': message.id,\n                            'text': message.text or '',\n                            'date': message.date.strftime('%Y-%m-%d %H:%M:%S'),\n                            'sender': message.sender_id,\n                            'media': [],\n                            'media_type': None,\n                            'grouped_id': message.grouped_id,\n                        }\n\n                        # Check if the message has media\n                        if message.media:\n                            print(f'Message ID {message.id} has media.')\n                            # Ensure the directory exists\n                            ",
        "actual_middle": "media_dir = 'static/media/'\n                            os.mak",
        "generated_middle": "os.mkdir(os.path.dirname(file_path))\n                                loop = asyncio.new",
        "suffix": "edirs(media_dir, exist_ok=True)\n\n                            # Initialize variables\n                            media_filename = None\n                            media_item = {}\n\n                            # Handle different media types\n                            if isinstance(message.media, MessageMediaPhoto):\n                                # For photos\n                                file_extension = '.jpg'\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded photo for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Photo for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'photo',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaDocument):\n                                # For documents (including videos, audio, etc.)\n                                file_extension = self.get_media_extension(message)\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded document for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Document for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'document',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaWebPage):\n                                # Handle web page previews\n                                print(f'Message ID {message.id} contains a web page preview.')\n                                webpage = message.media.webpage\n\n                                if isinstance(webpage, WebPage):\n                                    # Full web page preview\n                                    message_data['webpage'] = {\n                                        'url': webpage.url,\n                                        'title': getattr(webpage, 'title', ''),\n                                        'description': getattr(webpage, 'description', '')\n                                    }\n                                    print(\n                                        f\"Extracted webpage info for message ID {message.id}: {message_data['webpage']}\")\n                                elif isinstance(webpage, WebPageEmpty):\n                                    # Empty web page preview\n                                    print(f'Message ID {message.id} contains an empty web page preview.')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n                                else:\n                                    # Other web page types\n                                    print(\n                                        f'Message ID {message.id} contains an unsupported web page type: {type(webpage)}')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n\n                                # Add to new_messages and skip further processing\n                                new_messages.append(message_data)\n                                continue  # Skip to next message\n\n                            else:\n                                # Unsupported media type\n                                print(f'Message ID {message.id} has unsupported media type: {type(message.media)}')\n                                continue  # Skip this message\n\n                            # Update message data\n                            if media_item:\n                                message_data['media'].append(media_item)\n                                message_data['media_type'] = media_item['media_type']\n\n                        # Group messages by grouped_id if they are part of a media group\n                        if message.grouped_id:\n                            print(f'Message ID {message.id} is part of group {message.grouped_id}')\n                            if message.grouped_id not in media_groups:\n                                # First message in the group; store the text (caption) if available\n                                media_groups[message.grouped_id] = message_data\n                            else:\n                                # Append media to existing group\n                                existing_message = media_groups[message.grouped_id]\n                                existing_message['media'].extend(message_data['media'])\n                                # If the existing message doesn't have text, and current message has text, update it\n                                if not existing_message['text'] and message_data['text']:\n                                    existing_message['text'] = message_data['text']\n                                    print(\n                                        f'Updated text for media group {message.grouped_id}: \"{message_data[\"text\"]}\"')\n                        else:\n                            # Not part of a media group, add as individual message\n                            new_messages.append(message_data)\n\n                        # Update last_message_id\n                        if message.id > self.last_message_id:\n                            self.last_message_id = message.id\n\n                        # Update offset_id for the next batch\n                        offset_id = message.id\n\n                    # Add grouped messages to new_messages\n                    new_messages.extend(media_groups.values())\n\n                    # Sort messages by date (optional)\n                    new_messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    # Update the shared messages list\n                    with self.messages_lock:\n                        self.messages.extend(new_messages)\n                        # Remove duplicates based on message ID\n                        self.messages = list({msg['id']: msg for msg in self.messages}.values())\n                        # Sort messages after merging\n                        self.messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    print(f'Fetched and processed {len(new_messages)} new messages.')\n\n                    # Save messages to file\n                    self.save_messages()\n\n                    # Yield control to the event loop\n                    await asyncio.sleep(1)  # Adjust sleep time as needed\n\n            except Exception as e:\n                print(f'An error occurred in fetch_messages: {e}')\n                traceback.print_exc()\n\n        # Run the async function in the event loop\n        try:\n            loop.run_until_complete(main())\n        finally:\n            # Properly disconnect the client\n            self.client.disconnect()\n            loop.close()\n\n    def get_media_extension(self, message):\n        \"\"\"\n        Get the file extension for the media.\n        \"\"\"\n        if message.photo:\n            return '.jpg'\n        elif message.video:\n            return '.mp4'\n        elif message.document:\n            # Get the extension from the mime type or file name\n            mime_type = message.document.mime_type\n            if mime_type == 'image/jpeg':\n                return '.jpg'\n            elif mime_type == 'image/png':\n                return '.png'\n            elif mime_type == 'video/mp4':\n                return '.mp4'\n            else:\n                # Extract extension from file name\n                if message.file and message.file.name:\n                    return os.path.splitext(message.file.name)[1]\n                else:\n                    return ''\n        else:\n            return ''\n\n    def get_channel_messages(self):\n        with self.messages_lock:\n            return self.messages.copy()\n\n\n# Instantiate the ChannelViewer class\nviewer = ChannelViewer()\n\n\n@app.route('/')\ndef index():\n    print('Received request for /')\n    messages = viewer.get_channel_messages()\n    print(f\"Number of messages to display: {len(messages)}\")\n    return render_template('index.html', messages=messages)\n\n\nif __name__ == '__main__':\n    app.run(debug=True, use_reloader=False)",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 17.75979909883506,
            "bleu_score": 4.553719184146073,
            "rougeL_score": 0.125,
            "levenshtein_ratio": 45.97701149425287
        }
    },
    {
        "id": 13,
        "filename": "1.txt",
        "prefix": "from flask import Flask, render_template\nfrom dotenv import find_dotenv, load_dotenv\nfrom telethon import TelegramClient\nfrom telethon.tl.types import (\n    MessageMediaPhoto,\n    MessageMediaDocument,\n    MessageMediaWebPage,\n    WebPageEmpty,\n    WebPage\n)\n\nimport os\nimport asyncio\nimport threading\nimport traceback\nimport json\n\n# Initialize the Flask app in the global scope\napp = Flask(__name__)\n\n\nclass ChannelViewer:\n    def __init__(self):\n        self.channel_username = 'onlinerby'  # Replace with the target channel's username\n        self.messages = []\n        self.messages_lock = threading.Lock()\n        self.load_environment_variables()\n\n        # Store API credentials\n        self.api_id = os.getenv('API_ID')\n        self.api_hash = os.getenv('API_HASH')\n\n        # Initialize variables\n        self.last_message_id = 0  # To keep track of the last processed message ID\n\n        # Load existing messages from file\n        self.load_messages()\n\n        # Start the background thread\n        self.start_fetching_messages()\n\n    def load_environment_variables(self):\n        \"\"\"\n        Load environment variables from a .env file.\n        \"\"\"\n        try:\n            dotenv_path = find_dotenv()\n            if not dotenv_path:\n                raise FileNotFoundError(\".env file not found\")\n            load_dotenv(dotenv_path)\n            print(f\"Environment variables loaded from {dotenv_path}\")\n        except Exception as e:\n            print(f\"Error loading .env file: {e}\")\n            raise\n\n    def load_messages(self):\n        \"\"\"\n        Load messages from 'messages.json' if it exists.\n        \"\"\"\n        try:\n            with open('messages.json', 'r', encoding='utf-8') as f:\n                self.messages = json.load(f)\n            if self.messages:\n                # Update last_message_id with the highest message ID\n                self.last_message_id = max(msg['id'] for msg in self.messages)\n            print(f\"Loaded {len(self.messages)} messages from messages.json.\")\n        except FileNotFoundError:\n            print(\"messages.json not found. Starting with an empty message list.\")\n        except Exception as e:\n            print(f\"Error loading messages: {e}\")\n\n    def save_messages(self):\n        \"\"\"\n        Save messages to 'messages.json'.\n        \"\"\"\n        try:\n            with open('messages.json', 'w', encoding='utf-8') as f:\n                json.dump(self.messages, f, ensure_ascii=False, indent=4)\n            print(f\"Saved {len(self.messages)} messages to messages.json.\")\n        except Exception as e:\n            print(f\"Error saving messages: {e}\")\n\n    def start_fetching_messages(self):\n        print('Starting background thread to fetch messages.')\n        fetch_thread = threading.Thread(target=self.fetch_messages)\n        fetch_thread.daemon = True  # Daemonize thread to exit when main program exits\n        fetch_thread.start()\n        print('Background thread started.')\n\n    def fetch_messages(self):\n        print('fetch_messages: Started fetching messages.')\n        # Set up a new event loop for this thread\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n\n        async def main():\n            try:\n                print('fetch_messages: Starting main function.')\n\n                # Initialize the Telegram client in this thread's event loop\n                self.client = TelegramClient('session_name', self.api_id, self.api_hash, loop=loop)\n\n                # Start the client (connect and authenticate)\n                await self.client.start()\n                print('Telegram client started in background thread.')\n\n                # Initialize variables\n             ",
        "actual_middle": "   offset_id = 0  # Start from the latest message\n                limit = 50  # Number of messages to fetch in each batch\n\n                while Tru",
        "generated_middle": "self.last_message_id = 0  # To keep track of the last processed",
        "suffix": "e:\n                    print('Fetching new messages...')\n                    new_messages = []\n                    media_groups = {}\n\n                    # Fetch messages in batches\n                    messages = await self.client.get_messages(\n                        self.channel_username,\n                        limit=limit,\n                        offset_id=offset_id\n                    )\n\n                    if not messages:\n                        print('No new messages found.')\n                        await asyncio.sleep(5)  # Wait before checking again\n                        continue\n\n                    for message in reversed(messages):  # Process from oldest to newest\n                        print(f'Processing message ID {message.id}')\n                        message_data = {\n                            'id': message.id,\n                            'text': message.text or '',\n                            'date': message.date.strftime('%Y-%m-%d %H:%M:%S'),\n                            'sender': message.sender_id,\n                            'media': [],\n                            'media_type': None,\n                            'grouped_id': message.grouped_id,\n                        }\n\n                        # Check if the message has media\n                        if message.media:\n                            print(f'Message ID {message.id} has media.')\n                            # Ensure the directory exists\n                            media_dir = 'static/media/'\n                            os.makedirs(media_dir, exist_ok=True)\n\n                            # Initialize variables\n                            media_filename = None\n                            media_item = {}\n\n                            # Handle different media types\n                            if isinstance(message.media, MessageMediaPhoto):\n                                # For photos\n                                file_extension = '.jpg'\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded photo for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Photo for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'photo',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaDocument):\n                                # For documents (including videos, audio, etc.)\n                                file_extension = self.get_media_extension(message)\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded document for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Document for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'document',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaWebPage):\n                                # Handle web page previews\n                                print(f'Message ID {message.id} contains a web page preview.')\n                                webpage = message.media.webpage\n\n                                if isinstance(webpage, WebPage):\n                                    # Full web page preview\n                                    message_data['webpage'] = {\n                                        'url': webpage.url,\n                                        'title': getattr(webpage, 'title', ''),\n                                        'description': getattr(webpage, 'description', '')\n                                    }\n                                    print(\n                                        f\"Extracted webpage info for message ID {message.id}: {message_data['webpage']}\")\n                                elif isinstance(webpage, WebPageEmpty):\n                                    # Empty web page preview\n                                    print(f'Message ID {message.id} contains an empty web page preview.')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n                                else:\n                                    # Other web page types\n                                    print(\n                                        f'Message ID {message.id} contains an unsupported web page type: {type(webpage)}')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n\n                                # Add to new_messages and skip further processing\n                                new_messages.append(message_data)\n                                continue  # Skip to next message\n\n                            else:\n                                # Unsupported media type\n                                print(f'Message ID {message.id} has unsupported media type: {type(message.media)}')\n                                continue  # Skip this message\n\n                            # Update message data\n                            if media_item:\n                                message_data['media'].append(media_item)\n                                message_data['media_type'] = media_item['media_type']\n\n                        # Group messages by grouped_id if they are part of a media group\n                        if message.grouped_id:\n                            print(f'Message ID {message.id} is part of group {message.grouped_id}')\n                            if message.grouped_id not in media_groups:\n                                # First message in the group; store the text (caption) if available\n                                media_groups[message.grouped_id] = message_data\n                            else:\n                                # Append media to existing group\n                                existing_message = media_groups[message.grouped_id]\n                                existing_message['media'].extend(message_data['media'])\n                                # If the existing message doesn't have text, and current message has text, update it\n                                if not existing_message['text'] and message_data['text']:\n                                    existing_message['text'] = message_data['text']\n                                    print(\n                                        f'Updated text for media group {message.grouped_id}: \"{message_data[\"text\"]}\"')\n                        else:\n                            # Not part of a media group, add as individual message\n                            new_messages.append(message_data)\n\n                        # Update last_message_id\n                        if message.id > self.last_message_id:\n                            self.last_message_id = message.id\n\n                        # Update offset_id for the next batch\n                        offset_id = message.id\n\n                    # Add grouped messages to new_messages\n                    new_messages.extend(media_groups.values())\n\n                    # Sort messages by date (optional)\n                    new_messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    # Update the shared messages list\n                    with self.messages_lock:\n                        self.messages.extend(new_messages)\n                        # Remove duplicates based on message ID\n                        self.messages = list({msg['id']: msg for msg in self.messages}.values())\n                        # Sort messages after merging\n                        self.messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    print(f'Fetched and processed {len(new_messages)} new messages.')\n\n                    # Save messages to file\n                    self.save_messages()\n\n                    # Yield control to the event loop\n                    await asyncio.sleep(1)  # Adjust sleep time as needed\n\n            except Exception as e:\n                print(f'An error occurred in fetch_messages: {e}')\n                traceback.print_exc()\n\n        # Run the async function in the event loop\n        try:\n            loop.run_until_complete(main())\n        finally:\n            # Properly disconnect the client\n            self.client.disconnect()\n            loop.close()\n\n    def get_media_extension(self, message):\n        \"\"\"\n        Get the file extension for the media.\n        \"\"\"\n        if message.photo:\n            return '.jpg'\n        elif message.video:\n            return '.mp4'\n        elif message.document:\n            # Get the extension from the mime type or file name\n            mime_type = message.document.mime_type\n            if mime_type == 'image/jpeg':\n                return '.jpg'\n            elif mime_type == 'image/png':\n                return '.png'\n            elif mime_type == 'video/mp4':\n                return '.mp4'\n            else:\n                # Extract extension from file name\n                if message.file and message.file.name:\n                    return os.path.splitext(message.file.name)[1]\n                else:\n                    return ''\n        else:\n            return ''\n\n    def get_channel_messages(self):\n        with self.messages_lock:\n            return self.messages.copy()\n\n\n# Instantiate the ChannelViewer class\nviewer = ChannelViewer()\n\n\n@app.route('/')\ndef index():\n    print('Received request for /')\n    messages = viewer.get_channel_messages()\n    print(f\"Number of messages to display: {len(messages)}\")\n    return render_template('index.html', messages=messages)\n\n\nif __name__ == '__main__':\n    app.run(debug=True, use_reloader=False)",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 21.14319882226431,
            "bleu_score": 15.040226743634095,
            "rougeL_score": 0.18749999999999997,
            "levenshtein_ratio": 25.0
        }
    },
    {
        "id": 14,
        "filename": "1.txt",
        "prefix": "from flask import Flask, render_template\nfrom dotenv import find_dotenv, load_dotenv\nfrom telethon import TelegramClient\nfrom telethon.tl.types import (\n    MessageMediaPhoto,\n    MessageMediaDocument,\n    MessageMediaWebPage,\n    WebPageEmpty,\n    WebPage\n)\n\nimport os\nimport asyncio\nimport threading\nimport traceback\nimport json\n\n# Initialize the Flask app in the global scope\napp = Flask(__name__)\n\n\nclass ChannelViewer:\n    def __init__(self):\n        self.channel_username = 'onlinerby'  # Replace with the target channel's username\n        self.messages = []\n        self.messages_lock = threading.Lock()\n        self.load_environment_variables()\n\n        # Store API credentials\n        self.api_id = os.getenv('API_ID')\n        self.api_hash = os.getenv('API_HASH')\n\n        # Initialize variables\n        self.last_message_id = 0  # To keep track of the last processed message ID\n\n        # Load existing messages from file\n        self.load_messages()\n\n        # Start the background thread\n        self.start_fetching_messages()\n\n    def load_environment_variables(self):\n        \"\"\"\n        Load environment variables from a .env file.\n        \"\"\"\n        try:\n            dotenv_path = find_dotenv()\n            if not dotenv_path:\n                raise FileNotFoundError(\".env file not found\")\n            load_dotenv(dotenv_path)\n            print(f\"Environment variables loaded from {dotenv_path}\")\n        except Exception as e:\n            print(f\"Error loading .env file: {e}\")\n            raise\n\n    def load_messages(self):\n        \"\"\"\n        Load messages from 'messages.json' if it exists.\n        \"\"\"\n        try:\n            with open('messages.json', 'r', encoding='utf-8') as f:\n                self.messages = json.load(f)\n            if self.messages:\n                # Update last_message_id with the highest message ID\n                self.last_message_id = max(msg['id'] for msg in self.messages)\n            print(f\"Loaded {len(self.messages)} messages from messages.json.\")\n        except FileNotFoundError:\n            print(\"messages.json not found. Starting with an empty message list.\")\n        except Exception as e:\n            print(f\"Error loading messages: {e}\")\n\n    def save_messages(self):\n        \"\"\"\n        Save messages to 'messages.json'.\n        \"\"\"\n        try:\n            with open('messages.json', 'w', encoding='utf-8') as f:\n                json.dump(self.messages, f, ensure_ascii=False, indent=4)\n            print(f\"Saved {len(self.messages)} messages to messages.json.\")\n        except Exception as e:\n            print(f\"Error saving messages: {e}\")\n\n    def start_fetching_messages(self):\n        print('Starting background thread to fetch messages.')\n        fetch_thread = threading.Thread(target=self.fetch_messages)\n        fetch_thread.daemon = True  # Daemonize thread to exit when main program exits\n        fetch_thread.start()\n        print('Background thread started.')\n\n    def fetch_messages(self):\n        print('fetch_messages: Started fetching messages.')\n        # Set up a new event loop for this thread\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n\n        async def main():\n            try:\n                print('fetch_messages: Starting main function.')\n\n                # Initialize the Telegram client in this thread's event loop\n                self.client = TelegramClient('session_name', self.api_id, self.api_hash, loop=loop)\n\n                # Start the client (connect and authenticate)\n                await self.client.start()\n                print('Telegram client started in background thread.')\n\n                # Initialize variables\n                offset_id = 0  # Start from the latest message\n                limit = 50  # Number of messages to fetch in each batch\n\n                while True:\n                    print('Fetching new messages...')\n                    new_messages = []\n                    media_groups = {}\n\n                    # Fetch messages in batches\n                    messages = await self.client.get_messages(\n                        self.channel_username,\n                        limit=limit,\n                        offset_id=offset_id\n                    )\n\n                    if not messages:\n                        print('No new messages found.')\n                        await asyncio.sleep(5)  # Wait before checking again\n                        continue\n\n                    for message in reversed(messages):  # Process from oldest to newest\n                        print(f'Processing message ID {message.id}')\n                        message_data = {\n                            'id': message.id,\n                            'text': message.text or '',\n                            'date': message.date.strftime('%Y-%m-%d %H:%M:%S'),\n                            'sender': message.sender_id,\n                            'media': [],\n                            'media_type': None,\n                            'grouped_id': message.grouped_id,\n                        }\n\n                        # Check if the message has media\n                        if message.media:\n                            print(f'Message ID {message.id} has media.')\n                            # Ensure the directory exists\n                            media_dir = 'static/media/'\n                            os.makedirs(media_dir, exist_ok=True)\n\n                            # Initialize variables\n                            media_filename = None\n                            media_item = {}\n\n                            # Handle different media types\n                            if isinstance(message.media, MessageMediaPhoto):\n                                # For photos\n                                file_extension = '.jpg'\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded photo for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Photo for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'photo',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaDocument):\n                                # For documents (including videos, audio, etc.)\n                                file_extension = self.get_media_extension(message)\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded document for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Document for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'document',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaWebPage):\n                                # Handle web page previews\n                                print(f'Message ID {message.id} contains a web page preview.')\n                                webpage = message.media.webpage\n\n                                if isinstance(webpage, WebPage):\n                                    # Full web page preview\n                                    message_data['webpage'] = {\n                                        'url': webpage.url,\n                                        'title': getattr(webpage, 'title', ''),\n                                        'description': getattr(webpage, 'description', '')\n                                    }\n                                    print(\n                                        f\"Extracted webpage info for message ID {message.id}: {message_data['webpage']}\")\n                                elif isinstance(webpage, WebPageEmpty):\n                                    # Empty web page preview\n                                    print(f'Message ID {message.id} contains an empty web page preview.')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n                                else:\n                                    # Other web page types\n                                    print(\n                                        f'Message ID {message.id} contains an unsupported web page type: {type(webpage)}')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n\n                                # Add to new_messages and skip further processing\n                                new_messages.append(message_data)\n                                continue  # Skip to next message\n\n                            else:\n                                # Unsupported media type\n                                print(f'Message ID {message.id} has unsupported media type: {type(message.media)}')\n                                continue  # Skip this message\n\n                            # Update message data\n                            if media_item:\n                                message_data['media'].append(media_item)\n                                message_data['media_type'] = media_item['media_type']\n\n                        # Group messages by grouped_id if they are part of a media group\n                        if message.grouped_id:\n                            print(f'Message ID {message.id} is part of group {message.grouped_id}')\n                            if message.grouped_id not in media_groups:\n                                # First message in the group; store the text (caption) if available\n                                media_groups[message.grouped_id] = message_data\n                            else:\n                                # Append media to existing group\n                                existing_message = media_groups[message.grouped_id]\n                                existing_message['media'].extend(message_data['media'])\n                                # If the existing message doesn't have text, and current message has text, update it\n                                if not existing_message['text'] and message_data['text']:\n                                    existing_message['text'] = message_data['text']\n                                    print(\n                                        f'Updated text for media group {message.grouped_id}: \"{message_data[\"text\"]}\"')\n                        else:\n                            # Not part of a media group, add as individual message\n                            new_messages.append(message_data)\n\n                        # Update last_message_id\n                        if message.id > self.last_message_id:\n                            self.last_message_id = message.id\n\n                        # Update offset_id for the next batch\n                        offset_id = message.id\n\n                    # Add grouped messages to new_messages\n                    new_messages.extend(media_groups.values())\n\n                    # Sort messages by date (optional)\n                    new_messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    # Update the shared messages list\n                    with self.messages_lock:\n                        self.messages.extend(new_messages)\n                        # Remove duplicates based on message ID\n                        self.messages = list({msg['id']: msg for msg in self.messages}.values())\n                        # Sort messages after merging\n                        self.messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    print(f'Fetched and processed {len(new_messages)} new messages.')\n\n                    # Save messages to file\n                    self.save_messages()\n\n                    # Yield control to the event loop\n                    await asyncio.sleep(1)  # Adjust sleep time as needed\n\n            except Exception as e:\n                print(f'An error occurred in fetch_messages: {e}')\n                traceback.print_exc()\n\n        # Run the async function in the event loop\n        try:\n            loop.run_until_complete(main())\n        finally:\n            # Properly disconnect the client\n            self.client.disconnect()\n            loop.close()\n\n    def get_media_extension(self, message):\n        \"\"\"\n        Get the file extension for the media.\n        \"\"\"\n        if message.photo:\n            return '.jpg'\n        elif message.video:\n            return '.mp4'\n        elif message.document:\n            # Get the extension from the mime type or file name\n            mime_type = message.document.mime_type\n            if mime_type == 'image/jpeg':\n                return '.jpg'\n            elif mime_type == 'image/png':\n                return '.png'\n            elif mime_type == 'video/mp4':\n                return '.mp4'\n            else:\n                # Extract extension from file name\n                if message.file and message.file.name:\n                    return os.path.splitext(message.file.name)[1]\n                else:\n                    return ''\n        else:\n            return ''\n\n    def get_channel_messages(self",
        "actual_middle": "):\n        with self.messages_lock:\n            return self.messages.copy()\n\n\n# Instantiate the ChannelViewer class\nvie",
        "generated_middle": "):\n        \"\"\"\n        Get the latest messages from the channel.\n        \"\"\"\n        return self.messages[:",
        "suffix": "wer = ChannelViewer()\n\n\n@app.route('/')\ndef index():\n    print('Received request for /')\n    messages = viewer.get_channel_messages()\n    print(f\"Number of messages to display: {len(messages)}\")\n    return render_template('index.html', messages=messages)\n\n\nif __name__ == '__main__':\n    app.run(debug=True, use_reloader=False)",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 38.70452840873428,
            "bleu_score": 13.9612866954986,
            "rougeL_score": 0.34782608695652173,
            "levenshtein_ratio": 24.369747899159666
        }
    },
    {
        "id": 15,
        "filename": "1.txt",
        "prefix": "from flask import Flask, render_template\nfrom dotenv import find_dotenv, load_dotenv\nfrom telethon import TelegramClient\nfrom telethon.tl.types import (\n    MessageMediaPhoto,\n    MessageMediaDocument,\n    MessageMediaWebPage,\n    WebPageEmpty,\n    WebPage\n)\n\nimport os\nimport asyncio\nimport threading\nimport traceback\nimport json\n\n# Initialize the Flask app in the global scope\napp = Flask(__name__)\n\n\nclass ChannelViewer:\n    def __init__(self):\n        self.channel_username = 'onlinerby'  # Replace with the target channel's username\n        self.messages = []\n        self.messages_lock = threading.Lock()\n        self.load_environment_variables()\n\n        # Store API credentials\n        self.api_id = os.getenv('API_ID')\n        self.api_hash = os.getenv('API_HASH')\n\n        # Initialize variables\n        self.last_message_id = 0  # To keep track of the last processed message ID\n\n        # Load existing messages from file\n        self.load_messages()\n\n        # Start the background thread\n        self.start_fetching_messages()\n\n    def load_environment_variables(self):\n        \"\"\"\n        Load environment variables from a .env file.\n        \"\"\"\n        try:\n            dotenv_path = find_dotenv()\n            if not dotenv_path:\n                raise FileNotFoundError(\".env file not found\")\n            load_dotenv(dotenv_path)\n            print(f\"Environment variables loaded from {dotenv_path}\")\n        except Exception as e:\n            print(f\"Error loading .env file: {e}\")\n            raise\n\n    def load_messages(self):\n        \"\"\"\n        Load messages from 'messages.json' if it exists.\n        \"\"\"\n        try:\n            with open('messages.json', 'r', encoding='utf-8') as f:\n                self.messages = json.load(f)\n            if self.messages:\n                # Update last_message_id with the highest message ID\n                self.last_message_id = max(msg['id'] for msg in self.messages)\n            print(f\"Loaded {len(self.messages)} messages from messages.json.\")\n        except FileNotFoundError:\n            print(\"messages.json not found. Starting with an empty message list.\")\n        except Exception as e:\n            print(f\"Error loading messages: {e}\")\n\n    def save_messages(self):\n        \"\"\"\n        Save messages to 'messages.json'.\n        \"\"\"\n        try:\n            with open('messages.json', 'w', encoding='utf-8') as f:\n                json.dump(self.messages, f, ensure_ascii=False, indent=4)\n            print(f\"Saved {len(self.messages)} messages to messages.json.\")\n        except Exception as e:\n            print(f\"Error saving messages: {e}\")\n\n    def start_fetching_messages(self):\n        print('Starting background thread to fetch messages.')\n        fetch_thread = threading.Thread(target=self.fetch_messages)\n        fetch_thread.daemon = True  # Daemonize thread to exit when main program exits\n        fetch_thread.start()\n        print('Background thread started.')\n\n    def fetch_messages(self):\n        print('fetch_messages: Started fetching messages.')\n        # Set up a new event loop for this thread\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n\n        async def main():\n            try:\n                print('fetch_messages: Starting main function.')\n\n                # Initialize the Telegram client in this thread's event loop\n                self.client = TelegramClient('session_name', self.api_id, self.api_hash, loop=loop)\n\n                # Start the client (connect and authenticate)\n                await self.client.start()\n                print('Telegram client started in background thread.')\n\n                # Initialize variables\n                offset_id = 0  # Start from the latest message\n                limit = 50  # Number of messages to fetch in each batch\n\n                while True:\n                    print('Fetching new messages...')\n                    new_messages = []\n                    media_groups = {}\n\n                    # Fetch messages in batches\n                    messages = await self.client.get_messages(\n                        self.channel_username,\n                        limit=limit,\n                        offset_id=offset_id\n                    )\n\n                    if not messages:\n                        print('No new messages found.')\n                        await asyncio.sleep(5)  # Wait before checking again\n                        continue\n\n                    for message in reversed(messages):  # Process from oldest to newest\n                        print(f'Processing message ID {message.id}')\n                        message_data = {\n                            'id': message.id,\n                            'text': message.text or '',\n                            'date': message.date.strftime('%Y-%m-%d %H:%M:%S'),\n                            'sender': message.sender_id,\n                            'media': [],\n                            'media_type': None,\n                            'grouped_id': message.grouped_id,\n                        }\n\n                        # Check if the message has media\n                        if message.media:\n                            print(f'Message ID {message.id} has media.')\n                            # Ensure the directory exists\n                            media_dir = 'static/media/'\n                            os.makedirs(media_dir, exist_ok=True)\n\n                            # Initialize variables\n                            media_filename = None\n                            media_item = {}\n\n                            # Handle different media types\n                            if isinstance(message.media, MessageMediaPhoto):\n                                # For photos\n                                file_extension = '.jpg'\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                      ",
        "actual_middle": "          if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n            ",
        "generated_middle": "# Get media\n                                if message.media.file_extension!= file_extension:\n                                    print",
        "suffix": "                        print(f'Downloaded photo for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Photo for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'photo',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaDocument):\n                                # For documents (including videos, audio, etc.)\n                                file_extension = self.get_media_extension(message)\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded document for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Document for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'document',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaWebPage):\n                                # Handle web page previews\n                                print(f'Message ID {message.id} contains a web page preview.')\n                                webpage = message.media.webpage\n\n                                if isinstance(webpage, WebPage):\n                                    # Full web page preview\n                                    message_data['webpage'] = {\n                                        'url': webpage.url,\n                                        'title': getattr(webpage, 'title', ''),\n                                        'description': getattr(webpage, 'description', '')\n                                    }\n                                    print(\n                                        f\"Extracted webpage info for message ID {message.id}: {message_data['webpage']}\")\n                                elif isinstance(webpage, WebPageEmpty):\n                                    # Empty web page preview\n                                    print(f'Message ID {message.id} contains an empty web page preview.')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n                                else:\n                                    # Other web page types\n                                    print(\n                                        f'Message ID {message.id} contains an unsupported web page type: {type(webpage)}')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n\n                                # Add to new_messages and skip further processing\n                                new_messages.append(message_data)\n                                continue  # Skip to next message\n\n                            else:\n                                # Unsupported media type\n                                print(f'Message ID {message.id} has unsupported media type: {type(message.media)}')\n                                continue  # Skip this message\n\n                            # Update message data\n                            if media_item:\n                                message_data['media'].append(media_item)\n                                message_data['media_type'] = media_item['media_type']\n\n                        # Group messages by grouped_id if they are part of a media group\n                        if message.grouped_id:\n                            print(f'Message ID {message.id} is part of group {message.grouped_id}')\n                            if message.grouped_id not in media_groups:\n                                # First message in the group; store the text (caption) if available\n                                media_groups[message.grouped_id] = message_data\n                            else:\n                                # Append media to existing group\n                                existing_message = media_groups[message.grouped_id]\n                                existing_message['media'].extend(message_data['media'])\n                                # If the existing message doesn't have text, and current message has text, update it\n                                if not existing_message['text'] and message_data['text']:\n                                    existing_message['text'] = message_data['text']\n                                    print(\n                                        f'Updated text for media group {message.grouped_id}: \"{message_data[\"text\"]}\"')\n                        else:\n                            # Not part of a media group, add as individual message\n                            new_messages.append(message_data)\n\n                        # Update last_message_id\n                        if message.id > self.last_message_id:\n                            self.last_message_id = message.id\n\n                        # Update offset_id for the next batch\n                        offset_id = message.id\n\n                    # Add grouped messages to new_messages\n                    new_messages.extend(media_groups.values())\n\n                    # Sort messages by date (optional)\n                    new_messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    # Update the shared messages list\n                    with self.messages_lock:\n                        self.messages.extend(new_messages)\n                        # Remove duplicates based on message ID\n                        self.messages = list({msg['id']: msg for msg in self.messages}.values())\n                        # Sort messages after merging\n                        self.messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    print(f'Fetched and processed {len(new_messages)} new messages.')\n\n                    # Save messages to file\n                    self.save_messages()\n\n                    # Yield control to the event loop\n                    await asyncio.sleep(1)  # Adjust sleep time as needed\n\n            except Exception as e:\n                print(f'An error occurred in fetch_messages: {e}')\n                traceback.print_exc()\n\n        # Run the async function in the event loop\n        try:\n            loop.run_until_complete(main())\n        finally:\n            # Properly disconnect the client\n            self.client.disconnect()\n            loop.close()\n\n    def get_media_extension(self, message):\n        \"\"\"\n        Get the file extension for the media.\n        \"\"\"\n        if message.photo:\n            return '.jpg'\n        elif message.video:\n            return '.mp4'\n        elif message.document:\n            # Get the extension from the mime type or file name\n            mime_type = message.document.mime_type\n            if mime_type == 'image/jpeg':\n                return '.jpg'\n            elif mime_type == 'image/png':\n                return '.png'\n            elif mime_type == 'video/mp4':\n                return '.mp4'\n            else:\n                # Extract extension from file name\n                if message.file and message.file.name:\n                    return os.path.splitext(message.file.name)[1]\n                else:\n                    return ''\n        else:\n            return ''\n\n    def get_channel_messages(self):\n        with self.messages_lock:\n            return self.messages.copy()\n\n\n# Instantiate the ChannelViewer class\nviewer = ChannelViewer()\n\n\n@app.route('/')\ndef index():\n    print('Received request for /')\n    messages = viewer.get_channel_messages()\n    print(f\"Number of messages to display: {len(messages)}\")\n    return render_template('index.html', messages=messages)\n\n\nif __name__ == '__main__':\n    app.run(debug=True, use_reloader=False)",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 26.641794604174486,
            "bleu_score": 8.435342742621158,
            "rougeL_score": 0.41666666666666663,
            "levenshtein_ratio": 25.547445255474454
        }
    },
    {
        "id": 16,
        "filename": "1.txt",
        "prefix": "from flask import Flask, render_template\nfrom dotenv import find_dotenv, load_dotenv\nfrom telethon import TelegramClient\nfrom telethon.tl.types import (\n    MessageMediaPhoto,\n    MessageMediaDocument,\n    MessageMediaWebPage,\n    WebPageEmpty,\n    WebPage\n)\n\nimport os\nimport asyncio\nimport threading\nimport traceback\nimport json\n\n# Initialize the Flask app in the global scope\napp = Flask(__name__)\n\n\nclass ChannelViewer:\n    def __init__(self):\n        self.channel_username = 'onlinerby'  # Replace with the target channel's username\n        self.messages = []\n        self.messages_lock = threading.Lock()\n        self.load_environment_variables()\n\n        # Store API credentials\n        self.api_id = os.getenv('API_ID')\n        self.api_hash = os.getenv('API_HASH')\n\n        # Initialize variables\n        self.last_message_id = 0  # To keep track of the last processed message ID\n\n        # Load existing messages from file\n        self.load_messages()\n\n        # Start the background thread\n        self.start_fetching_messages()\n\n    def load_environment_variables(self):\n        \"\"\"\n        Load environment variables from a .env file.\n        \"\"\"\n        try:\n            dotenv_path = find_dotenv()\n            if not dotenv_path:\n                raise FileNotFoundError(\".env file not found\")\n            load_dotenv(dotenv_path)\n            print(f\"Environment variables loaded from {dotenv_path}\")\n        except Exception as e:\n            print(f\"Error loading .env file: {e}\")\n            raise\n\n    def load_messages(self):\n        \"\"\"\n        Load messages from 'messages.json' if it exists.\n        \"\"\"\n        try:\n            with open('messages.json', 'r', encoding='utf-8') as f:\n                self.messages = json.load(f)\n            if self.messages:\n                # Update last_message_id with the highest message ID\n                self.last_message_id = max(msg['id'] for msg in self.messages)\n            print(f\"Loaded {len(self.messages)} messages from messages.json.\")\n        except FileNotFoundError:\n            print(\"messages.json not found. Starting with an empty message list.\")\n        except Exception as e:\n            print(f\"Error loading messages: {e}\")\n\n    def save_messages(self):\n        \"\"\"\n        Save messages to 'messages.json'.\n        \"\"\"\n        try:\n            with open('messages.json', 'w', encoding='utf-8') as f:\n                json.dump(self.messages, f, ensure_ascii=False, indent=4)\n            print(f\"Saved {len(self.messages)} messages to messages.json.\")\n        except Exception as e:\n            print(f\"Error saving messages: {e}\")\n\n    def start_fetching_messages(self):\n        print('Starting background thread to fetch messages.')\n        fetch_thread = threading.Thread(target=self.fetch_messages)\n        fetch_thread.daemon = True  # Daemonize thread to ",
        "actual_middle": "exit when main program exits\n        fetch_thread.start()\n        print('Background thread started.')\n\n    def fetch_messages(self):\n        pr",
        "generated_middle": "use it to avoid a race condition with the event loop\n            fetch_thread.start()\n\n    def",
        "suffix": "int('fetch_messages: Started fetching messages.')\n        # Set up a new event loop for this thread\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n\n        async def main():\n            try:\n                print('fetch_messages: Starting main function.')\n\n                # Initialize the Telegram client in this thread's event loop\n                self.client = TelegramClient('session_name', self.api_id, self.api_hash, loop=loop)\n\n                # Start the client (connect and authenticate)\n                await self.client.start()\n                print('Telegram client started in background thread.')\n\n                # Initialize variables\n                offset_id = 0  # Start from the latest message\n                limit = 50  # Number of messages to fetch in each batch\n\n                while True:\n                    print('Fetching new messages...')\n                    new_messages = []\n                    media_groups = {}\n\n                    # Fetch messages in batches\n                    messages = await self.client.get_messages(\n                        self.channel_username,\n                        limit=limit,\n                        offset_id=offset_id\n                    )\n\n                    if not messages:\n                        print('No new messages found.')\n                        await asyncio.sleep(5)  # Wait before checking again\n                        continue\n\n                    for message in reversed(messages):  # Process from oldest to newest\n                        print(f'Processing message ID {message.id}')\n                        message_data = {\n                            'id': message.id,\n                            'text': message.text or '',\n                            'date': message.date.strftime('%Y-%m-%d %H:%M:%S'),\n                            'sender': message.sender_id,\n                            'media': [],\n                            'media_type': None,\n                            'grouped_id': message.grouped_id,\n                        }\n\n                        # Check if the message has media\n                        if message.media:\n                            print(f'Message ID {message.id} has media.')\n                            # Ensure the directory exists\n                            media_dir = 'static/media/'\n                            os.makedirs(media_dir, exist_ok=True)\n\n                            # Initialize variables\n                            media_filename = None\n                            media_item = {}\n\n                            # Handle different media types\n                            if isinstance(message.media, MessageMediaPhoto):\n                                # For photos\n                                file_extension = '.jpg'\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded photo for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Photo for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'photo',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaDocument):\n                                # For documents (including videos, audio, etc.)\n                                file_extension = self.get_media_extension(message)\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded document for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Document for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'document',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaWebPage):\n                                # Handle web page previews\n                                print(f'Message ID {message.id} contains a web page preview.')\n                                webpage = message.media.webpage\n\n                                if isinstance(webpage, WebPage):\n                                    # Full web page preview\n                                    message_data['webpage'] = {\n                                        'url': webpage.url,\n                                        'title': getattr(webpage, 'title', ''),\n                                        'description': getattr(webpage, 'description', '')\n                                    }\n                                    print(\n                                        f\"Extracted webpage info for message ID {message.id}: {message_data['webpage']}\")\n                                elif isinstance(webpage, WebPageEmpty):\n                                    # Empty web page preview\n                                    print(f'Message ID {message.id} contains an empty web page preview.')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n                                else:\n                                    # Other web page types\n                                    print(\n                                        f'Message ID {message.id} contains an unsupported web page type: {type(webpage)}')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n\n                                # Add to new_messages and skip further processing\n                                new_messages.append(message_data)\n                                continue  # Skip to next message\n\n                            else:\n                                # Unsupported media type\n                                print(f'Message ID {message.id} has unsupported media type: {type(message.media)}')\n                                continue  # Skip this message\n\n                            # Update message data\n                            if media_item:\n                                message_data['media'].append(media_item)\n                                message_data['media_type'] = media_item['media_type']\n\n                        # Group messages by grouped_id if they are part of a media group\n                        if message.grouped_id:\n                            print(f'Message ID {message.id} is part of group {message.grouped_id}')\n                            if message.grouped_id not in media_groups:\n                                # First message in the group; store the text (caption) if available\n                                media_groups[message.grouped_id] = message_data\n                            else:\n                                # Append media to existing group\n                                existing_message = media_groups[message.grouped_id]\n                                existing_message['media'].extend(message_data['media'])\n                                # If the existing message doesn't have text, and current message has text, update it\n                                if not existing_message['text'] and message_data['text']:\n                                    existing_message['text'] = message_data['text']\n                                    print(\n                                        f'Updated text for media group {message.grouped_id}: \"{message_data[\"text\"]}\"')\n                        else:\n                            # Not part of a media group, add as individual message\n                            new_messages.append(message_data)\n\n                        # Update last_message_id\n                        if message.id > self.last_message_id:\n                            self.last_message_id = message.id\n\n                        # Update offset_id for the next batch\n                        offset_id = message.id\n\n                    # Add grouped messages to new_messages\n                    new_messages.extend(media_groups.values())\n\n                    # Sort messages by date (optional)\n                    new_messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    # Update the shared messages list\n                    with self.messages_lock:\n                        self.messages.extend(new_messages)\n                        # Remove duplicates based on message ID\n                        self.messages = list({msg['id']: msg for msg in self.messages}.values())\n                        # Sort messages after merging\n                        self.messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    print(f'Fetched and processed {len(new_messages)} new messages.')\n\n                    # Save messages to file\n                    self.save_messages()\n\n                    # Yield control to the event loop\n                    await asyncio.sleep(1)  # Adjust sleep time as needed\n\n            except Exception as e:\n                print(f'An error occurred in fetch_messages: {e}')\n                traceback.print_exc()\n\n        # Run the async function in the event loop\n        try:\n            loop.run_until_complete(main())\n        finally:\n            # Properly disconnect the client\n            self.client.disconnect()\n            loop.close()\n\n    def get_media_extension(self, message):\n        \"\"\"\n        Get the file extension for the media.\n        \"\"\"\n        if message.photo:\n            return '.jpg'\n        elif message.video:\n            return '.mp4'\n        elif message.document:\n            # Get the extension from the mime type or file name\n            mime_type = message.document.mime_type\n            if mime_type == 'image/jpeg':\n                return '.jpg'\n            elif mime_type == 'image/png':\n                return '.png'\n            elif mime_type == 'video/mp4':\n                return '.mp4'\n            else:\n                # Extract extension from file name\n                if message.file and message.file.name:\n                    return os.path.splitext(message.file.name)[1]\n                else:\n                    return ''\n        else:\n            return ''\n\n    def get_channel_messages(self):\n        with self.messages_lock:\n            return self.messages.copy()\n\n\n# Instantiate the ChannelViewer class\nviewer = ChannelViewer()\n\n\n@app.route('/')\ndef index():\n    print('Received request for /')\n    messages = viewer.get_channel_messages()\n    print(f\"Number of messages to display: {len(messages)}\")\n    return render_template('index.html', messages=messages)\n\n\nif __name__ == '__main__':\n    app.run(debug=True, use_reloader=False)",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 28.458096314312076,
            "bleu_score": 19.569499118895305,
            "rougeL_score": 0.25,
            "levenshtein_ratio": 30.76923076923077
        }
    },
    {
        "id": 17,
        "filename": "1.txt",
        "prefix": "from flask import Flask, render_template\nfrom dotenv import find_dotenv, load_dotenv\nfrom telethon import TelegramClient\nfrom telethon.tl.types import (\n    MessageMediaPhoto,\n    MessageMediaDocument,\n    MessageMediaWebPage,\n    WebPageEmpty,\n    WebPage\n)\n\nimport os\nimport asyncio\nimport threading\nimport traceback\nimport json\n\n# Initialize the Flask app in the global scope\napp = Flask(__name__)\n\n\nclass ChannelViewer:\n    def __init__(self):\n        self.channel_username = 'onlinerby'  # Replace with the target channel's username\n        self.messages = []\n        self.messages_lock = threading.Lock()\n        self.load_environment_variables()\n\n        # Store API credentials\n        self.api_id = os.getenv('API_ID')\n        self.api_hash = os.getenv('API_HASH')\n\n        # Initialize variables\n        self.last_message_id = 0  # To keep track of the last processed message ID\n\n        # Load existing messages from file\n        self.load_messages()\n\n        # Start the background thread\n        self.start_fetching_messages()\n\n    def load_environment_variables(self):\n        \"\"\"\n        Load environment variables from a .env file.\n        \"\"\"\n        try:\n            dotenv_path = find_dotenv()\n            if not dotenv_path:\n                raise FileNotFoundError(\".env file not found\")\n            load_dotenv(dotenv_path)\n            print(f\"Environment variables loaded from {dotenv_path}\")\n        except Exception as e:\n            print(f\"Error loading .env file: {e}\")\n            raise\n\n    def load_messages(self):\n        \"\"\"\n        Load messages from 'messages.json' if it exists.\n        \"\"\"\n        try:\n            with open('messages.json', 'r', encoding='utf-8') as f:\n                self.messages = json.load(f)\n            if self.messages:\n                # Update last_message_id with the highest message ID\n                self.last_message_id = max(msg['id'] for msg in self.messages)\n            print(f\"Loaded {len(self.messages)} messages from messages.json.\")\n        except FileNotFoundError:\n            print(\"messages.json not found. Starting with an empty message list.\")\n        except Exception as e:\n            print(f\"Error loading messages: {e}\")\n\n    def save_messages(self):\n        \"\"\"\n        Save messages to 'messages.json'.\n        \"\"\"\n        try:\n            with open('messages.json', 'w', encoding='utf-8') as f:\n                json.dump(self.messages, f, ensure_ascii=False, indent=4)\n            print(f\"Saved {len(self.messages)} messages to messages.json.\")\n        except Exception as e:\n            print(f\"Error saving messages: {e}\")\n\n    def start_fetching_messages(self):\n        print('Starting background thread to fetch messages.')\n        fetch_thread = threading.Thread(target=self.fetch_messages)\n        fetch_thread.daemon = True  # Daemonize thread to exit when main program exits\n        fetch_thread.start()\n        print('Background thread started.')\n\n    def fetch_messages(self):\n        print('fetch_messages: Started fetching messages.')\n        # Set up a new event loop for this thread\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n\n        async def main():\n            try:\n                print('fetch_messages: Starting main function.')\n\n                # Initialize the Telegram client in this thread's event loop\n                self.client = TelegramClient('session_name', self.api_id, self.api_hash, loop=loop)\n\n                # Start the client (connect and authenticate)\n                await self.client.start()\n                print('Telegram client started in background thread.')\n\n                # Initialize variables\n                offset_id = 0  # Start from the latest message\n                limit = 50  # Number of messages to fetch in each batch\n\n                while True:\n                    print('Fetching new messages...')\n                    new_messages = []\n                    media_groups = {}\n\n                    # Fetch messages in batches\n                    messages = await self.client.get_messages(\n                        self.channel_username,\n                        limit=limit,\n                        offset_id=offset_id\n                    )\n\n                    if not messages:\n                        print('No new messages found.')\n                        await asyncio.sleep(5)  # Wait before checking again\n                        continue\n\n                    for message in reversed(messages):  # Process from oldest to newest\n                        print(f'Processing message ID {message.id}')\n                        message_data = {\n                            'id': message.id,\n                            'text': message.text or '',\n                            'date': message.date.strftime('%Y-%m-%d %H:%M:%S'),\n                            'sender': message.sender_id,\n                            'media': [],\n                            'media_type': None,\n                            'grouped_id': message.grouped_id,\n                        }\n\n                        # Check if the message has media\n                        if message.media:\n                            print(f'Message ID {message.id} has media.')\n                            # Ensure the directory exists\n                            media_dir = 'static/media/'\n                            os.makedirs(media_dir, exist_ok=True)\n\n                            # Initialize variables\n                            media_filename = None\n                            media_item = {}\n\n                            # Handle different media types\n                            if isinstance(message.media, MessageMediaPhoto):\n                                # For photos\n                                file_extension = '.jpg'\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded photo for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Photo for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                    ",
        "actual_middle": "      ",
        "generated_middle": "",
        "suffix": "          'file_path': file_path,\n                                    'media_type': 'photo',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaDocument):\n                                # For documents (including videos, audio, etc.)\n                                file_extension = self.get_media_extension(message)\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded document for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Document for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'document',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaWebPage):\n                                # Handle web page previews\n                                print(f'Message ID {message.id} contains a web page preview.')\n                                webpage = message.media.webpage\n\n                                if isinstance(webpage, WebPage):\n                                    # Full web page preview\n                                    message_data['webpage'] = {\n                                        'url': webpage.url,\n                                        'title': getattr(webpage, 'title', ''),\n                                        'description': getattr(webpage, 'description', '')\n                                    }\n                                    print(\n                                        f\"Extracted webpage info for message ID {message.id}: {message_data['webpage']}\")\n                                elif isinstance(webpage, WebPageEmpty):\n                                    # Empty web page preview\n                                    print(f'Message ID {message.id} contains an empty web page preview.')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n                                else:\n                                    # Other web page types\n                                    print(\n                                        f'Message ID {message.id} contains an unsupported web page type: {type(webpage)}')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n\n                                # Add to new_messages and skip further processing\n                                new_messages.append(message_data)\n                                continue  # Skip to next message\n\n                            else:\n                                # Unsupported media type\n                                print(f'Message ID {message.id} has unsupported media type: {type(message.media)}')\n                                continue  # Skip this message\n\n                            # Update message data\n                            if media_item:\n                                message_data['media'].append(media_item)\n                                message_data['media_type'] = media_item['media_type']\n\n                        # Group messages by grouped_id if they are part of a media group\n                        if message.grouped_id:\n                            print(f'Message ID {message.id} is part of group {message.grouped_id}')\n                            if message.grouped_id not in media_groups:\n                                # First message in the group; store the text (caption) if available\n                                media_groups[message.grouped_id] = message_data\n                            else:\n                                # Append media to existing group\n                                existing_message = media_groups[message.grouped_id]\n                                existing_message['media'].extend(message_data['media'])\n                                # If the existing message doesn't have text, and current message has text, update it\n                                if not existing_message['text'] and message_data['text']:\n                                    existing_message['text'] = message_data['text']\n                                    print(\n                                        f'Updated text for media group {message.grouped_id}: \"{message_data[\"text\"]}\"')\n                        else:\n                            # Not part of a media group, add as individual message\n                            new_messages.append(message_data)\n\n                        # Update last_message_id\n                        if message.id > self.last_message_id:\n                            self.last_message_id = message.id\n\n                        # Update offset_id for the next batch\n                        offset_id = message.id\n\n                    # Add grouped messages to new_messages\n                    new_messages.extend(media_groups.values())\n\n                    # Sort messages by date (optional)\n                    new_messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    # Update the shared messages list\n                    with self.messages_lock:\n                        self.messages.extend(new_messages)\n                        # Remove duplicates based on message ID\n                        self.messages = list({msg['id']: msg for msg in self.messages}.values())\n                        # Sort messages after merging\n                        self.messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    print(f'Fetched and processed {len(new_messages)} new messages.')\n\n                    # Save messages to file\n                    self.save_messages()\n\n                    # Yield control to the event loop\n                    await asyncio.sleep(1)  # Adjust sleep time as needed\n\n            except Exception as e:\n                print(f'An error occurred in fetch_messages: {e}')\n                traceback.print_exc()\n\n        # Run the async function in the event loop\n        try:\n            loop.run_until_complete(main())\n        finally:\n            # Properly disconnect the client\n            self.client.disconnect()\n            loop.close()\n\n    def get_media_extension(self, message):\n        \"\"\"\n        Get the file extension for the media.\n        \"\"\"\n        if message.photo:\n            return '.jpg'\n        elif message.video:\n            return '.mp4'\n        elif message.document:\n            # Get the extension from the mime type or file name\n            mime_type = message.document.mime_type\n            if mime_type == 'image/jpeg':\n                return '.jpg'\n            elif mime_type == 'image/png':\n                return '.png'\n            elif mime_type == 'video/mp4':\n                return '.mp4'\n            else:\n                # Extract extension from file name\n                if message.file and message.file.name:\n                    return os.path.splitext(message.file.name)[1]\n                else:\n                    return ''\n        else:\n            return ''\n\n    def get_channel_messages(self):\n        with self.messages_lock:\n            return self.messages.copy()\n\n\n# Instantiate the ChannelViewer class\nviewer = ChannelViewer()\n\n\n@app.route('/')\ndef index():\n    print('Received request for /')\n    messages = viewer.get_channel_messages()\n    print(f\"Number of messages to display: {len(messages)}\")\n    return render_template('index.html', messages=messages)\n\n\nif __name__ == '__main__':\n    app.run(debug=True, use_reloader=False)",
        "label": "correct",
        "metrics": {
            "exact_match": 1,
            "chrf_score": 0.0,
            "bleu_score": 0.0,
            "rougeL_score": 0,
            "levenshtein_ratio": 0.0
        }
    }
]