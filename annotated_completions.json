[
    {
        "id": 0,
        "filename": "3.txt",
        "prefix": "def visualize_classes(data):\n\n    class_counts = count_classes(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_classes_v2(data):\n\n    class_counts = count_classes_v2(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_sample_images(data):\n    plt.figure(figsize=(24, 12))\n    for images, labels in data.take(1):\n        for i in range(32):\n            plt.subplot(4, 8, i + 1)\n            plt.imshow(np.array(images[i]).astype(\"uint8\"))\n    ",
        "actual_middle": "        plt.title(class_names[labels[i]])\n            plt.axis(\"off\")\n\ndef count_classes(data):\n    class_cou",
        "generated_middle": "def visualize_classes(data):\n\n    class_counts = count_classes(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_classes_v2(data):\n\n    class_counts = count_classes_v2(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_sample_images(data):\n    plt.figure(figsize=(24, 12))\n    for images, labels in data.take(1):\n        for i in range(32):\n            plt.subplot(4, 8, i + 1)\n            plt.imshow(np.array(images[i]).astype(\"uint8\"))\n    nts = {class_name: 0 for class_name in class_names}\n    for images, labels in data:\n        for label in labels:\n            class_name = class_names[label]\n            class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_v2(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for image, label in data:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_in_predicted_labels(y_pred):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for label in y_pred:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts        plt.title(classes_as_string(labels[i]), fontsize=20)",
        "suffix": "nts = {class_name: 0 for class_name in class_names}\n    for images, labels in data:\n        for label in labels:\n            class_name = class_names[label]\n            class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_v2(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for image, label in data:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_in_predicted_labels(y_pred):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for label in y_pred:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts",
        "label": "correct",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 20.989070722761564,
            "bleu_score": 4.2156640680416295,
            "rougeL_score": 0.08298755186721993,
            "levenshtein_ratio": 6.555269922879181
        }
    },
    {
        "id": 1,
        "filename": "3.txt",
        "prefix": "def visualize_classes(data):\n\n    class_counts = count_classes(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_classes_v2(data):\n\n    class_counts = count_classes_v2(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_sample_images(data):\n    plt.figure(figsize=(24, 12))\n    for images, labels in data.take(1):\n        for i in range(32):\n            plt.subplot(4, 8, i + 1)\n            plt.imshow(np.array(images[i]).astype(\"uint8\"))\n            plt.title(class_names[labels[i]])\n            plt.axis(\"off\")\n\ndef count_classes(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for images, labels in data:\n        for label in labels:\n            class_name = class_names[label]\n            class_counts[class_name] +=",
        "actual_middle": " 1\n\n    return c",
        "generated_middle": "def visualize_classes(data):\n\n    class_counts = count_classes(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_classes_v2(data):\n\n    class_counts = count_classes_v2(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_sample_images(data):\n    plt.figure(figsize=(24, 12))\n    for images, labels in data.take(1):\n        for i in range(32):\n            plt.subplot(4, 8, i + 1)\n            plt.imshow(np.array(images[i]).astype(\"uint8\"))\n            plt.title(class_names[labels[i]])\n            plt.axis(\"off\")\n\ndef count_classes(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for images, labels in data:\n        for label in labels:\n            class_name = class_names[label]\n            class_counts[class_name] +=lass_counts\n\ndef count_classes_v2(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for image, label in data:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_in_predicted_labels(y_pred):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for label in y_pred:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts count_samples_count(images[i])\n    return c",
        "suffix": "lass_counts\n\ndef count_classes_v2(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for image, label in data:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_in_predicted_labels(y_pred):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for label in y_pred:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts",
        "label": "correct",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 2.1185979798713848,
            "bleu_score": 0.20034608284893907,
            "rougeL_score": 0.025104602510460254,
            "levenshtein_ratio": 0.9797917942437229
        }
    },
    {
        "id": 2,
        "filename": "3.txt",
        "prefix": "def visualize_classes(data):\n\n    class_counts = count_classes(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_classes_v2(data):\n\n    class_counts = count_classes_v2(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_sample_images(data):\n    plt.figure(figsize=(24, 12))\n    for images, labels in data.take(1):\n        for i in range(32):\n            plt.subplot(4, 8, i + 1)\n            plt.imshow(np.array(images[i]).astype(\"uint8\"))\n            plt.title(class_names[labels[i]])\n            plt.axis(\"off\")\n\ndef count_classes(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for images, labels in data:\n        for label in labels:\n            class_name = class_names[label",
        "actual_middle": "]\n    ",
        "generated_middle": "def visualize_classes(data):\n\n    class_counts = count_classes(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_classes_v2(data):\n\n    class_counts = count_classes_v2(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_sample_images(data):\n    plt.figure(figsize=(24, 12))\n    for images, labels in data.take(1):\n        for i in range(32):\n            plt.subplot(4, 8, i + 1)\n            plt.imshow(np.array(images[i]).astype(\"uint8\"))\n            plt.title(class_names[labels[i]])\n            plt.axis(\"off\")\n\ndef count_classes(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for images, labels in data:\n        for label in labels:\n            class_name = class_names[label        class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_v2(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for image, label in data:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_in_predicted_labels(y_pred):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for label in y_pred:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts]\n            class_counts[class_name] += 1\n\n    return class_counts",
        "suffix": "        class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_v2(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for image, label in data:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_in_predicted_labels(y_pred):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for label in y_pred:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 0.38520801232665647,
            "bleu_score": 0.07546518619764185,
            "rougeL_score": 0,
            "levenshtein_ratio": 0.3599280143971151
        }
    },
    {
        "id": 3,
        "filename": "3.txt",
        "prefix": "def visualize_classes(data):\n\n    class_counts = count_classes(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_classes_v2(data):\n\n    class_counts = count_classes_v2(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_sample_images(data):\n    plt.figure(figsize=(24, 12))\n    for images, labels in data.take(1):\n        for i in range(32):\n            plt.subplot(4, 8, i + 1)\n            plt.imshow(np.array(images[i]).astype(\"uint8\"))\n            plt.title(class_names[labels[i]])\n            plt.axis(\"off\")\n\ndef count_classes(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for images, labels in data:\n        for label in labels:\n            class_name = class_names[label]\n            class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_v2(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for image, label in data:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_in_predicted_labels(y_pred):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for label in y_pred:\n        class_name ",
        "actual_middle": "= c",
        "generated_middle": "def visualize_classes(data):\n\n    class_counts = count_classes(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_classes_v2(data):\n\n    class_counts = count_classes_v2(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_sample_images(data):\n    plt.figure(figsize=(24, 12))\n    for images, labels in data.take(1):\n        for i in range(32):\n            plt.subplot(4, 8, i + 1)\n            plt.imshow(np.array(images[i]).astype(\"uint8\"))\n            plt.title(class_names[labels[i]])\n            plt.axis(\"off\")\n\ndef count_classes(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for images, labels in data:\n        for label in labels:\n            class_name = class_names[label]\n            class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_v2(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for image, label in data:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_in_predicted_labels(y_pred):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for label in y_pred:\n        class_name lass_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts= cl",
        "suffix": "lass_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts",
        "label": "partially_correct",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 0.5972923596299209,
            "bleu_score": 0.07778976024491494,
            "rougeL_score": 0.0,
            "levenshtein_ratio": 0.18679950186799577
        }
    },
    {
        "id": 4,
        "filename": "3.txt",
        "prefix": "def visualize_classes(data):\n\n    class_counts = count_classes(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_classes_v2(data):\n\n    class_counts = count_classes_v2(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_sample_images(data):\n    plt.figure(figsize=(24, 12))\n    for images, labels in data.take(1):\n        for i in range(32):\n            plt.subplot(4, 8, i + 1)\n            plt.imshow(np.array(images[i]).astype(\"uint8\"))\n            plt.title(class_names[labels[i]])\n            plt.axis(\"off\")\n\ndef count_classes(data):\n    class_counts = {class_name: 0 for class_name ",
        "actual_middle": "in class_names}\n    fo",
        "generated_middle": "def visualize_classes(data):\n\n    class_counts = count_classes(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_classes_v2(data):\n\n    class_counts = count_classes_v2(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_sample_images(data):\n    plt.figure(figsize=(24, 12))\n    for images, labels in data.take(1):\n        for i in range(32):\n            plt.subplot(4, 8, i + 1)\n            plt.imshow(np.array(images[i]).astype(\"uint8\"))\n            plt.title(class_names[labels[i]])\n            plt.axis(\"off\")\n\ndef count_classes(data):\n    class_counts = {class_name: 0 for class_name r images, labels in data:\n        for label in labels:\n            class_name = class_names[label]\n            class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_v2(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for image, label in data:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_in_predicted_labels(y_pred):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for label in y_pred:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_countsin class_names}\n\n    \n    fo",
        "suffix": "r images, labels in data:\n        for label in labels:\n            class_name = class_names[label]\n            class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_v2(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for image, label in data:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_in_predicted_labels(y_pred):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for label in y_pred:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts",
        "label": "correct",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 5.189458492619798,
            "bleu_score": 0.9605050522886858,
            "rougeL_score": 0.03404255319148936,
            "levenshtein_ratio": 1.3656114214773418
        }
    },
    {
        "id": 5,
        "filename": "3.txt",
        "prefix": "def visualize_classes(data):\n\n    class_counts = count_classes(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_classes_v2(data):\n\n    class_counts = count_classes_v2(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(",
        "actual_middle": "), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    pl",
        "generated_middle": "def visualize_classes(data):\n\n    class_counts = count_classes(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of samples')\n    plt.xticks(rotation=45)\n    plt.show()\n\ndef visualize_classes_v2(data):\n\n    class_counts = count_classes_v2(data)\n\n    plt.figure(figsize=(10, 6))\n    plt.bar(class_counts.keys(), class_counts.values(t.show()\n\ndef visualize_sample_images(data):\n    plt.figure(figsize=(24, 12))\n    for images, labels in data.take(1):\n        for i in range(32):\n            plt.subplot(4, 8, i + 1)\n            plt.imshow(np.array(images[i]).astype(\"uint8\"))\n            plt.title(class_names[labels[i]])\n            plt.axis(\"off\")\n\ndef count_classes(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for images, labels in data:\n        for label in labels:\n            class_name = class_names[label]\n            class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_v2(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for image, label in data:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_in_predicted_labels(y_pred):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for label in y_pred:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts), color='skyblue')\n    plt.xlabel('Classes')\n    plt.ylabel('Number of",
        "suffix": "t.show()\n\ndef visualize_sample_images(data):\n    plt.figure(figsize=(24, 12))\n    for images, labels in data.take(1):\n        for i in range(32):\n            plt.subplot(4, 8, i + 1)\n            plt.imshow(np.array(images[i]).astype(\"uint8\"))\n            plt.title(class_names[labels[i]])\n            plt.axis(\"off\")\n\ndef count_classes(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for images, labels in data:\n        for label in labels:\n            class_name = class_names[label]\n            class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_v2(data):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for image, label in data:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts\n\ndef count_classes_in_predicted_labels(y_pred):\n    class_counts = {class_name: 0 for class_name in class_names}\n    for label in y_pred:\n        class_name = class_names[label]\n        class_counts[class_name] += 1\n\n    return class_counts",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 28.738737951438036,
            "bleu_score": 5.969892953907958,
            "rougeL_score": 0.11618257261410789,
            "levenshtein_ratio": 7.435897435897432
        }
    },
    {
        "id": 6,
        "filename": "2.txt",
        "prefix": "import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder\nfeatures=pd.read_csv(\"features.csv\",index_col=0).to_numpy()\nlabels=pd.read_csv(\"labels.csv\",index_col=0).to_numpy()\n\ntarget_names = [BIOMES.get(int(label), str(label)) for label in labels]\n\n\nX_train, X_test, y_train, y_test = train_test_split(features, target_names, test_size=0.2, random_state=42)\nlabel_encoder = LabelEncoder()\n\n\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\nmodel = xgb.XGBClassifier(objective='multi:softmax',",
        "actual_middle": " num_c",
        "generated_middle": "import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder\nfeatures=pd.read_csv(\"features.csv\",index_col=0).to_numpy()\nlabels=pd.read_csv(\"labels.csv\",index_col=0).to_numpy()\n\ntarget_names = [BIOMES.get(int(label), str(label)) for label in labels]\n\n\nX_train, X_test, y_train, y_test = train_test_split(features, target_names, test_size=0.2, random_state=42)\nlabel_encoder = LabelEncoder()\n\n\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\nmodel = xgb.XGBClassifier(objective='multi:softmax',lass=len(np.unique(y_train)))\nmodel.fit(X_train, y_train_encoded)\n\npredictions = model.predict(X_test)\npredictions = label_encoder.inverse_transform(predictions)\nreport = classification_report(y_test, predictions)\nprint(\"Classification Report:\\n\", report) s",
        "suffix": "lass=len(np.unique(y_train)))\nmodel.fit(X_train, y_train_encoded)\n\npredictions = model.predict(X_test)\npredictions = label_encoder.inverse_transform(predictions)\nreport = classification_report(y_test, predictions)\nprint(\"Classification Report:\\n\", report)",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 1.1553449852252171,
            "bleu_score": 0.12974545557248765,
            "rougeL_score": 0.0,
            "levenshtein_ratio": 0.6535947712418277
        }
    },
    {
        "id": 7,
        "filename": "2.txt",
        "prefix": "import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder\nfeatures=pd.read_csv(\"features.csv\",index_col=0).to_numpy()\nlabels=pd.read_csv(\"labels.csv\",index_col=0).to_numpy()\n\ntarget_names = [BIOMES.get(int(label), str(label)) for label in labels]\n\n\nX_train, X_test, y_train, y_test = train_test_split(features, target_names, test_size=0.2, random_state=42)\nlabel_encoder = LabelEncoder()\n\n\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\nmodel = xgb.XGBClassifier(objective='multi:softmax'",
        "actual_middle": ", num_cla",
        "generated_middle": "import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder\nfeatures=pd.read_csv(\"features.csv\",index_col=0).to_numpy()\nlabels=pd.read_csv(\"labels.csv\",index_col=0).to_numpy()\n\ntarget_names = [BIOMES.get(int(label), str(label)) for label in labels]\n\n\nX_train, X_test, y_train, y_test = train_test_split(features, target_names, test_size=0.2, random_state=42)\nlabel_encoder = LabelEncoder()\n\n\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\nmodel = xgb.XGBClassifier(objective='multi:softmax'ss=len(np.unique(y_train)))\nmodel.fit(X_train, y_train_encoded)\n\npredictions = model.predict(X_test)\npredictions = label_encoder.inverse_transform(predictions)\nreport = classification_report(y_test, predictions)\nprint(\"Classification Report:\\n\", report))\n\nmodel.fit(X_train, y_train_encoded, epo",
        "suffix": "ss=len(np.unique(y_train)))\nmodel.fit(X_train, y_train_encoded)\n\npredictions = model.predict(X_test)\npredictions = label_encoder.inverse_transform(predictions)\nreport = classification_report(y_test, predictions)\nprint(\"Classification Report:\\n\", report)",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 1.462642897616097,
            "bleu_score": 0.1472684523889216,
            "rougeL_score": 0.0,
            "levenshtein_ratio": 0.9424083769633551
        }
    },
    {
        "id": 8,
        "filename": "2.txt",
        "prefix": "import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder\n",
        "actual_middle": "features=pd.",
        "generated_middle": "import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder\nread_csv(\"features.csv\",index_col=0).to_numpy()\nlabels=pd.read_csv(\"labels.csv\",index_col=0).to_numpy()\n\ntarget_names = [BIOMES.get(int(label), str(label)) for label in labels]\n\n\nX_train, X_test, y_train, y_test = train_test_split(features, target_names, test_size=0.2, random_state=42)\nlabel_encoder = LabelEncoder()\n\n\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\nmodel = xgb.XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_train)))\nmodel.fit(X_train, y_train_encoded)\n\npredictions = model.predict(X_test)\npredictions = label_encoder.inverse_transform(predictions)\nreport = classification_report(y_test, predictions)\nprint(\"Classification Report:\\n\", report)load_data = pd.read_csv(\"features.csv\")    # Feature names: Bio",
        "suffix": "read_csv(\"features.csv\",index_col=0).to_numpy()\nlabels=pd.read_csv(\"labels.csv\",index_col=0).to_numpy()\n\ntarget_names = [BIOMES.get(int(label), str(label)) for label in labels]\n\n\nX_train, X_test, y_train, y_test = train_test_split(features, target_names, test_size=0.2, random_state=42)\nlabel_encoder = LabelEncoder()\n\n\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\nmodel = xgb.XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_train)))\nmodel.fit(X_train, y_train_encoded)\n\npredictions = model.predict(X_test)\npredictions = label_encoder.inverse_transform(predictions)\nreport = classification_report(y_test, predictions)\nprint(\"Classification Report:\\n\", report)",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 4.287588483068057,
            "bleu_score": 0.4868241088819548,
            "rougeL_score": 0.026666666666666665,
            "levenshtein_ratio": 1.2332990750256956
        }
    },
    {
        "id": 9,
        "filename": "2.txt",
        "prefix": "import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder\nfeatures=pd.read_csv(\"features.csv\",index_col=0).to_numpy()\nlabels=pd.read_csv(\"labels.csv\",index_col=0).to_numpy()\n\ntarget_names = [BIOMES.get(int(label), str(label)) for label in labels]\n\n\nX_train, X_test, y_train, y_test = train_test_split(features, target_names, test_size=0.2, random_state=42)\nlabel_encoder = LabelEncoder()\n\n\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\nmodel = xgb.XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_train)))\nmodel.fit(X_train, y_train_encoded)\n",
        "actual_middle": "\npredictions ",
        "generated_middle": "import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder\nfeatures=pd.read_csv(\"features.csv\",index_col=0).to_numpy()\nlabels=pd.read_csv(\"labels.csv\",index_col=0).to_numpy()\n\ntarget_names = [BIOMES.get(int(label), str(label)) for label in labels]\n\n\nX_train, X_test, y_train, y_test = train_test_split(features, target_names, test_size=0.2, random_state=42)\nlabel_encoder = LabelEncoder()\n\n\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\nmodel = xgb.XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_train)))\nmodel.fit(X_train, y_train_encoded)\n= model.predict(X_test)\npredictions = label_encoder.inverse_transform(predictions)\nreport = classification_report(y_test, predictions)\nprint(\"Classification Report:\\n\", report)predictions",
        "suffix": "= model.predict(X_test)\npredictions = label_encoder.inverse_transform(predictions)\nreport = classification_report(y_test, predictions)\nprint(\"Classification Report:\\n\", report)",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 4.803129085048886,
            "bleu_score": 0.12927105839606598,
            "rougeL_score": 0.014184397163120567,
            "levenshtein_ratio": 1.413043478260867
        }
    },
    {
        "id": 10,
        "filename": "2.txt",
        "prefix": "import xgboost ",
        "actual_middle": "as xgb\nfrom sklearn.mode",
        "generated_middle": "import xgboost l_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder\nfeatures=pd.read_csv(\"features.csv\",index_col=0).to_numpy()\nlabels=pd.read_csv(\"labels.csv\",index_col=0).to_numpy()\n\ntarget_names = [BIOMES.get(int(label), str(label)) for label in labels]\n\n\nX_train, X_test, y_train, y_test = train_test_split(features, target_names, test_size=0.2, random_state=42)\nlabel_encoder = LabelEncoder()\n\n\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\nmodel = xgb.XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_train)))\nmodel.fit(X_train, y_train_encoded)\n\npredictions = model.predict(X_test)\npredictions = label_encoder.inverse_transform(predictions)\nreport = classification_report(y_test, predictions)\nprint(\"Classification Report:\\n\", report)\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ima",
        "suffix": "l_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder\nfeatures=pd.read_csv(\"features.csv\",index_col=0).to_numpy()\nlabels=pd.read_csv(\"labels.csv\",index_col=0).to_numpy()\n\ntarget_names = [BIOMES.get(int(label), str(label)) for label in labels]\n\n\nX_train, X_test, y_train, y_test = train_test_split(features, target_names, test_size=0.2, random_state=42)\nlabel_encoder = LabelEncoder()\n\n\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\nmodel = xgb.XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_train)))\nmodel.fit(X_train, y_train_encoded)\n\npredictions = model.predict(X_test)\npredictions = label_encoder.inverse_transform(predictions)\nreport = classification_report(y_test, predictions)\nprint(\"Classification Report:\\n\", report)",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 7.091595932232064,
            "bleu_score": 0.5331054045602345,
            "rougeL_score": 0.039473684210526314,
            "levenshtein_ratio": 2.4109014675052443
        }
    },
    {
        "id": 11,
        "filename": "2.txt",
        "prefix": "import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder\nfeatures=pd.read_csv(\"features.csv\",index_col=0).to_numpy()\nlabels=pd.read_csv(\"labels.csv\",index_col=0).to_numpy()\n\ntarget_names = [BIOMES.get(int(label), str(label)) for label in labels]\n\n\nX_train, X_test, y_train, y_test = train_test_split(features, target_names, test_size=0.2, random_state=42)\nlabel_encoder = LabelEncoder()\n\n\ny_train_encoded = label_encoder.fit_transform(y_trai",
        "actual_middle": "n)\ny_test_encoded = label_encoder.transform(y_test)\n\nmodel = xgb.XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y_tra",
        "generated_middle": "import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder\nfeatures=pd.read_csv(\"features.csv\",index_col=0).to_numpy()\nlabels=pd.read_csv(\"labels.csv\",index_col=0).to_numpy()\n\ntarget_names = [BIOMES.get(int(label), str(label)) for label in labels]\n\n\nX_train, X_test, y_train, y_test = train_test_split(features, target_names, test_size=0.2, random_state=42)\nlabel_encoder = LabelEncoder()\n\n\ny_train_encoded = label_encoder.fit_transform(y_traiin)))\nmodel.fit(X_train, y_train_encoded)\n\npredictions = model.predict(X_test)\npredictions = label_encoder.inverse_transform(predictions)\nreport = classification_report(y_test, predictions)\nprint(\"Classification Report:\\n\", report)m).toarray()\ny_test_encoded = label_encoder.transform(y_",
        "suffix": "in)))\nmodel.fit(X_train, y_train_encoded)\n\npredictions = model.predict(X_test)\npredictions = label_encoder.inverse_transform(predictions)\nreport = classification_report(y_test, predictions)\nprint(\"Classification Report:\\n\", report)",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 28.38081298276685,
            "bleu_score": 7.556123036287742,
            "rougeL_score": 0.12000000000000001,
            "levenshtein_ratio": 11.150652431791219
        }
    },
    {
        "id": 12,
        "filename": "1.txt",
        "prefix": "from flask import Flask, render_template\nfrom dotenv import find_dotenv, load_dotenv\nfrom telethon import TelegramClient\nfrom telethon.tl.types import (\n    MessageMediaPhoto,\n    MessageMediaDocument,\n    MessageMediaWebPage,\n    WebPageEmpty,\n    WebPage\n)\n\nimport os\nimport asyncio\nimport threading\nimport traceback\nimport json\n\n# Initialize the Flask app in the global scope\napp = Flask(__name__)\n\n\nclass ChannelViewer:\n    def __init__(self):\n        self.channel_username = 'onlinerby'  # Replace with the target channel's username\n        self.messages = []\n        self.messages_lock = threading.Lock()\n        self.load_environment_variables()\n\n        # Store API credentials\n        self.api_id = os.getenv('API_ID')\n        self.api_hash = os.getenv('API_HASH')\n\n        # Initialize variables\n        self.last_message_id = 0  # To keep track of the last processed message ID\n\n        # Load existing messages from file\n        self.load_messages()\n\n        # Start the background thread\n        self.start_fetching_messages()\n\n    def load_environment_variables(self):\n        \"\"\"\n        Load environment variables from a .env file.\n        \"\"\"\n        try:\n            dotenv_path = find_dotenv()\n            if not dotenv_path:\n                raise FileNotFoundError(\".env file not found\")\n            load_dotenv(dotenv_path)\n            print(f\"Environment variables loaded from {dotenv_path}\")\n        except Exception as e:\n            print(f\"Error loading .env file: {e}\")\n            raise\n\n    def load_messages(self):\n        \"\"\"\n        Load messages from 'messages.json' if it exists.\n        \"\"\"\n        try:\n            with open('messages.json', 'r', encoding='utf-8') as f:\n                self.messages = json.load(f)\n            if self.messages:\n                # Update last_message_id with the highest message ID\n                self.last_message_id = max(msg['id'] for msg in self.messages)\n            print(f\"Loaded {len(self.messages)} messages from messages.json.\")\n        except FileNotFoundError:\n            print(\"messages.json not found. Starting with an empty message list.\")\n        except Exception as e:\n            print(f\"Error loading messages: {e}\")\n\n    def save_messages(self):\n        \"\"\"\n        Save messages to 'messages.json'.\n        \"\"\"\n        try:\n            with open('messages.json', 'w', encoding='utf-8') as f:\n                json.dump(self.messages, f, ensure_ascii=False, indent=4)\n            print(f\"Saved {len(self.messages)} messages to messages.json.\")\n        except Exception as e:\n            print(f\"Error saving messages: {e}\")\n\n    def start_fetching_messages(self):\n        print('Starting background thread",
        "actual_middle": " to fetch messages.')\n     ",
        "generated_middle": "from flask import Flask, render_template\nfrom dotenv import find_dotenv, load_dotenv\nfrom telethon import TelegramClient\nfrom telethon.tl.types import (\n    MessageMediaPhoto,\n    MessageMediaDocument,\n    MessageMediaWebPage,\n    WebPageEmpty,\n    WebPage\n)\n\nimport os\nimport asyncio\nimport threading\nimport traceback\nimport json\n\n# Initialize the Flask app in the global scope\napp = Flask(__name__)\n\n\nclass ChannelViewer:\n    def __init__(self):\n        self.channel_username = 'onlinerby'  # Replace with the target channel's username\n        self.messages = []\n        self.messages_lock = threading.Lock()\n        self.load_environment_variables()\n\n        # Store API credentials\n        self.api_id = os.getenv('API_ID')\n        self.api_hash = os.getenv('API_HASH')\n\n        # Initialize variables\n        self.last_message_id = 0  # To keep track of the last processed message ID\n\n        # Load existing messages from file\n        self.load_messages()\n\n        # Start the background thread\n        self.start_fetching_messages()\n\n    def load_environment_variables(self):\n        \"\"\"\n        Load environment variables from a .env file.\n        \"\"\"\n        try:\n            dotenv_path = find_dotenv()\n            if not dotenv_path:\n                raise FileNotFoundError(\".env file not found\")\n            load_dotenv(dotenv_path)\n            print(f\"Environment variables loaded from {dotenv_path}\")\n        except Exception as e:\n            print(f\"Error loading .env file: {e}\")\n            raise\n\n    def load_messages(self):\n        \"\"\"\n        Load messages from 'messages.json' if it exists.\n        \"\"\"\n        try:\n            with open('messages.json', 'r', encoding='utf-8') as f:\n                self.messages = json.load(f)\n            if self.messages:\n                # Update last_message_id with the highest message ID\n                self.last_message_id = max(msg['id'] for msg in self.messages)\n            print(f\"Loaded {len(self.messages)} messages from messages.json.\")\n        except FileNotFoundError:\n            print(\"messages.json not found. Starting with an empty message list.\")\n        except Exception as e:\n            print(f\"Error loading messages: {e}\")\n\n    def save_messages(self):\n        \"\"\"\n        Save messages to 'messages.json'.\n        \"\"\"\n        try:\n            with open('messages.json', 'w', encoding='utf-8') as f:\n                json.dump(self.messages, f, ensure_ascii=False, indent=4)\n            print(f\"Saved {len(self.messages)} messages to messages.json.\")\n        except Exception as e:\n            print(f\"Error saving messages: {e}\")\n\n    def start_fetching_messages(self):\n        print('Starting background thread   fetch_thread = threading.Thread(target=self.fetch_messages)\n        fetch_thread.daemon = True  # Daemonize thread to exit when main program exits\n        fetch_thread.start()\n        print('Background thread started.')\n\n    def fetch_messages(self):\n        print('fetch_messages: Started fetching messages.')\n        # Set up a new event loop for this thread\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n\n        async def main():\n            try:\n                print('fetch_messages: Starting main function.')\n\n                # Initialize the Telegram client in this thread's event loop\n                self.client = TelegramClient('session_name', self.api_id, self.api_hash, loop=loop)\n\n                # Start the client (connect and authenticate)\n                await self.client.start()\n                print('Telegram client started in background thread.')\n\n                # Initialize variables\n                offset_id = 0  # Start from the latest message\n                limit = 50  # Number of messages to fetch in each batch\n\n                while True:\n                    print('Fetching new messages...')\n                    new_messages = []\n                    media_groups = {}\n\n                    # Fetch messages in batches\n                    messages = await self.client.get_messages(\n                        self.channel_username,\n                        limit=limit,\n                        offset_id=offset_id\n                    )\n\n                    if not messages:\n                        print('No new messages found.')\n                        await asyncio.sleep(5)  # Wait before checking again\n                        continue\n\n                    for message in reversed(messages):  # Process from oldest to newest\n                        print(f'Processing message ID {message.id}')\n                        message_data = {\n                            'id': message.id,\n                            'text': message.text or '',\n                            'date': message.date.strftime('%Y-%m-%d %H:%M:%S'),\n                            'sender': message.sender_id,\n                            'media': [],\n                            'media_type': None,\n                            'grouped_id': message.grouped_id,\n                        }\n\n                        # Check if the message has media\n                        if message.media:\n                            print(f'Message ID {message.id} has media.')\n                            # Ensure the directory exists\n                            media_dir = 'static/media/'\n                            os.makedirs(media_dir, exist_ok=True)\n\n                            # Initialize variables\n                            media_filename = None\n                            media_item = {}\n\n                            # Handle different media types\n                            if isinstance(message.media, MessageMediaPhoto):\n                                # For photos\n                                file_extension = '.jpg'\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded photo for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Photo for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'photo',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaDocument):\n                                # For documents (including videos, audio, etc.)\n                                file_extension = self.get_media_extension(message)\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded document for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Document for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'document',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaWebPage):\n                                # Handle web page previews\n                                print(f'Message ID {message.id} contains a web page preview.')\n                                webpage = message.media.webpage\n\n                                if isinstance(webpage, WebPage):\n                                    # Full web page preview\n                                    message_data['webpage'] = {\n                                        'url': webpage.url,\n                                        'title': getattr(webpage, 'title', ''),\n                                        'description': getattr(webpage, 'description', '')\n                                    }\n                                    print(\n                                        f\"Extracted webpage info for message ID {message.id}: {message_data['webpage']}\")\n                                elif isinstance(webpage, WebPageEmpty):\n                                    # Empty web page preview\n                                    print(f'Message ID {message.id} contains an empty web page preview.')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n                                else:\n                                    # Other web page types\n                                    print(\n                                        f'Message ID {message.id} contains an unsupported web page type: {type(webpage)}')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n\n                                # Add to new_messages and skip further processing\n                                new_messages.append(message_data)\n                                continue  # Skip to next message\n\n                            else:\n                                # Unsupported media type\n                                print(f'Message ID {message.id} has unsupported media type: {type(message.media)}')\n                                continue  # Skip this message\n\n                            # Update message data\n                            if media_item:\n                                message_data['media'].append(media_item)\n                                message_data['media_type'] = media_item['media_type']\n\n                        # Group messages by grouped_id if they are part of a media group\n                        if message.grouped_id:\n                            print(f'Message ID {message.id} is part of group {message.grouped_id}')\n                            if message.grouped_id not in media_groups:\n                                # First message in the group; store the text (caption) if available\n                                media_groups[message.grouped_id] = message_data\n                            else:\n                                # Append media to existing group\n                                existing_message = media_groups[message.grouped_id]\n                                existing_message['media'].extend(message_data['media'])\n                                # If the existing message doesn't have text, and current message has text, update it\n                                if not existing_message['text'] and message_data['text']:\n                                    existing_message['text'] = message_data['text']\n                                    print(\n                                        f'Updated text for media group {message.grouped_id}: \"{message_data[\"text\"]}\"')\n                        else:\n                            # Not part of a media group, add as individual message\n                            new_messages.append(message_data)\n\n                        # Update last_message_id\n                        if message.id > self.last_message_id:\n                            self.last_message_id = message.id\n\n                        # Update offset_id for the next batch\n                        offset_id = message.id\n\n                    # Add grouped messages to new_messages\n                    new_messages.extend(media_groups.values())\n\n                    # Sort messages by date (optional)\n                    new_messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    # Update the shared messages list\n                    with self.messages_lock:\n                        self.messages.extend(new_messages)\n                        # Remove duplicates based on message ID\n                        self.messages = list({msg['id']: msg for msg in self.messages}.values())\n                        # Sort messages after merging\n                        self.messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    print(f'Fetched and processed {len(new_messages)} new messages.')\n\n                    # Save messages to file\n                    self.save_messages()\n\n                    # Yield control to the event loop\n                    await asyncio.sleep(1)  # Adjust sleep time as needed\n\n            except Exception as e:\n                print(f'An error occurred in fetch_messages: {e}')\n                traceback.print_exc()\n\n        # Run the async function in the event loop\n        try:\n            loop.run_until_complete(main())\n        finally:\n            # Properly disconnect the client\n            self.client.disconnect()\n            loop.close()\n\n    def get_media_extension(self, message):\n        \"\"\"\n        Get the file extension for the media.\n        \"\"\"\n        if message.photo:\n            return '.jpg'\n        elif message.video:\n            return '.mp4'\n        elif message.document:\n            # Get the extension from the mime type or file name\n            mime_type = message.document.mime_type\n            if mime_type == 'image/jpeg':\n                return '.jpg'\n            elif mime_type == 'image/png':\n                return '.png'\n            elif mime_type == 'video/mp4':\n                return '.mp4'\n            else:\n                # Extract extension from file name\n                if message.file and message.file.name:\n                    return os.path.splitext(message.file.name)[1]\n                else:\n                    return ''\n        else:\n            return ''\n\n    def get_channel_messages(self):\n        with self.messages_lock:\n            return self.messages.copy()\n\n\n# Instantiate the ChannelViewer class\nviewer = ChannelViewer()\n\n\n@app.route('/')\ndef index():\n    print('Received request for /')\n    messages = viewer.get_channel_messages()\n    print(f\"Number of messages to display: {len(messages)}\")\n    return render_template('index.html', messages=messages)\n\n\nif __name__ == '__main__':\n    app.run(debug=True, use_reloader=False)_fetching_messages: Started fetching messages.')\n        loop = asyncio.new_event_loop",
        "suffix": "   fetch_thread = threading.Thread(target=self.fetch_messages)\n        fetch_thread.daemon = True  # Daemonize thread to exit when main program exits\n        fetch_thread.start()\n        print('Background thread started.')\n\n    def fetch_messages(self):\n        print('fetch_messages: Started fetching messages.')\n        # Set up a new event loop for this thread\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n\n        async def main():\n            try:\n                print('fetch_messages: Starting main function.')\n\n                # Initialize the Telegram client in this thread's event loop\n                self.client = TelegramClient('session_name', self.api_id, self.api_hash, loop=loop)\n\n                # Start the client (connect and authenticate)\n                await self.client.start()\n                print('Telegram client started in background thread.')\n\n                # Initialize variables\n                offset_id = 0  # Start from the latest message\n                limit = 50  # Number of messages to fetch in each batch\n\n                while True:\n                    print('Fetching new messages...')\n                    new_messages = []\n                    media_groups = {}\n\n                    # Fetch messages in batches\n                    messages = await self.client.get_messages(\n                        self.channel_username,\n                        limit=limit,\n                        offset_id=offset_id\n                    )\n\n                    if not messages:\n                        print('No new messages found.')\n                        await asyncio.sleep(5)  # Wait before checking again\n                        continue\n\n                    for message in reversed(messages):  # Process from oldest to newest\n                        print(f'Processing message ID {message.id}')\n                        message_data = {\n                            'id': message.id,\n                            'text': message.text or '',\n                            'date': message.date.strftime('%Y-%m-%d %H:%M:%S'),\n                            'sender': message.sender_id,\n                            'media': [],\n                            'media_type': None,\n                            'grouped_id': message.grouped_id,\n                        }\n\n                        # Check if the message has media\n                        if message.media:\n                            print(f'Message ID {message.id} has media.')\n                            # Ensure the directory exists\n                            media_dir = 'static/media/'\n                            os.makedirs(media_dir, exist_ok=True)\n\n                            # Initialize variables\n                            media_filename = None\n                            media_item = {}\n\n                            # Handle different media types\n                            if isinstance(message.media, MessageMediaPhoto):\n                                # For photos\n                                file_extension = '.jpg'\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded photo for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Photo for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'photo',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaDocument):\n                                # For documents (including videos, audio, etc.)\n                                file_extension = self.get_media_extension(message)\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded document for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Document for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'document',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaWebPage):\n                                # Handle web page previews\n                                print(f'Message ID {message.id} contains a web page preview.')\n                                webpage = message.media.webpage\n\n                                if isinstance(webpage, WebPage):\n                                    # Full web page preview\n                                    message_data['webpage'] = {\n                                        'url': webpage.url,\n                                        'title': getattr(webpage, 'title', ''),\n                                        'description': getattr(webpage, 'description', '')\n                                    }\n                                    print(\n                                        f\"Extracted webpage info for message ID {message.id}: {message_data['webpage']}\")\n                                elif isinstance(webpage, WebPageEmpty):\n                                    # Empty web page preview\n                                    print(f'Message ID {message.id} contains an empty web page preview.')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n                                else:\n                                    # Other web page types\n                                    print(\n                                        f'Message ID {message.id} contains an unsupported web page type: {type(webpage)}')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n\n                                # Add to new_messages and skip further processing\n                                new_messages.append(message_data)\n                                continue  # Skip to next message\n\n                            else:\n                                # Unsupported media type\n                                print(f'Message ID {message.id} has unsupported media type: {type(message.media)}')\n                                continue  # Skip this message\n\n                            # Update message data\n                            if media_item:\n                                message_data['media'].append(media_item)\n                                message_data['media_type'] = media_item['media_type']\n\n                        # Group messages by grouped_id if they are part of a media group\n                        if message.grouped_id:\n                            print(f'Message ID {message.id} is part of group {message.grouped_id}')\n                            if message.grouped_id not in media_groups:\n                                # First message in the group; store the text (caption) if available\n                                media_groups[message.grouped_id] = message_data\n                            else:\n                                # Append media to existing group\n                                existing_message = media_groups[message.grouped_id]\n                                existing_message['media'].extend(message_data['media'])\n                                # If the existing message doesn't have text, and current message has text, update it\n                                if not existing_message['text'] and message_data['text']:\n                                    existing_message['text'] = message_data['text']\n                                    print(\n                                        f'Updated text for media group {message.grouped_id}: \"{message_data[\"text\"]}\"')\n                        else:\n                            # Not part of a media group, add as individual message\n                            new_messages.append(message_data)\n\n                        # Update last_message_id\n                        if message.id > self.last_message_id:\n                            self.last_message_id = message.id\n\n                        # Update offset_id for the next batch\n                        offset_id = message.id\n\n                    # Add grouped messages to new_messages\n                    new_messages.extend(media_groups.values())\n\n                    # Sort messages by date (optional)\n                    new_messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    # Update the shared messages list\n                    with self.messages_lock:\n                        self.messages.extend(new_messages)\n                        # Remove duplicates based on message ID\n                        self.messages = list({msg['id']: msg for msg in self.messages}.values())\n                        # Sort messages after merging\n                        self.messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    print(f'Fetched and processed {len(new_messages)} new messages.')\n\n                    # Save messages to file\n                    self.save_messages()\n\n                    # Yield control to the event loop\n                    await asyncio.sleep(1)  # Adjust sleep time as needed\n\n            except Exception as e:\n                print(f'An error occurred in fetch_messages: {e}')\n                traceback.print_exc()\n\n        # Run the async function in the event loop\n        try:\n            loop.run_until_complete(main())\n        finally:\n            # Properly disconnect the client\n            self.client.disconnect()\n            loop.close()\n\n    def get_media_extension(self, message):\n        \"\"\"\n        Get the file extension for the media.\n        \"\"\"\n        if message.photo:\n            return '.jpg'\n        elif message.video:\n            return '.mp4'\n        elif message.document:\n            # Get the extension from the mime type or file name\n            mime_type = message.document.mime_type\n            if mime_type == 'image/jpeg':\n                return '.jpg'\n            elif mime_type == 'image/png':\n                return '.png'\n            elif mime_type == 'video/mp4':\n                return '.mp4'\n            else:\n                # Extract extension from file name\n                if message.file and message.file.name:\n                    return os.path.splitext(message.file.name)[1]\n                else:\n                    return ''\n        else:\n            return ''\n\n    def get_channel_messages(self):\n        with self.messages_lock:\n            return self.messages.copy()\n\n\n# Instantiate the ChannelViewer class\nviewer = ChannelViewer()\n\n\n@app.route('/')\ndef index():\n    print('Received request for /')\n    messages = viewer.get_channel_messages()\n    print(f\"Number of messages to display: {len(messages)}\")\n    return render_template('index.html', messages=messages)\n\n\nif __name__ == '__main__':\n    app.run(debug=True, use_reloader=False)",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 0.9243800546553702,
            "bleu_score": 0.10594277691343595,
            "rougeL_score": 0.0043446777697320775,
            "levenshtein_ratio": 0.18154922001075713
        }
    },
    {
        "id": 13,
        "filename": "1.txt",
        "prefix": "from flask import Flask, render_template\nfrom dotenv import find_dotenv, load_dotenv\nfrom telethon import TelegramClient\nfrom telethon.tl.types import (\n    MessageMediaPhoto,\n    MessageMediaDocument,\n    MessageMediaWebPage,\n    WebPageEmpty,\n    WebPage\n)\n\nimport os\nimport asyncio\nimport threading\nimport traceback\nimport json\n\n# Initialize the Flask app in the global scope\napp = Flask(__name__)\n\n\nclass ChannelViewer:\n    def __init__(self):\n        self.channel_username = 'onlinerby'  # Replace with the target channel's username\n        self.messages = []\n        self.messages_lock = threading.Lock()\n        self.load_environment_variables()\n\n        # Store API credentials\n        self.api_id = os.getenv('API_ID')\n        self.api_hash = os.getenv('API_HASH')\n\n        # Initialize variables\n        self.last_message_id = 0  # To keep track of the last processed message ID\n\n        # Load existing messages from file\n        self.load_messages()\n\n        # Start the background thread\n        self.start_fetching_messages()\n\n    def load_environment_variables(self):\n        \"\"\"\n        Load environment variables from a .env file.\n        \"\"\"\n        try:\n            dotenv_path = find_dotenv()\n            if not dotenv_path:\n       ",
        "actual_middle": "         raise ",
        "generated_middle": "from flask import Flask, render_template\nfrom dotenv import find_dotenv, load_dotenv\nfrom telethon import TelegramClient\nfrom telethon.tl.types import (\n    MessageMediaPhoto,\n    MessageMediaDocument,\n    MessageMediaWebPage,\n    WebPageEmpty,\n    WebPage\n)\n\nimport os\nimport asyncio\nimport threading\nimport traceback\nimport json\n\n# Initialize the Flask app in the global scope\napp = Flask(__name__)\n\n\nclass ChannelViewer:\n    def __init__(self):\n        self.channel_username = 'onlinerby'  # Replace with the target channel's username\n        self.messages = []\n        self.messages_lock = threading.Lock()\n        self.load_environment_variables()\n\n        # Store API credentials\n        self.api_id = os.getenv('API_ID')\n        self.api_hash = os.getenv('API_HASH')\n\n        # Initialize variables\n        self.last_message_id = 0  # To keep track of the last processed message ID\n\n        # Load existing messages from file\n        self.load_messages()\n\n        # Start the background thread\n        self.start_fetching_messages()\n\n    def load_environment_variables(self):\n        \"\"\"\n        Load environment variables from a .env file.\n        \"\"\"\n        try:\n            dotenv_path = find_dotenv()\n            if not dotenv_path:\n       FileNotFoundError(\".env file not found\")\n            load_dotenv(dotenv_path)\n            print(f\"Environment variables loaded from {dotenv_path}\")\n        except Exception as e:\n            print(f\"Error loading .env file: {e}\")\n            raise\n\n    def load_messages(self):\n        \"\"\"\n        Load messages from 'messages.json' if it exists.\n        \"\"\"\n        try:\n            with open('messages.json', 'r', encoding='utf-8') as f:\n                self.messages = json.load(f)\n            if self.messages:\n                # Update last_message_id with the highest message ID\n                self.last_message_id = max(msg['id'] for msg in self.messages)\n            print(f\"Loaded {len(self.messages)} messages from messages.json.\")\n        except FileNotFoundError:\n            print(\"messages.json not found. Starting with an empty message list.\")\n        except Exception as e:\n            print(f\"Error loading messages: {e}\")\n\n    def save_messages(self):\n        \"\"\"\n        Save messages to 'messages.json'.\n        \"\"\"\n        try:\n            with open('messages.json', 'w', encoding='utf-8') as f:\n                json.dump(self.messages, f, ensure_ascii=False, indent=4)\n            print(f\"Saved {len(self.messages)} messages to messages.json.\")\n        except Exception as e:\n            print(f\"Error saving messages: {e}\")\n\n    def start_fetching_messages(self):\n        print('Starting background thread to fetch messages.')\n        fetch_thread = threading.Thread(target=self.fetch_messages)\n        fetch_thread.daemon = True  # Daemonize thread to exit when main program exits\n        fetch_thread.start()\n        print('Background thread started.')\n\n    def fetch_messages(self):\n        print('fetch_messages: Started fetching messages.')\n        # Set up a new event loop for this thread\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n\n        async def main():\n            try:\n                print('fetch_messages: Starting main function.')\n\n                # Initialize the Telegram client in this thread's event loop\n                self.client = TelegramClient('session_name', self.api_id, self.api_hash, loop=loop)\n\n                # Start the client (connect and authenticate)\n                await self.client.start()\n                print('Telegram client started in background thread.')\n\n                # Initialize variables\n                offset_id = 0  # Start from the latest message\n                limit = 50  # Number of messages to fetch in each batch\n\n                while True:\n                    print('Fetching new messages...')\n                    new_messages = []\n                    media_groups = {}\n\n                    # Fetch messages in batches\n                    messages = await self.client.get_messages(\n                        self.channel_username,\n                        limit=limit,\n                        offset_id=offset_id\n                    )\n\n                    if not messages:\n                        print('No new messages found.')\n                        await asyncio.sleep(5)  # Wait before checking again\n                        continue\n\n                    for message in reversed(messages):  # Process from oldest to newest\n                        print(f'Processing message ID {message.id}')\n                        message_data = {\n                            'id': message.id,\n                            'text': message.text or '',\n                            'date': message.date.strftime('%Y-%m-%d %H:%M:%S'),\n                            'sender': message.sender_id,\n                            'media': [],\n                            'media_type': None,\n                            'grouped_id': message.grouped_id,\n                        }\n\n                        # Check if the message has media\n                        if message.media:\n                            print(f'Message ID {message.id} has media.')\n                            # Ensure the directory exists\n                            media_dir = 'static/media/'\n                            os.makedirs(media_dir, exist_ok=True)\n\n                            # Initialize variables\n                            media_filename = None\n                            media_item = {}\n\n                            # Handle different media types\n                            if isinstance(message.media, MessageMediaPhoto):\n                                # For photos\n                                file_extension = '.jpg'\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded photo for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Photo for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'photo',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaDocument):\n                                # For documents (including videos, audio, etc.)\n                                file_extension = self.get_media_extension(message)\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded document for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Document for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'document',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaWebPage):\n                                # Handle web page previews\n                                print(f'Message ID {message.id} contains a web page preview.')\n                                webpage = message.media.webpage\n\n                                if isinstance(webpage, WebPage):\n                                    # Full web page preview\n                                    message_data['webpage'] = {\n                                        'url': webpage.url,\n                                        'title': getattr(webpage, 'title', ''),\n                                        'description': getattr(webpage, 'description', '')\n                                    }\n                                    print(\n                                        f\"Extracted webpage info for message ID {message.id}: {message_data['webpage']}\")\n                                elif isinstance(webpage, WebPageEmpty):\n                                    # Empty web page preview\n                                    print(f'Message ID {message.id} contains an empty web page preview.')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n                                else:\n                                    # Other web page types\n                                    print(\n                                        f'Message ID {message.id} contains an unsupported web page type: {type(webpage)}')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n\n                                # Add to new_messages and skip further processing\n                                new_messages.append(message_data)\n                                continue  # Skip to next message\n\n                            else:\n                                # Unsupported media type\n                                print(f'Message ID {message.id} has unsupported media type: {type(message.media)}')\n                                continue  # Skip this message\n\n                            # Update message data\n                            if media_item:\n                                message_data['media'].append(media_item)\n                                message_data['media_type'] = media_item['media_type']\n\n                        # Group messages by grouped_id if they are part of a media group\n                        if message.grouped_id:\n                            print(f'Message ID {message.id} is part of group {message.grouped_id}')\n                            if message.grouped_id not in media_groups:\n                                # First message in the group; store the text (caption) if available\n                                media_groups[message.grouped_id] = message_data\n                            else:\n                                # Append media to existing group\n                                existing_message = media_groups[message.grouped_id]\n                                existing_message['media'].extend(message_data['media'])\n                                # If the existing message doesn't have text, and current message has text, update it\n                                if not existing_message['text'] and message_data['text']:\n                                    existing_message['text'] = message_data['text']\n                                    print(\n                                        f'Updated text for media group {message.grouped_id}: \"{message_data[\"text\"]}\"')\n                        else:\n                            # Not part of a media group, add as individual message\n                            new_messages.append(message_data)\n\n                        # Update last_message_id\n                        if message.id > self.last_message_id:\n                            self.last_message_id = message.id\n\n                        # Update offset_id for the next batch\n                        offset_id = message.id\n\n                    # Add grouped messages to new_messages\n                    new_messages.extend(media_groups.values())\n\n                    # Sort messages by date (optional)\n                    new_messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    # Update the shared messages list\n                    with self.messages_lock:\n                        self.messages.extend(new_messages)\n                        # Remove duplicates based on message ID\n                        self.messages = list({msg['id']: msg for msg in self.messages}.values())\n                        # Sort messages after merging\n                        self.messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    print(f'Fetched and processed {len(new_messages)} new messages.')\n\n                    # Save messages to file\n                    self.save_messages()\n\n                    # Yield control to the event loop\n                    await asyncio.sleep(1)  # Adjust sleep time as needed\n\n            except Exception as e:\n                print(f'An error occurred in fetch_messages: {e}')\n                traceback.print_exc()\n\n        # Run the async function in the event loop\n        try:\n            loop.run_until_complete(main())\n        finally:\n            # Properly disconnect the client\n            self.client.disconnect()\n            loop.close()\n\n    def get_media_extension(self, message):\n        \"\"\"\n        Get the file extension for the media.\n        \"\"\"\n        if message.photo:\n            return '.jpg'\n        elif message.video:\n            return '.mp4'\n        elif message.document:\n            # Get the extension from the mime type or file name\n            mime_type = message.document.mime_type\n            if mime_type == 'image/jpeg':\n                return '.jpg'\n            elif mime_type == 'image/png':\n                return '.png'\n            elif mime_type == 'video/mp4':\n                return '.mp4'\n            else:\n                # Extract extension from file name\n                if message.file and message.file.name:\n                    return os.path.splitext(message.file.name)[1]\n                else:\n                    return ''\n        else:\n            return ''\n\n    def get_channel_messages(self):\n        with self.messages_lock:\n            return self.messages.copy()\n\n\n# Instantiate the ChannelViewer class\nviewer = ChannelViewer()\n\n\n@app.route('/')\ndef index():\n    print('Received request for /')\n    messages = viewer.get_channel_messages()\n    print(f\"Number of messages to display: {len(messages)}\")\n    return render_template('index.html', messages=messages)\n\n\nif __name__ == '__main__':\n    app.run(debug=True, use_reloader=False)         print(\"Missing .env file\")\n                raise EnvironmentError\n            self.load_dotenv(dotenv",
        "suffix": "FileNotFoundError(\".env file not found\")\n            load_dotenv(dotenv_path)\n            print(f\"Environment variables loaded from {dotenv_path}\")\n        except Exception as e:\n            print(f\"Error loading .env file: {e}\")\n            raise\n\n    def load_messages(self):\n        \"\"\"\n        Load messages from 'messages.json' if it exists.\n        \"\"\"\n        try:\n            with open('messages.json', 'r', encoding='utf-8') as f:\n                self.messages = json.load(f)\n            if self.messages:\n                # Update last_message_id with the highest message ID\n                self.last_message_id = max(msg['id'] for msg in self.messages)\n            print(f\"Loaded {len(self.messages)} messages from messages.json.\")\n        except FileNotFoundError:\n            print(\"messages.json not found. Starting with an empty message list.\")\n        except Exception as e:\n            print(f\"Error loading messages: {e}\")\n\n    def save_messages(self):\n        \"\"\"\n        Save messages to 'messages.json'.\n        \"\"\"\n        try:\n            with open('messages.json', 'w', encoding='utf-8') as f:\n                json.dump(self.messages, f, ensure_ascii=False, indent=4)\n            print(f\"Saved {len(self.messages)} messages to messages.json.\")\n        except Exception as e:\n            print(f\"Error saving messages: {e}\")\n\n    def start_fetching_messages(self):\n        print('Starting background thread to fetch messages.')\n        fetch_thread = threading.Thread(target=self.fetch_messages)\n        fetch_thread.daemon = True  # Daemonize thread to exit when main program exits\n        fetch_thread.start()\n        print('Background thread started.')\n\n    def fetch_messages(self):\n        print('fetch_messages: Started fetching messages.')\n        # Set up a new event loop for this thread\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n\n        async def main():\n            try:\n                print('fetch_messages: Starting main function.')\n\n                # Initialize the Telegram client in this thread's event loop\n                self.client = TelegramClient('session_name', self.api_id, self.api_hash, loop=loop)\n\n                # Start the client (connect and authenticate)\n                await self.client.start()\n                print('Telegram client started in background thread.')\n\n                # Initialize variables\n                offset_id = 0  # Start from the latest message\n                limit = 50  # Number of messages to fetch in each batch\n\n                while True:\n                    print('Fetching new messages...')\n                    new_messages = []\n                    media_groups = {}\n\n                    # Fetch messages in batches\n                    messages = await self.client.get_messages(\n                        self.channel_username,\n                        limit=limit,\n                        offset_id=offset_id\n                    )\n\n                    if not messages:\n                        print('No new messages found.')\n                        await asyncio.sleep(5)  # Wait before checking again\n                        continue\n\n                    for message in reversed(messages):  # Process from oldest to newest\n                        print(f'Processing message ID {message.id}')\n                        message_data = {\n                            'id': message.id,\n                            'text': message.text or '',\n                            'date': message.date.strftime('%Y-%m-%d %H:%M:%S'),\n                            'sender': message.sender_id,\n                            'media': [],\n                            'media_type': None,\n                            'grouped_id': message.grouped_id,\n                        }\n\n                        # Check if the message has media\n                        if message.media:\n                            print(f'Message ID {message.id} has media.')\n                            # Ensure the directory exists\n                            media_dir = 'static/media/'\n                            os.makedirs(media_dir, exist_ok=True)\n\n                            # Initialize variables\n                            media_filename = None\n                            media_item = {}\n\n                            # Handle different media types\n                            if isinstance(message.media, MessageMediaPhoto):\n                                # For photos\n                                file_extension = '.jpg'\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded photo for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Photo for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'photo',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaDocument):\n                                # For documents (including videos, audio, etc.)\n                                file_extension = self.get_media_extension(message)\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded document for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Document for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'document',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaWebPage):\n                                # Handle web page previews\n                                print(f'Message ID {message.id} contains a web page preview.')\n                                webpage = message.media.webpage\n\n                                if isinstance(webpage, WebPage):\n                                    # Full web page preview\n                                    message_data['webpage'] = {\n                                        'url': webpage.url,\n                                        'title': getattr(webpage, 'title', ''),\n                                        'description': getattr(webpage, 'description', '')\n                                    }\n                                    print(\n                                        f\"Extracted webpage info for message ID {message.id}: {message_data['webpage']}\")\n                                elif isinstance(webpage, WebPageEmpty):\n                                    # Empty web page preview\n                                    print(f'Message ID {message.id} contains an empty web page preview.')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n                                else:\n                                    # Other web page types\n                                    print(\n                                        f'Message ID {message.id} contains an unsupported web page type: {type(webpage)}')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n\n                                # Add to new_messages and skip further processing\n                                new_messages.append(message_data)\n                                continue  # Skip to next message\n\n                            else:\n                                # Unsupported media type\n                                print(f'Message ID {message.id} has unsupported media type: {type(message.media)}')\n                                continue  # Skip this message\n\n                            # Update message data\n                            if media_item:\n                                message_data['media'].append(media_item)\n                                message_data['media_type'] = media_item['media_type']\n\n                        # Group messages by grouped_id if they are part of a media group\n                        if message.grouped_id:\n                            print(f'Message ID {message.id} is part of group {message.grouped_id}')\n                            if message.grouped_id not in media_groups:\n                                # First message in the group; store the text (caption) if available\n                                media_groups[message.grouped_id] = message_data\n                            else:\n                                # Append media to existing group\n                                existing_message = media_groups[message.grouped_id]\n                                existing_message['media'].extend(message_data['media'])\n                                # If the existing message doesn't have text, and current message has text, update it\n                                if not existing_message['text'] and message_data['text']:\n                                    existing_message['text'] = message_data['text']\n                                    print(\n                                        f'Updated text for media group {message.grouped_id}: \"{message_data[\"text\"]}\"')\n                        else:\n                            # Not part of a media group, add as individual message\n                            new_messages.append(message_data)\n\n                        # Update last_message_id\n                        if message.id > self.last_message_id:\n                            self.last_message_id = message.id\n\n                        # Update offset_id for the next batch\n                        offset_id = message.id\n\n                    # Add grouped messages to new_messages\n                    new_messages.extend(media_groups.values())\n\n                    # Sort messages by date (optional)\n                    new_messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    # Update the shared messages list\n                    with self.messages_lock:\n                        self.messages.extend(new_messages)\n                        # Remove duplicates based on message ID\n                        self.messages = list({msg['id']: msg for msg in self.messages}.values())\n                        # Sort messages after merging\n                        self.messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    print(f'Fetched and processed {len(new_messages)} new messages.')\n\n                    # Save messages to file\n                    self.save_messages()\n\n                    # Yield control to the event loop\n                    await asyncio.sleep(1)  # Adjust sleep time as needed\n\n            except Exception as e:\n                print(f'An error occurred in fetch_messages: {e}')\n                traceback.print_exc()\n\n        # Run the async function in the event loop\n        try:\n            loop.run_until_complete(main())\n        finally:\n            # Properly disconnect the client\n            self.client.disconnect()\n            loop.close()\n\n    def get_media_extension(self, message):\n        \"\"\"\n        Get the file extension for the media.\n        \"\"\"\n        if message.photo:\n            return '.jpg'\n        elif message.video:\n            return '.mp4'\n        elif message.document:\n            # Get the extension from the mime type or file name\n            mime_type = message.document.mime_type\n            if mime_type == 'image/jpeg':\n                return '.jpg'\n            elif mime_type == 'image/png':\n                return '.png'\n            elif mime_type == 'video/mp4':\n                return '.mp4'\n            else:\n                # Extract extension from file name\n                if message.file and message.file.name:\n                    return os.path.splitext(message.file.name)[1]\n                else:\n                    return ''\n        else:\n            return ''\n\n    def get_channel_messages(self):\n        with self.messages_lock:\n            return self.messages.copy()\n\n\n# Instantiate the ChannelViewer class\nviewer = ChannelViewer()\n\n\n@app.route('/')\ndef index():\n    print('Received request for /')\n    messages = viewer.get_channel_messages()\n    print(f\"Number of messages to display: {len(messages)}\")\n    return render_template('index.html', messages=messages)\n\n\nif __name__ == '__main__':\n    app.run(debug=True, use_reloader=False)",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 0.1817374137924181,
            "bleu_score": 0.01421320306753139,
            "rougeL_score": 0.0014482259232440262,
            "levenshtein_ratio": 0.10061711832572984
        }
    },
    {
        "id": 14,
        "filename": "1.txt",
        "prefix": "from flask import Flask, render_template\nfrom dotenv import find_dotenv, load_dotenv\nfrom telethon import TelegramClient\nfrom telethon.tl.types import (\n    MessageMediaPhoto,\n    MessageMediaDocument,\n    MessageMediaWebPage,\n    WebPageEmpty,\n    WebPage\n)\n\nimport os\nimport asyncio\nimport threading\nimport traceback\nimport json\n\n# Initialize the Flask app in the global scope\napp = Flask(__name__)\n\n\nclass ChannelViewer:\n    def __init__(self):\n        self.channel_username = 'onlinerby'  # Replace with the target channel's username\n        self.messages = []\n        self.messages_lock = threading.Lock()\n        self.load_environment_variables()\n\n        # Store API credentials\n        self.api_id = os.getenv('API_ID')\n        self.api_hash = os.getenv('API_HASH')\n\n        # Initialize variables\n        self.last_message_id = 0  # To keep track of the last processed message ID\n\n        # Load existing messages from file\n        self.load_messages()\n\n        # Start the background thread\n        self.start_fetching_messages()\n\n    def load_environment_variables(self):\n        \"\"\"\n        Load environment variables from a .env file.\n        \"\"\"\n        try:\n            dotenv_path = find_dotenv()\n            if not dotenv_path:\n                raise FileNotFoundError(\".env file not found\")\n            load_dotenv(dotenv_path)\n            print(f\"Environment variables loaded from {dotenv_path}\")\n        except Exception as e:\n            print(f\"Error loading .env file: {e}\")\n            raise\n\n    def load_messages(self):\n        \"\"\"\n        Load messages from 'messages.json' if it exists.\n        \"\"\"\n        try:\n            with open('messages.json', 'r', encoding='utf-8') as f:\n                self.messages = json.load(f)\n            if self.messages:\n                # Update last_message_id with the highest message ID\n                self.last_message_id = max(msg['id'] for msg in self.messages)\n            print(f\"Loaded {len(self.messages)} messages from messages.json.\")\n        except FileNotFoundError:\n            print(\"messages.json not found. Starting with an empty message list.\")\n        except Exception as e:\n            print(f\"Error loading messages: {e}\")\n\n    def save_messages(self):\n        \"\"\"\n        Save messages to 'messages.json'.\n        \"\"\"\n        try:\n            with open('messages.json', 'w', encoding='utf-8') as f:\n                json.dump(self.messages, f, ensure_ascii=False, indent=4)\n            print(f\"Saved {len(self.messages)} messages to messages.json.\")\n        except Exception as e:\n            print(f\"Error saving messages: {e}\")\n\n    def start_fetching_messages(self):\n        print('Starting background thread to fetch messages.')\n        fetch_thread = threading.Thread(target=self.fetch_messages)\n        fetch_thread.daemon = True  # Daemonize thread to exit when main program exits\n        fetch_thread.start()\n        print('Background thread started.')\n\n    def fetch_messages(self):\n        print('fetch_messages: Started fetching messages.')\n        # Set up a new event loop for this thread\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n\n        async def main():\n            try:\n                print('fetch_messages: Starting main function.')\n\n                # Initialize the Telegram client in this thread's event loop\n                self.client = TelegramClient('session_name', self.api_id, self.api_hash, loop=loop)\n\n                # Start the client (connect and authenticate)\n                await self.client.start()\n                print('Telegram client started in background thread.')\n\n                # Initialize variables\n                offset_id = 0  # Start from the latest message\n                limit = 50  # Number of messages to fetch in each batch\n\n                while True:\n                    print('Fetching new messages...')\n                    new_messages = []\n                    media_groups = {}\n\n                    # Fetch messages in batches\n                    messages = await self.client.get_messages(\n                        self.channel_username,\n                        limit=limit,\n                        offset_id=offset_id\n                    )\n\n                    if not messages:\n                        print('No new messages found.')\n                        await asyncio.sleep(5)  # Wait before checking again\n                        continue\n\n                    for message in reversed(messages):  # Process from oldest to newest\n                        print(f'Processing message ID {message.id}')\n                        message_data = {\n                            'id': message.id,\n                            'text': message.text or '',\n                            'date': message.date.strftime('%Y-%m-%d %H:%M:%S'),\n                            'sender': message.sender_id,\n                            'media': [],\n                            'media_type': None,\n                            'grouped_id': message.grouped_id,\n                        }\n\n                        # Check if the message has media\n                        if message.media:\n                            print(f'Message ID {message.id} has media.')\n                            # Ensure the directory exists\n                            media_dir = 'static/media/'\n                            os.makedirs(media_dir, exist_ok=True)\n\n                            # Initialize variables\n                            media_filename = None\n                            media_item = {}\n\n                            # Handle different media types\n                            if isinstance(message.media, MessageMediaPhoto):\n                                # For photos\n                                file_extension = '.jpg'\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded photo for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Photo for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'photo',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaDocument):\n                                # For documents (including videos, audio, etc.)\n                                file_extension = self.get_media_extension(message)\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded document for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Document for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'document',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaWebPage):\n                                # Handle web page previews\n                                print(f'Message ID {message.id} contains a web page preview.')\n                                webpage = message.media.webpage\n\n                                if isinstance(webpage, WebPage):\n                                    # Full web page preview\n                                    message_data['webpage'] = {\n                                        'url': webpage.url,\n                                        'title': getattr(webpage, 'title', ''),\n                                        'description': getattr(webpage, 'description', '')\n                                    }\n                                    print(\n                                        f\"Extracted webpage info for message ID {message.id}: {message_data['webpage']}\")",
        "actual_middle": "\n                        ",
        "generated_middle": "from flask import Flask, render_template\nfrom dotenv import find_dotenv, load_dotenv\nfrom telethon import TelegramClient\nfrom telethon.tl.types import (\n    MessageMediaPhoto,\n    MessageMediaDocument,\n    MessageMediaWebPage,\n    WebPageEmpty,\n    WebPage\n)\n\nimport os\nimport asyncio\nimport threading\nimport traceback\nimport json\n\n# Initialize the Flask app in the global scope\napp = Flask(__name__)\n\n\nclass ChannelViewer:\n    def __init__(self):\n        self.channel_username = 'onlinerby'  # Replace with the target channel's username\n        self.messages = []\n        self.messages_lock = threading.Lock()\n        self.load_environment_variables()\n\n        # Store API credentials\n        self.api_id = os.getenv('API_ID')\n        self.api_hash = os.getenv('API_HASH')\n\n        # Initialize variables\n        self.last_message_id = 0  # To keep track of the last processed message ID\n\n        # Load existing messages from file\n        self.load_messages()\n\n        # Start the background thread\n        self.start_fetching_messages()\n\n    def load_environment_variables(self):\n        \"\"\"\n        Load environment variables from a .env file.\n        \"\"\"\n        try:\n            dotenv_path = find_dotenv()\n            if not dotenv_path:\n                raise FileNotFoundError(\".env file not found\")\n            load_dotenv(dotenv_path)\n            print(f\"Environment variables loaded from {dotenv_path}\")\n        except Exception as e:\n            print(f\"Error loading .env file: {e}\")\n            raise\n\n    def load_messages(self):\n        \"\"\"\n        Load messages from 'messages.json' if it exists.\n        \"\"\"\n        try:\n            with open('messages.json', 'r', encoding='utf-8') as f:\n                self.messages = json.load(f)\n            if self.messages:\n                # Update last_message_id with the highest message ID\n                self.last_message_id = max(msg['id'] for msg in self.messages)\n            print(f\"Loaded {len(self.messages)} messages from messages.json.\")\n        except FileNotFoundError:\n            print(\"messages.json not found. Starting with an empty message list.\")\n        except Exception as e:\n            print(f\"Error loading messages: {e}\")\n\n    def save_messages(self):\n        \"\"\"\n        Save messages to 'messages.json'.\n        \"\"\"\n        try:\n            with open('messages.json', 'w', encoding='utf-8') as f:\n                json.dump(self.messages, f, ensure_ascii=False, indent=4)\n            print(f\"Saved {len(self.messages)} messages to messages.json.\")\n        except Exception as e:\n            print(f\"Error saving messages: {e}\")\n\n    def start_fetching_messages(self):\n        print('Starting background thread to fetch messages.')\n        fetch_thread = threading.Thread(target=self.fetch_messages)\n        fetch_thread.daemon = True  # Daemonize thread to exit when main program exits\n        fetch_thread.start()\n        print('Background thread started.')\n\n    def fetch_messages(self):\n        print('fetch_messages: Started fetching messages.')\n        # Set up a new event loop for this thread\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n\n        async def main():\n            try:\n                print('fetch_messages: Starting main function.')\n\n                # Initialize the Telegram client in this thread's event loop\n                self.client = TelegramClient('session_name', self.api_id, self.api_hash, loop=loop)\n\n                # Start the client (connect and authenticate)\n                await self.client.start()\n                print('Telegram client started in background thread.')\n\n                # Initialize variables\n                offset_id = 0  # Start from the latest message\n                limit = 50  # Number of messages to fetch in each batch\n\n                while True:\n                    print('Fetching new messages...')\n                    new_messages = []\n                    media_groups = {}\n\n                    # Fetch messages in batches\n                    messages = await self.client.get_messages(\n                        self.channel_username,\n                        limit=limit,\n                        offset_id=offset_id\n                    )\n\n                    if not messages:\n                        print('No new messages found.')\n                        await asyncio.sleep(5)  # Wait before checking again\n                        continue\n\n                    for message in reversed(messages):  # Process from oldest to newest\n                        print(f'Processing message ID {message.id}')\n                        message_data = {\n                            'id': message.id,\n                            'text': message.text or '',\n                            'date': message.date.strftime('%Y-%m-%d %H:%M:%S'),\n                            'sender': message.sender_id,\n                            'media': [],\n                            'media_type': None,\n                            'grouped_id': message.grouped_id,\n                        }\n\n                        # Check if the message has media\n                        if message.media:\n                            print(f'Message ID {message.id} has media.')\n                            # Ensure the directory exists\n                            media_dir = 'static/media/'\n                            os.makedirs(media_dir, exist_ok=True)\n\n                            # Initialize variables\n                            media_filename = None\n                            media_item = {}\n\n                            # Handle different media types\n                            if isinstance(message.media, MessageMediaPhoto):\n                                # For photos\n                                file_extension = '.jpg'\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded photo for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Photo for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'photo',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaDocument):\n                                # For documents (including videos, audio, etc.)\n                                file_extension = self.get_media_extension(message)\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded document for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Document for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'document',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaWebPage):\n                                # Handle web page previews\n                                print(f'Message ID {message.id} contains a web page preview.')\n                                webpage = message.media.webpage\n\n                                if isinstance(webpage, WebPage):\n                                    # Full web page preview\n                                    message_data['webpage'] = {\n                                        'url': webpage.url,\n                                        'title': getattr(webpage, 'title', ''),\n                                        'description': getattr(webpage, 'description', '')\n                                    }\n                                    print(\n                                        f\"Extracted webpage info for message ID {message.id}: {message_data['webpage']}\")        elif isinstance(webpage, WebPageEmpty):\n                                    # Empty web page preview\n                                    print(f'Message ID {message.id} contains an empty web page preview.')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n                                else:\n                                    # Other web page types\n                                    print(\n                                        f'Message ID {message.id} contains an unsupported web page type: {type(webpage)}')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n\n                                # Add to new_messages and skip further processing\n                                new_messages.append(message_data)\n                                continue  # Skip to next message\n\n                            else:\n                                # Unsupported media type\n                                print(f'Message ID {message.id} has unsupported media type: {type(message.media)}')\n                                continue  # Skip this message\n\n                            # Update message data\n                            if media_item:\n                                message_data['media'].append(media_item)\n                                message_data['media_type'] = media_item['media_type']\n\n                        # Group messages by grouped_id if they are part of a media group\n                        if message.grouped_id:\n                            print(f'Message ID {message.id} is part of group {message.grouped_id}')\n                            if message.grouped_id not in media_groups:\n                                # First message in the group; store the text (caption) if available\n                                media_groups[message.grouped_id] = message_data\n                            else:\n                                # Append media to existing group\n                                existing_message = media_groups[message.grouped_id]\n                                existing_message['media'].extend(message_data['media'])\n                                # If the existing message doesn't have text, and current message has text, update it\n                                if not existing_message['text'] and message_data['text']:\n                                    existing_message['text'] = message_data['text']\n                                    print(\n                                        f'Updated text for media group {message.grouped_id}: \"{message_data[\"text\"]}\"')\n                        else:\n                            # Not part of a media group, add as individual message\n                            new_messages.append(message_data)\n\n                        # Update last_message_id\n                        if message.id > self.last_message_id:\n                            self.last_message_id = message.id\n\n                        # Update offset_id for the next batch\n                        offset_id = message.id\n\n                    # Add grouped messages to new_messages\n                    new_messages.extend(media_groups.values())\n\n                    # Sort messages by date (optional)\n                    new_messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    # Update the shared messages list\n                    with self.messages_lock:\n                        self.messages.extend(new_messages)\n                        # Remove duplicates based on message ID\n                        self.messages = list({msg['id']: msg for msg in self.messages}.values())\n                        # Sort messages after merging\n                        self.messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    print(f'Fetched and processed {len(new_messages)} new messages.')\n\n                    # Save messages to file\n                    self.save_messages()\n\n                    # Yield control to the event loop\n                    await asyncio.sleep(1)  # Adjust sleep time as needed\n\n            except Exception as e:\n                print(f'An error occurred in fetch_messages: {e}')\n                traceback.print_exc()\n\n        # Run the async function in the event loop\n        try:\n            loop.run_until_complete(main())\n        finally:\n            # Properly disconnect the client\n            self.client.disconnect()\n            loop.close()\n\n    def get_media_extension(self, message):\n        \"\"\"\n        Get the file extension for the media.\n        \"\"\"\n        if message.photo:\n            return '.jpg'\n        elif message.video:\n            return '.mp4'\n        elif message.document:\n            # Get the extension from the mime type or file name\n            mime_type = message.document.mime_type\n            if mime_type == 'image/jpeg':\n                return '.jpg'\n            elif mime_type == 'image/png':\n                return '.png'\n            elif mime_type == 'video/mp4':\n                return '.mp4'\n            else:\n                # Extract extension from file name\n                if message.file and message.file.name:\n                    return os.path.splitext(message.file.name)[1]\n                else:\n                    return ''\n        else:\n            return ''\n\n    def get_channel_messages(self):\n        with self.messages_lock:\n            return self.messages.copy()\n\n\n# Instantiate the ChannelViewer class\nviewer = ChannelViewer()\n\n\n@app.route('/')\ndef index():\n    print('Received request for /')\n    messages = viewer.get_channel_messages()\n    print(f\"Number of messages to display: {len(messages)}\")\n    return render_template('index.html', messages=messages)\n\n\nif __name__ == '__main__':\n    app.run(debug=True, use_reloader=False)\n                                    media_item = {'file_path': file_path, 'media_type': '",
        "suffix": "        elif isinstance(webpage, WebPageEmpty):\n                                    # Empty web page preview\n                                    print(f'Message ID {message.id} contains an empty web page preview.')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n                                else:\n                                    # Other web page types\n                                    print(\n                                        f'Message ID {message.id} contains an unsupported web page type: {type(webpage)}')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n\n                                # Add to new_messages and skip further processing\n                                new_messages.append(message_data)\n                                continue  # Skip to next message\n\n                            else:\n                                # Unsupported media type\n                                print(f'Message ID {message.id} has unsupported media type: {type(message.media)}')\n                                continue  # Skip this message\n\n                            # Update message data\n                            if media_item:\n                                message_data['media'].append(media_item)\n                                message_data['media_type'] = media_item['media_type']\n\n                        # Group messages by grouped_id if they are part of a media group\n                        if message.grouped_id:\n                            print(f'Message ID {message.id} is part of group {message.grouped_id}')\n                            if message.grouped_id not in media_groups:\n                                # First message in the group; store the text (caption) if available\n                                media_groups[message.grouped_id] = message_data\n                            else:\n                                # Append media to existing group\n                                existing_message = media_groups[message.grouped_id]\n                                existing_message['media'].extend(message_data['media'])\n                                # If the existing message doesn't have text, and current message has text, update it\n                                if not existing_message['text'] and message_data['text']:\n                                    existing_message['text'] = message_data['text']\n                                    print(\n                                        f'Updated text for media group {message.grouped_id}: \"{message_data[\"text\"]}\"')\n                        else:\n                            # Not part of a media group, add as individual message\n                            new_messages.append(message_data)\n\n                        # Update last_message_id\n                        if message.id > self.last_message_id:\n                            self.last_message_id = message.id\n\n                        # Update offset_id for the next batch\n                        offset_id = message.id\n\n                    # Add grouped messages to new_messages\n                    new_messages.extend(media_groups.values())\n\n                    # Sort messages by date (optional)\n                    new_messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    # Update the shared messages list\n                    with self.messages_lock:\n                        self.messages.extend(new_messages)\n                        # Remove duplicates based on message ID\n                        self.messages = list({msg['id']: msg for msg in self.messages}.values())\n                        # Sort messages after merging\n                        self.messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    print(f'Fetched and processed {len(new_messages)} new messages.')\n\n                    # Save messages to file\n                    self.save_messages()\n\n                    # Yield control to the event loop\n                    await asyncio.sleep(1)  # Adjust sleep time as needed\n\n            except Exception as e:\n                print(f'An error occurred in fetch_messages: {e}')\n                traceback.print_exc()\n\n        # Run the async function in the event loop\n        try:\n            loop.run_until_complete(main())\n        finally:\n            # Properly disconnect the client\n            self.client.disconnect()\n            loop.close()\n\n    def get_media_extension(self, message):\n        \"\"\"\n        Get the file extension for the media.\n        \"\"\"\n        if message.photo:\n            return '.jpg'\n        elif message.video:\n            return '.mp4'\n        elif message.document:\n            # Get the extension from the mime type or file name\n            mime_type = message.document.mime_type\n            if mime_type == 'image/jpeg':\n                return '.jpg'\n            elif mime_type == 'image/png':\n                return '.png'\n            elif mime_type == 'video/mp4':\n                return '.mp4'\n            else:\n                # Extract extension from file name\n                if message.file and message.file.name:\n                    return os.path.splitext(message.file.name)[1]\n                else:\n                    return ''\n        else:\n            return ''\n\n    def get_channel_messages(self):\n        with self.messages_lock:\n            return self.messages.copy()\n\n\n# Instantiate the ChannelViewer class\nviewer = ChannelViewer()\n\n\n@app.route('/')\ndef index():\n    print('Received request for /')\n    messages = viewer.get_channel_messages()\n    print(f\"Number of messages to display: {len(messages)}\")\n    return render_template('index.html', messages=messages)\n\n\nif __name__ == '__main__':\n    app.run(debug=True, use_reloader=False)",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 0.0,
            "bleu_score": 0.0,
            "rougeL_score": 0,
            "levenshtein_ratio": 0.1680333378142218
        }
    },
    {
        "id": 15,
        "filename": "1.txt",
        "prefix": "from flask import Flask, render_template\nfrom dotenv import find_dotenv, load_dotenv\nfrom telethon import TelegramClient\nfrom telethon.tl.types import (\n    MessageMediaPhoto,\n    MessageMediaDocument,\n    MessageMediaWebPage,\n    WebPageEmpty,\n    WebPage\n)\n\nimport os\nimport asyncio\nimport threading\nimport traceback\nimport json\n\n# Initialize the Flask app in the global scope\napp = Flask(__name__)\n\n\nclass ChannelViewer:\n    def __init__(self):\n        self.channel_username = 'onlinerby'  # Replace with the target channel's username\n        self.messages = []\n        self.messages_lock = threading.Lock()\n        self.load_environment_variables()\n\n        # Store API credentials\n        self.api_id = os.getenv('API_ID')\n        self.api_hash = os.getenv('API_HASH')\n\n        # Initialize variables\n        self.last_message_id = 0  # To keep track of the last processed message ID\n\n        # Load existing messages from file\n        self.load_messages()\n\n        # Start the background thread\n        self.start_fetching_messages()\n\n    def load_environment_variables(self):\n        \"\"\"\n        Load environment variables from a .env file.\n        \"\"\"\n        try:\n            dotenv_path = find_dotenv()\n            if not dotenv_path:\n                raise FileNotFoundError(\".env file not found\")\n            load_dotenv(dotenv_path)\n            print(f\"Environment variables loaded from {dotenv_path}\")\n        except Exception as e:\n            print(f\"Error loading .env file: {e}\")\n            raise\n\n    def load_messages(self):\n        \"\"\"\n        Load messages from 'messages.json' if it exists.\n        \"\"\"\n        try:\n            with open('messages.json', 'r', encoding='utf-8') as f:\n                self.messages = json.load(f)\n            if self.messages:\n                # Update last_message_id with the highest message ID\n                self.last_message_id = max(msg['id'] for msg in self.messages)\n            print(f\"Loaded {len(self.messages)} messages from messages.json.\")\n        except FileNotFoundError:\n            print(\"messages.json not found. Starting with an empty message list.\")\n        except Exception as e:\n            print(f\"Error loading messages: {e}\")\n\n    def save_messages(self):\n        \"\"\"\n        Save messages to 'messages.json'.\n        \"\"\"\n        try:\n            with open('messages.json', 'w', encoding='utf-8') as f:\n                json.dump(self.messages, f, ensure_ascii=False, indent=4)\n            print(f\"Saved {len(self.messages)} messages to messages.json.\")\n        except Exception as e:\n            print(f\"Error saving messages: {e}\")\n\n    def start_fetching_messages(self):\n        print('Starting background thread to fetch messages.')\n        fetch_thread = threading.Thread(target=self.fetch_messages)\n        fetch_thread.daemon = True  # Daemonize thread to exit when main program exits\n        fetch_thread.start()\n        print('Background thread started.')\n\n    def fetch_messages(self):\n        print('fetch_messages: Started fetching messages.')\n        # Set up a new event loop for this thread\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n\n        async def main():\n            try:\n                print('fetch_messages: Starting main function.')\n\n                # Initialize the Telegram client in this thread's event loop\n                self.client = TelegramClient('session_name', self.api_id, self.api_hash, loop=loop)\n\n                # Start the client (connect and authenticate)\n                await self.client.start()\n                print('Telegram client started in background thread.')\n\n                # Initialize variables\n                offset_id = 0  # Start from the latest message\n                limit = 50  # Number of messages to fetch in each batch\n\n                while True:\n                    print('Fetching new messages...')\n                    new_messages = []\n                    media_groups = {}\n\n                   ",
        "actual_middle": " # Fetch messages in ba",
        "generated_middle": "from flask import Flask, render_template\nfrom dotenv import find_dotenv, load_dotenv\nfrom telethon import TelegramClient\nfrom telethon.tl.types import (\n    MessageMediaPhoto,\n    MessageMediaDocument,\n    MessageMediaWebPage,\n    WebPageEmpty,\n    WebPage\n)\n\nimport os\nimport asyncio\nimport threading\nimport traceback\nimport json\n\n# Initialize the Flask app in the global scope\napp = Flask(__name__)\n\n\nclass ChannelViewer:\n    def __init__(self):\n        self.channel_username = 'onlinerby'  # Replace with the target channel's username\n        self.messages = []\n        self.messages_lock = threading.Lock()\n        self.load_environment_variables()\n\n        # Store API credentials\n        self.api_id = os.getenv('API_ID')\n        self.api_hash = os.getenv('API_HASH')\n\n        # Initialize variables\n        self.last_message_id = 0  # To keep track of the last processed message ID\n\n        # Load existing messages from file\n        self.load_messages()\n\n        # Start the background thread\n        self.start_fetching_messages()\n\n    def load_environment_variables(self):\n        \"\"\"\n        Load environment variables from a .env file.\n        \"\"\"\n        try:\n            dotenv_path = find_dotenv()\n            if not dotenv_path:\n                raise FileNotFoundError(\".env file not found\")\n            load_dotenv(dotenv_path)\n            print(f\"Environment variables loaded from {dotenv_path}\")\n        except Exception as e:\n            print(f\"Error loading .env file: {e}\")\n            raise\n\n    def load_messages(self):\n        \"\"\"\n        Load messages from 'messages.json' if it exists.\n        \"\"\"\n        try:\n            with open('messages.json', 'r', encoding='utf-8') as f:\n                self.messages = json.load(f)\n            if self.messages:\n                # Update last_message_id with the highest message ID\n                self.last_message_id = max(msg['id'] for msg in self.messages)\n            print(f\"Loaded {len(self.messages)} messages from messages.json.\")\n        except FileNotFoundError:\n            print(\"messages.json not found. Starting with an empty message list.\")\n        except Exception as e:\n            print(f\"Error loading messages: {e}\")\n\n    def save_messages(self):\n        \"\"\"\n        Save messages to 'messages.json'.\n        \"\"\"\n        try:\n            with open('messages.json', 'w', encoding='utf-8') as f:\n                json.dump(self.messages, f, ensure_ascii=False, indent=4)\n            print(f\"Saved {len(self.messages)} messages to messages.json.\")\n        except Exception as e:\n            print(f\"Error saving messages: {e}\")\n\n    def start_fetching_messages(self):\n        print('Starting background thread to fetch messages.')\n        fetch_thread = threading.Thread(target=self.fetch_messages)\n        fetch_thread.daemon = True  # Daemonize thread to exit when main program exits\n        fetch_thread.start()\n        print('Background thread started.')\n\n    def fetch_messages(self):\n        print('fetch_messages: Started fetching messages.')\n        # Set up a new event loop for this thread\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n\n        async def main():\n            try:\n                print('fetch_messages: Starting main function.')\n\n                # Initialize the Telegram client in this thread's event loop\n                self.client = TelegramClient('session_name', self.api_id, self.api_hash, loop=loop)\n\n                # Start the client (connect and authenticate)\n                await self.client.start()\n                print('Telegram client started in background thread.')\n\n                # Initialize variables\n                offset_id = 0  # Start from the latest message\n                limit = 50  # Number of messages to fetch in each batch\n\n                while True:\n                    print('Fetching new messages...')\n                    new_messages = []\n                    media_groups = {}\n\n                   tches\n                    messages = await self.client.get_messages(\n                        self.channel_username,\n                        limit=limit,\n                        offset_id=offset_id\n                    )\n\n                    if not messages:\n                        print('No new messages found.')\n                        await asyncio.sleep(5)  # Wait before checking again\n                        continue\n\n                    for message in reversed(messages):  # Process from oldest to newest\n                        print(f'Processing message ID {message.id}')\n                        message_data = {\n                            'id': message.id,\n                            'text': message.text or '',\n                            'date': message.date.strftime('%Y-%m-%d %H:%M:%S'),\n                            'sender': message.sender_id,\n                            'media': [],\n                            'media_type': None,\n                            'grouped_id': message.grouped_id,\n                        }\n\n                        # Check if the message has media\n                        if message.media:\n                            print(f'Message ID {message.id} has media.')\n                            # Ensure the directory exists\n                            media_dir = 'static/media/'\n                            os.makedirs(media_dir, exist_ok=True)\n\n                            # Initialize variables\n                            media_filename = None\n                            media_item = {}\n\n                            # Handle different media types\n                            if isinstance(message.media, MessageMediaPhoto):\n                                # For photos\n                                file_extension = '.jpg'\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded photo for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Photo for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'photo',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaDocument):\n                                # For documents (including videos, audio, etc.)\n                                file_extension = self.get_media_extension(message)\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded document for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Document for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'document',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaWebPage):\n                                # Handle web page previews\n                                print(f'Message ID {message.id} contains a web page preview.')\n                                webpage = message.media.webpage\n\n                                if isinstance(webpage, WebPage):\n                                    # Full web page preview\n                                    message_data['webpage'] = {\n                                        'url': webpage.url,\n                                        'title': getattr(webpage, 'title', ''),\n                                        'description': getattr(webpage, 'description', '')\n                                    }\n                                    print(\n                                        f\"Extracted webpage info for message ID {message.id}: {message_data['webpage']}\")\n                                elif isinstance(webpage, WebPageEmpty):\n                                    # Empty web page preview\n                                    print(f'Message ID {message.id} contains an empty web page preview.')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n                                else:\n                                    # Other web page types\n                                    print(\n                                        f'Message ID {message.id} contains an unsupported web page type: {type(webpage)}')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n\n                                # Add to new_messages and skip further processing\n                                new_messages.append(message_data)\n                                continue  # Skip to next message\n\n                            else:\n                                # Unsupported media type\n                                print(f'Message ID {message.id} has unsupported media type: {type(message.media)}')\n                                continue  # Skip this message\n\n                            # Update message data\n                            if media_item:\n                                message_data['media'].append(media_item)\n                                message_data['media_type'] = media_item['media_type']\n\n                        # Group messages by grouped_id if they are part of a media group\n                        if message.grouped_id:\n                            print(f'Message ID {message.id} is part of group {message.grouped_id}')\n                            if message.grouped_id not in media_groups:\n                                # First message in the group; store the text (caption) if available\n                                media_groups[message.grouped_id] = message_data\n                            else:\n                                # Append media to existing group\n                                existing_message = media_groups[message.grouped_id]\n                                existing_message['media'].extend(message_data['media'])\n                                # If the existing message doesn't have text, and current message has text, update it\n                                if not existing_message['text'] and message_data['text']:\n                                    existing_message['text'] = message_data['text']\n                                    print(\n                                        f'Updated text for media group {message.grouped_id}: \"{message_data[\"text\"]}\"')\n                        else:\n                            # Not part of a media group, add as individual message\n                            new_messages.append(message_data)\n\n                        # Update last_message_id\n                        if message.id > self.last_message_id:\n                            self.last_message_id = message.id\n\n                        # Update offset_id for the next batch\n                        offset_id = message.id\n\n                    # Add grouped messages to new_messages\n                    new_messages.extend(media_groups.values())\n\n                    # Sort messages by date (optional)\n                    new_messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    # Update the shared messages list\n                    with self.messages_lock:\n                        self.messages.extend(new_messages)\n                        # Remove duplicates based on message ID\n                        self.messages = list({msg['id']: msg for msg in self.messages}.values())\n                        # Sort messages after merging\n                        self.messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    print(f'Fetched and processed {len(new_messages)} new messages.')\n\n                    # Save messages to file\n                    self.save_messages()\n\n                    # Yield control to the event loop\n                    await asyncio.sleep(1)  # Adjust sleep time as needed\n\n            except Exception as e:\n                print(f'An error occurred in fetch_messages: {e}')\n                traceback.print_exc()\n\n        # Run the async function in the event loop\n        try:\n            loop.run_until_complete(main())\n        finally:\n            # Properly disconnect the client\n            self.client.disconnect()\n            loop.close()\n\n    def get_media_extension(self, message):\n        \"\"\"\n        Get the file extension for the media.\n        \"\"\"\n        if message.photo:\n            return '.jpg'\n        elif message.video:\n            return '.mp4'\n        elif message.document:\n            # Get the extension from the mime type or file name\n            mime_type = message.document.mime_type\n            if mime_type == 'image/jpeg':\n                return '.jpg'\n            elif mime_type == 'image/png':\n                return '.png'\n            elif mime_type == 'video/mp4':\n                return '.mp4'\n            else:\n                # Extract extension from file name\n                if message.file and message.file.name:\n                    return os.path.splitext(message.file.name)[1]\n                else:\n                    return ''\n        else:\n            return ''\n\n    def get_channel_messages(self):\n        with self.messages_lock:\n            return self.messages.copy()\n\n\n# Instantiate the ChannelViewer class\nviewer = ChannelViewer()\n\n\n@app.route('/')\ndef index():\n    print('Received request for /')\n    messages = viewer.get_channel_messages()\n    print(f\"Number of messages to display: {len(messages)}\")\n    return render_template('index.html', messages=messages)\n\n\nif __name__ == '__main__':\n    app.run(debug=True, use_reloader=False) print('Fetching new messages from channel \"{self.channel_username}\".')\n                    for offset, message",
        "suffix": "tches\n                    messages = await self.client.get_messages(\n                        self.channel_username,\n                        limit=limit,\n                        offset_id=offset_id\n                    )\n\n                    if not messages:\n                        print('No new messages found.')\n                        await asyncio.sleep(5)  # Wait before checking again\n                        continue\n\n                    for message in reversed(messages):  # Process from oldest to newest\n                        print(f'Processing message ID {message.id}')\n                        message_data = {\n                            'id': message.id,\n                            'text': message.text or '',\n                            'date': message.date.strftime('%Y-%m-%d %H:%M:%S'),\n                            'sender': message.sender_id,\n                            'media': [],\n                            'media_type': None,\n                            'grouped_id': message.grouped_id,\n                        }\n\n                        # Check if the message has media\n                        if message.media:\n                            print(f'Message ID {message.id} has media.')\n                            # Ensure the directory exists\n                            media_dir = 'static/media/'\n                            os.makedirs(media_dir, exist_ok=True)\n\n                            # Initialize variables\n                            media_filename = None\n                            media_item = {}\n\n                            # Handle different media types\n                            if isinstance(message.media, MessageMediaPhoto):\n                                # For photos\n                                file_extension = '.jpg'\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded photo for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Photo for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'photo',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaDocument):\n                                # For documents (including videos, audio, etc.)\n                                file_extension = self.get_media_extension(message)\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded document for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Document for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'document',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaWebPage):\n                                # Handle web page previews\n                                print(f'Message ID {message.id} contains a web page preview.')\n                                webpage = message.media.webpage\n\n                                if isinstance(webpage, WebPage):\n                                    # Full web page preview\n                                    message_data['webpage'] = {\n                                        'url': webpage.url,\n                                        'title': getattr(webpage, 'title', ''),\n                                        'description': getattr(webpage, 'description', '')\n                                    }\n                                    print(\n                                        f\"Extracted webpage info for message ID {message.id}: {message_data['webpage']}\")\n                                elif isinstance(webpage, WebPageEmpty):\n                                    # Empty web page preview\n                                    print(f'Message ID {message.id} contains an empty web page preview.')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n                                else:\n                                    # Other web page types\n                                    print(\n                                        f'Message ID {message.id} contains an unsupported web page type: {type(webpage)}')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n\n                                # Add to new_messages and skip further processing\n                                new_messages.append(message_data)\n                                continue  # Skip to next message\n\n                            else:\n                                # Unsupported media type\n                                print(f'Message ID {message.id} has unsupported media type: {type(message.media)}')\n                                continue  # Skip this message\n\n                            # Update message data\n                            if media_item:\n                                message_data['media'].append(media_item)\n                                message_data['media_type'] = media_item['media_type']\n\n                        # Group messages by grouped_id if they are part of a media group\n                        if message.grouped_id:\n                            print(f'Message ID {message.id} is part of group {message.grouped_id}')\n                            if message.grouped_id not in media_groups:\n                                # First message in the group; store the text (caption) if available\n                                media_groups[message.grouped_id] = message_data\n                            else:\n                                # Append media to existing group\n                                existing_message = media_groups[message.grouped_id]\n                                existing_message['media'].extend(message_data['media'])\n                                # If the existing message doesn't have text, and current message has text, update it\n                                if not existing_message['text'] and message_data['text']:\n                                    existing_message['text'] = message_data['text']\n                                    print(\n                                        f'Updated text for media group {message.grouped_id}: \"{message_data[\"text\"]}\"')\n                        else:\n                            # Not part of a media group, add as individual message\n                            new_messages.append(message_data)\n\n                        # Update last_message_id\n                        if message.id > self.last_message_id:\n                            self.last_message_id = message.id\n\n                        # Update offset_id for the next batch\n                        offset_id = message.id\n\n                    # Add grouped messages to new_messages\n                    new_messages.extend(media_groups.values())\n\n                    # Sort messages by date (optional)\n                    new_messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    # Update the shared messages list\n                    with self.messages_lock:\n                        self.messages.extend(new_messages)\n                        # Remove duplicates based on message ID\n                        self.messages = list({msg['id']: msg for msg in self.messages}.values())\n                        # Sort messages after merging\n                        self.messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    print(f'Fetched and processed {len(new_messages)} new messages.')\n\n                    # Save messages to file\n                    self.save_messages()\n\n                    # Yield control to the event loop\n                    await asyncio.sleep(1)  # Adjust sleep time as needed\n\n            except Exception as e:\n                print(f'An error occurred in fetch_messages: {e}')\n                traceback.print_exc()\n\n        # Run the async function in the event loop\n        try:\n            loop.run_until_complete(main())\n        finally:\n            # Properly disconnect the client\n            self.client.disconnect()\n            loop.close()\n\n    def get_media_extension(self, message):\n        \"\"\"\n        Get the file extension for the media.\n        \"\"\"\n        if message.photo:\n            return '.jpg'\n        elif message.video:\n            return '.mp4'\n        elif message.document:\n            # Get the extension from the mime type or file name\n            mime_type = message.document.mime_type\n            if mime_type == 'image/jpeg':\n                return '.jpg'\n            elif mime_type == 'image/png':\n                return '.png'\n            elif mime_type == 'video/mp4':\n                return '.mp4'\n            else:\n                # Extract extension from file name\n                if message.file and message.file.name:\n                    return os.path.splitext(message.file.name)[1]\n                else:\n                    return ''\n        else:\n            return ''\n\n    def get_channel_messages(self):\n        with self.messages_lock:\n            return self.messages.copy()\n\n\n# Instantiate the ChannelViewer class\nviewer = ChannelViewer()\n\n\n@app.route('/')\ndef index():\n    print('Received request for /')\n    messages = viewer.get_channel_messages()\n    print(f\"Number of messages to display: {len(messages)}\")\n    return render_template('index.html', messages=messages)\n\n\nif __name__ == '__main__':\n    app.run(debug=True, use_reloader=False)",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 0.7725789640771824,
            "bleu_score": 0.0186905995772096,
            "rougeL_score": 0.004335260115606937,
            "levenshtein_ratio": 0.15435205690893516
        }
    },
    {
        "id": 16,
        "filename": "1.txt",
        "prefix": "from flask import Flask, render_template\nfrom dotenv import find_dotenv, load_dotenv\nfrom telethon import TelegramClient\nfrom telethon.tl.types import (\n    MessageMediaPhoto,\n    MessageMediaDocument,\n    MessageMediaWebPage,\n    WebPageEmpty,\n    WebPage\n)\n\nimport os\nimport asyncio\nimport threading\nimport traceback\nimport json\n\n# Initialize the Flask app in the global scope\napp = Flask(__name__)\n\n\nclass ChannelViewer:\n    def __init__(self):\n        self.channel_username = 'onlinerby'  # Replace with the target channel's username\n        self.messages = []\n        self.messages_lock = threading.Lock()\n        self.load_environment_variables()\n\n        # Store API credentials\n        self.api_id = os.getenv('API_ID')\n        self.api_hash = os.getenv('API_HASH')\n\n        # Initialize variables\n        self.last_message_id = 0  # To keep track of the last processed message ID\n\n        # Load existing messages from file\n        self.load_messages()\n\n        # Start the background thread\n        self.start_fetching_messages()\n\n    def load_environment_variables(self):\n        \"\"\"\n        Load environment variables from a .env file.\n        \"\"\"\n        try:\n            dotenv_path = find_dotenv()\n            if not dotenv_path:\n                raise FileNotFoundError(\".env file not found\")\n            load_dotenv(dotenv_path)\n            print(f\"Environment variables loaded from {dotenv_path}\")\n        except Exception as e:\n            print(f\"Error loading .env file: {e}\")\n            raise\n\n    def load_messages(self):\n        \"\"\"\n        Load messages from 'messages.json' if it exists.\n        \"\"\"\n        try:\n            with open('messages.json', 'r', encoding='utf-8') as f:\n                self.messages = json.load(f)\n            if self.messages:\n                # Update last_message_id with the highest message ID\n                self.last_message_id = max(msg['id'] for msg in self.messages)\n            print(f\"Loaded {len(self.messages)} messages from messages.json.\")\n        except FileNotFoundError:\n            print(\"messages.json not found. Starting with an empty message list.\")\n        except Exception as e:\n            print(f\"Error loading messages: {e}\")\n\n    def save_messages(self):\n        \"\"\"\n        Save messages to 'messages.json'.\n        \"\"\"\n        try:\n            with open('messages.json', 'w', encoding='utf-8') as f:\n                json.dump(self.messages, f, ensure_ascii=False, indent=4)\n            print(f\"Saved {len(self.messages)} messages to messages.json.\")\n        except Exception as e:\n            print(f\"Error saving messages: {e}\")\n\n    def start_fetching_messages(self):\n        print('Starting background thread to fetch messages.')\n        fetch_thread = threading.Thread(target=self.fetch_messages)\n        fetch_thread.daemon = True  # Daemonize thread to exit when main program exits\n        fetch_thread.start()\n        print('Background thread started.')\n\n    def fetch_messages(self):\n        print('fetch_messages: Started fetching messages.')\n        # Set up a new event loop for this thread\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n\n        async def main():\n            try:\n                print('fetch_messages: Starting main function.')\n\n                # Initialize the Telegram client in this thread's event loop\n                self.client = TelegramClient('session_name', self.api_id, self.api_hash, loop=loop)\n\n                # Start the client (connect and authenticate)\n                await self.client.start()\n                print('Telegram client started in background thread.')\n\n                # Initialize variables\n                offset_id = 0  # Start from the latest message\n                limit = 50  # Number of messages to fetch in each batch\n\n                while True:\n                    print('Fetching new messages...')\n                    new_messages = []\n                    media_groups = {}\n\n                    # Fetch messages in batches\n                    messages = await self.client.get_messages(\n                        self.channel_username,\n                        limit=limit,\n                        offset_id=offset_id\n                    )\n\n                    if not messages:\n                        print('No new messages found.')\n                        await asyncio.sleep(5)  # Wait before checking again\n                        continue\n\n                    for message in reversed(messages):  # Process from oldest to newest\n                        print(f'Processing message ID {message.id}')\n                        message_data = {\n                            'id': message.id,\n                            'text': message.text or '',\n                            'date': message.date.strftime('%Y-%m-%d %H:%M:%S'),\n                            'sender': message.sender_id,\n                            'media': [],\n                            'media_type': None,\n                            'grouped_id': message.grouped_id,\n                        }\n\n                        # Check if the message has media\n                        if message.media:\n                            print(f'Message ID {message.id} has media.')\n                            # Ensure the directory exists\n                            media_dir = 'static/media/'\n                            os.makedirs(media_dir, exist_ok=True)\n\n                            # Initialize variables\n                            media_filename = None\n                            media_item = {}\n\n                            # Handle different media types\n                            if isinstance(message.media, MessageMediaPhoto):\n                                # For photos\n                                file_extension = '.jpg'\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(",
        "actual_middle": "media_dir, media_f",
        "generated_middle": "from flask import Flask, render_template\nfrom dotenv import find_dotenv, load_dotenv\nfrom telethon import TelegramClient\nfrom telethon.tl.types import (\n    MessageMediaPhoto,\n    MessageMediaDocument,\n    MessageMediaWebPage,\n    WebPageEmpty,\n    WebPage\n)\n\nimport os\nimport asyncio\nimport threading\nimport traceback\nimport json\n\n# Initialize the Flask app in the global scope\napp = Flask(__name__)\n\n\nclass ChannelViewer:\n    def __init__(self):\n        self.channel_username = 'onlinerby'  # Replace with the target channel's username\n        self.messages = []\n        self.messages_lock = threading.Lock()\n        self.load_environment_variables()\n\n        # Store API credentials\n        self.api_id = os.getenv('API_ID')\n        self.api_hash = os.getenv('API_HASH')\n\n        # Initialize variables\n        self.last_message_id = 0  # To keep track of the last processed message ID\n\n        # Load existing messages from file\n        self.load_messages()\n\n        # Start the background thread\n        self.start_fetching_messages()\n\n    def load_environment_variables(self):\n        \"\"\"\n        Load environment variables from a .env file.\n        \"\"\"\n        try:\n            dotenv_path = find_dotenv()\n            if not dotenv_path:\n                raise FileNotFoundError(\".env file not found\")\n            load_dotenv(dotenv_path)\n            print(f\"Environment variables loaded from {dotenv_path}\")\n        except Exception as e:\n            print(f\"Error loading .env file: {e}\")\n            raise\n\n    def load_messages(self):\n        \"\"\"\n        Load messages from 'messages.json' if it exists.\n        \"\"\"\n        try:\n            with open('messages.json', 'r', encoding='utf-8') as f:\n                self.messages = json.load(f)\n            if self.messages:\n                # Update last_message_id with the highest message ID\n                self.last_message_id = max(msg['id'] for msg in self.messages)\n            print(f\"Loaded {len(self.messages)} messages from messages.json.\")\n        except FileNotFoundError:\n            print(\"messages.json not found. Starting with an empty message list.\")\n        except Exception as e:\n            print(f\"Error loading messages: {e}\")\n\n    def save_messages(self):\n        \"\"\"\n        Save messages to 'messages.json'.\n        \"\"\"\n        try:\n            with open('messages.json', 'w', encoding='utf-8') as f:\n                json.dump(self.messages, f, ensure_ascii=False, indent=4)\n            print(f\"Saved {len(self.messages)} messages to messages.json.\")\n        except Exception as e:\n            print(f\"Error saving messages: {e}\")\n\n    def start_fetching_messages(self):\n        print('Starting background thread to fetch messages.')\n        fetch_thread = threading.Thread(target=self.fetch_messages)\n        fetch_thread.daemon = True  # Daemonize thread to exit when main program exits\n        fetch_thread.start()\n        print('Background thread started.')\n\n    def fetch_messages(self):\n        print('fetch_messages: Started fetching messages.')\n        # Set up a new event loop for this thread\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n\n        async def main():\n            try:\n                print('fetch_messages: Starting main function.')\n\n                # Initialize the Telegram client in this thread's event loop\n                self.client = TelegramClient('session_name', self.api_id, self.api_hash, loop=loop)\n\n                # Start the client (connect and authenticate)\n                await self.client.start()\n                print('Telegram client started in background thread.')\n\n                # Initialize variables\n                offset_id = 0  # Start from the latest message\n                limit = 50  # Number of messages to fetch in each batch\n\n                while True:\n                    print('Fetching new messages...')\n                    new_messages = []\n                    media_groups = {}\n\n                    # Fetch messages in batches\n                    messages = await self.client.get_messages(\n                        self.channel_username,\n                        limit=limit,\n                        offset_id=offset_id\n                    )\n\n                    if not messages:\n                        print('No new messages found.')\n                        await asyncio.sleep(5)  # Wait before checking again\n                        continue\n\n                    for message in reversed(messages):  # Process from oldest to newest\n                        print(f'Processing message ID {message.id}')\n                        message_data = {\n                            'id': message.id,\n                            'text': message.text or '',\n                            'date': message.date.strftime('%Y-%m-%d %H:%M:%S'),\n                            'sender': message.sender_id,\n                            'media': [],\n                            'media_type': None,\n                            'grouped_id': message.grouped_id,\n                        }\n\n                        # Check if the message has media\n                        if message.media:\n                            print(f'Message ID {message.id} has media.')\n                            # Ensure the directory exists\n                            media_dir = 'static/media/'\n                            os.makedirs(media_dir, exist_ok=True)\n\n                            # Initialize variables\n                            media_filename = None\n                            media_item = {}\n\n                            # Handle different media types\n                            if isinstance(message.media, MessageMediaPhoto):\n                                # For photos\n                                file_extension = '.jpg'\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(ilename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded photo for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Photo for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'photo',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaDocument):\n                                # For documents (including videos, audio, etc.)\n                                file_extension = self.get_media_extension(message)\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded document for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Document for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'document',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaWebPage):\n                                # Handle web page previews\n                                print(f'Message ID {message.id} contains a web page preview.')\n                                webpage = message.media.webpage\n\n                                if isinstance(webpage, WebPage):\n                                    # Full web page preview\n                                    message_data['webpage'] = {\n                                        'url': webpage.url,\n                                        'title': getattr(webpage, 'title', ''),\n                                        'description': getattr(webpage, 'description', '')\n                                    }\n                                    print(\n                                        f\"Extracted webpage info for message ID {message.id}: {message_data['webpage']}\")\n                                elif isinstance(webpage, WebPageEmpty):\n                                    # Empty web page preview\n                                    print(f'Message ID {message.id} contains an empty web page preview.')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n                                else:\n                                    # Other web page types\n                                    print(\n                                        f'Message ID {message.id} contains an unsupported web page type: {type(webpage)}')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n\n                                # Add to new_messages and skip further processing\n                                new_messages.append(message_data)\n                                continue  # Skip to next message\n\n                            else:\n                                # Unsupported media type\n                                print(f'Message ID {message.id} has unsupported media type: {type(message.media)}')\n                                continue  # Skip this message\n\n                            # Update message data\n                            if media_item:\n                                message_data['media'].append(media_item)\n                                message_data['media_type'] = media_item['media_type']\n\n                        # Group messages by grouped_id if they are part of a media group\n                        if message.grouped_id:\n                            print(f'Message ID {message.id} is part of group {message.grouped_id}')\n                            if message.grouped_id not in media_groups:\n                                # First message in the group; store the text (caption) if available\n                                media_groups[message.grouped_id] = message_data\n                            else:\n                                # Append media to existing group\n                                existing_message = media_groups[message.grouped_id]\n                                existing_message['media'].extend(message_data['media'])\n                                # If the existing message doesn't have text, and current message has text, update it\n                                if not existing_message['text'] and message_data['text']:\n                                    existing_message['text'] = message_data['text']\n                                    print(\n                                        f'Updated text for media group {message.grouped_id}: \"{message_data[\"text\"]}\"')\n                        else:\n                            # Not part of a media group, add as individual message\n                            new_messages.append(message_data)\n\n                        # Update last_message_id\n                        if message.id > self.last_message_id:\n                            self.last_message_id = message.id\n\n                        # Update offset_id for the next batch\n                        offset_id = message.id\n\n                    # Add grouped messages to new_messages\n                    new_messages.extend(media_groups.values())\n\n                    # Sort messages by date (optional)\n                    new_messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    # Update the shared messages list\n                    with self.messages_lock:\n                        self.messages.extend(new_messages)\n                        # Remove duplicates based on message ID\n                        self.messages = list({msg['id']: msg for msg in self.messages}.values())\n                        # Sort messages after merging\n                        self.messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    print(f'Fetched and processed {len(new_messages)} new messages.')\n\n                    # Save messages to file\n                    self.save_messages()\n\n                    # Yield control to the event loop\n                    await asyncio.sleep(1)  # Adjust sleep time as needed\n\n            except Exception as e:\n                print(f'An error occurred in fetch_messages: {e}')\n                traceback.print_exc()\n\n        # Run the async function in the event loop\n        try:\n            loop.run_until_complete(main())\n        finally:\n            # Properly disconnect the client\n            self.client.disconnect()\n            loop.close()\n\n    def get_media_extension(self, message):\n        \"\"\"\n        Get the file extension for the media.\n        \"\"\"\n        if message.photo:\n            return '.jpg'\n        elif message.video:\n            return '.mp4'\n        elif message.document:\n            # Get the extension from the mime type or file name\n            mime_type = message.document.mime_type\n            if mime_type == 'image/jpeg':\n                return '.jpg'\n            elif mime_type == 'image/png':\n                return '.png'\n            elif mime_type == 'video/mp4':\n                return '.mp4'\n            else:\n                # Extract extension from file name\n                if message.file and message.file.name:\n                    return os.path.splitext(message.file.name)[1]\n                else:\n                    return ''\n        else:\n            return ''\n\n    def get_channel_messages(self):\n        with self.messages_lock:\n            return self.messages.copy()\n\n\n# Instantiate the ChannelViewer class\nviewer = ChannelViewer()\n\n\n@app.route('/')\ndef index():\n    print('Received request for /')\n    messages = viewer.get_channel_messages()\n    print(f\"Number of messages to display: {len(messages)}\")\n    return render_template('index.html', messages=messages)\n\n\nif __name__ == '__main__':\n    app.run(debug=True, use_reloader=False)file_path, media_filename)\n                                elif isinstance(message.media, MessageMediaDocument):",
        "suffix": "ilename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded photo for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Photo for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'photo',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaDocument):\n                                # For documents (including videos, audio, etc.)\n                                file_extension = self.get_media_extension(message)\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded document for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Document for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'document',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaWebPage):\n                                # Handle web page previews\n                                print(f'Message ID {message.id} contains a web page preview.')\n                                webpage = message.media.webpage\n\n                                if isinstance(webpage, WebPage):\n                                    # Full web page preview\n                                    message_data['webpage'] = {\n                                        'url': webpage.url,\n                                        'title': getattr(webpage, 'title', ''),\n                                        'description': getattr(webpage, 'description', '')\n                                    }\n                                    print(\n                                        f\"Extracted webpage info for message ID {message.id}: {message_data['webpage']}\")\n                                elif isinstance(webpage, WebPageEmpty):\n                                    # Empty web page preview\n                                    print(f'Message ID {message.id} contains an empty web page preview.')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n                                else:\n                                    # Other web page types\n                                    print(\n                                        f'Message ID {message.id} contains an unsupported web page type: {type(webpage)}')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n\n                                # Add to new_messages and skip further processing\n                                new_messages.append(message_data)\n                                continue  # Skip to next message\n\n                            else:\n                                # Unsupported media type\n                                print(f'Message ID {message.id} has unsupported media type: {type(message.media)}')\n                                continue  # Skip this message\n\n                            # Update message data\n                            if media_item:\n                                message_data['media'].append(media_item)\n                                message_data['media_type'] = media_item['media_type']\n\n                        # Group messages by grouped_id if they are part of a media group\n                        if message.grouped_id:\n                            print(f'Message ID {message.id} is part of group {message.grouped_id}')\n                            if message.grouped_id not in media_groups:\n                                # First message in the group; store the text (caption) if available\n                                media_groups[message.grouped_id] = message_data\n                            else:\n                                # Append media to existing group\n                                existing_message = media_groups[message.grouped_id]\n                                existing_message['media'].extend(message_data['media'])\n                                # If the existing message doesn't have text, and current message has text, update it\n                                if not existing_message['text'] and message_data['text']:\n                                    existing_message['text'] = message_data['text']\n                                    print(\n                                        f'Updated text for media group {message.grouped_id}: \"{message_data[\"text\"]}\"')\n                        else:\n                            # Not part of a media group, add as individual message\n                            new_messages.append(message_data)\n\n                        # Update last_message_id\n                        if message.id > self.last_message_id:\n                            self.last_message_id = message.id\n\n                        # Update offset_id for the next batch\n                        offset_id = message.id\n\n                    # Add grouped messages to new_messages\n                    new_messages.extend(media_groups.values())\n\n                    # Sort messages by date (optional)\n                    new_messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    # Update the shared messages list\n                    with self.messages_lock:\n                        self.messages.extend(new_messages)\n                        # Remove duplicates based on message ID\n                        self.messages = list({msg['id']: msg for msg in self.messages}.values())\n                        # Sort messages after merging\n                        self.messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    print(f'Fetched and processed {len(new_messages)} new messages.')\n\n                    # Save messages to file\n                    self.save_messages()\n\n                    # Yield control to the event loop\n                    await asyncio.sleep(1)  # Adjust sleep time as needed\n\n            except Exception as e:\n                print(f'An error occurred in fetch_messages: {e}')\n                traceback.print_exc()\n\n        # Run the async function in the event loop\n        try:\n            loop.run_until_complete(main())\n        finally:\n            # Properly disconnect the client\n            self.client.disconnect()\n            loop.close()\n\n    def get_media_extension(self, message):\n        \"\"\"\n        Get the file extension for the media.\n        \"\"\"\n        if message.photo:\n            return '.jpg'\n        elif message.video:\n            return '.mp4'\n        elif message.document:\n            # Get the extension from the mime type or file name\n            mime_type = message.document.mime_type\n            if mime_type == 'image/jpeg':\n                return '.jpg'\n            elif mime_type == 'image/png':\n                return '.png'\n            elif mime_type == 'video/mp4':\n                return '.mp4'\n            else:\n                # Extract extension from file name\n                if message.file and message.file.name:\n                    return os.path.splitext(message.file.name)[1]\n                else:\n                    return ''\n        else:\n            return ''\n\n    def get_channel_messages(self):\n        with self.messages_lock:\n            return self.messages.copy()\n\n\n# Instantiate the ChannelViewer class\nviewer = ChannelViewer()\n\n\n@app.route('/')\ndef index():\n    print('Received request for /')\n    messages = viewer.get_channel_messages()\n    print(f\"Number of messages to display: {len(messages)}\")\n    return render_template('index.html', messages=messages)\n\n\nif __name__ == '__main__':\n    app.run(debug=True, use_reloader=False)",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 0.8740520212383214,
            "bleu_score": 0.1823572815687764,
            "rougeL_score": 0.005792903692976104,
            "levenshtein_ratio": 0.12074864157778364
        }
    },
    {
        "id": 17,
        "filename": "1.txt",
        "prefix": "from flask import Flask, render_template\nfrom dotenv import find_dotenv, load_dotenv\nfrom telethon import TelegramClient\nfrom telethon.tl.types import (\n    MessageMediaPhoto,\n    MessageMediaDocument,\n    MessageMediaWebPage,\n    WebPageEmpty,\n    WebPage\n)\n\nimport os\nimport asyncio\nimport threading\nimport traceback\nimport json\n\n# Initialize the Flask app in the global scope\napp = Flask(__name__)\n\n\nclass ChannelViewer:\n    def __init__(self):\n        self.channel_username = 'onlinerby'  # Replace with the target channel's username\n        self.messages = []\n        self.messages_lock = threading.Lock()\n        self.load_environment_variables()\n\n        # Store API credentials\n        self.api_id = os.getenv('API_ID')\n        self.api_hash = os.getenv('API_HASH')\n\n        # Initialize variables\n        self.last_message_id = 0  # To keep track of the last processed message ID\n\n        # Load existing messages from file\n        self.load_messages()\n\n        # Start the background thread\n        self.start_fetching_messages()\n\n    def load_environment_variables(self):\n        \"\"\"\n        Load environment variables from a .env file.\n        \"\"\"\n        try:\n            dotenv_path = find_dotenv()\n            if not dotenv_path:\n                raise FileNotFoundError(\".env file not found\")\n            load_dotenv(dotenv_path)\n            print(f\"Environment variables loaded from {dotenv_path}\")\n        except Exception as e:\n            print(f\"Error loading .env file: {e}\")\n            raise\n\n    def load_messages(self):\n        \"\"\"\n        Load messages from 'messages.json' if it exists.\n        \"\"\"\n        try:\n            with open('messages.json', 'r', encoding='utf-8') as f:\n                self.messages = json.load(f)\n            if self.messages:\n                # Update last_message_id with the highest message ID\n                self.last_message_id = max(msg['id'] for msg in self.messages)\n            print(f\"Loaded {len(self.messages)} messages from messages.json.\")\n        except FileNotFoundError:\n            print(\"messages.json not found. Starting with an empty message list.\")\n        except Exception as e:\n            print(f\"Error loading messages: {e}\")\n\n    def save_messages(self):\n        \"\"\"\n        Save messages to 'messages.json'.\n        \"\"\"\n        try:\n            with open('messages.json', 'w', encoding='utf-8') as f:\n                json.dump(self.messages, f, ensure_ascii=False, indent=4)\n            print(f\"Saved {len(self.messages)} messages to messages.json.\")\n        except Exception as e:\n            print(f\"Error saving messages: {e}\")\n\n    def start_fetching_messages(self):\n        print('Starting background thread to fetch messages.')\n        fetch_thread = threading.Thread(target=self.fetch_messages)\n        fetch_thread.daemon = True  # Daemonize thread to exit when main program exits\n        fetch_thread.start()\n        print('Background thread started.')\n\n    def fetch_messages(self):\n        print('fetch_messages: Started fetching messages.')\n        # Set up a new event loop for this thread\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n\n        async def main():\n            try:\n                print('fetch_messages: Starting main function.')\n\n                # Initialize the Telegram client in this thread's event loop\n                self.client = TelegramClient('session_name', self.api_id, self.api_hash, loop=loop)\n\n                # Start the client (connect and authenticate)\n                await self.client.start()\n                print('Telegram client started in background thread.')\n\n                # Initialize variables\n                offset_id = 0  # Start from the latest message\n                limit = 50  # Number of messages to fetch in each batch\n\n                while True:\n                    print('Fetching new messages...')\n                    new_messages = []\n                    media_groups = {}\n\n                    # Fetch messages in batches\n                    messages = await self.client.get_messages(\n                        self.channel_username,\n                        limit=limit,\n                        offset_id=offset_id\n                    )\n\n                    if not messages:\n                        print('No new messages found.')\n                        await asyncio.sleep(5)  # Wait before checking again\n                        continue\n\n                    for message in reversed(messages):  # Process from oldest to newest\n                        print(f'Processing message ID {message.id}')\n                        message_data = {\n                            'id': message.id,\n                            'text': message.text or '',\n                            'date': message.date.strftime('%Y-%m-%d %H:%M:%S'),\n                            'sender': message.sender_id,\n                            'media': [],\n                            'media_type': None,\n                            'grouped_id': message.grouped_id,\n                        }\n\n                        # Check if the message has media\n                        if message.media:\n                            print(f'Message ID {message.id} has media.')\n                            # Ensure the directory exists\n                            media_dir = 'static/media/'\n                            os.makedirs(media_dir, exist_ok=True)\n\n                            # Initialize variables\n                            media_filename = None\n                            media_item = {}\n\n                            # Handle different media types\n                            if isinstance(message.media, MessageMediaPhoto):\n                                # For photos\n                                file_extension = '.jpg'\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded photo for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Photo for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'photo',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaDocument):\n                                # For documents (including videos, audio, etc.)\n                                file_extension = self.get_media_extension(message)\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded document for message ID {message.id}: {media_filename}')\n                                else:\n     ",
        "actual_middle": "         ",
        "generated_middle": "from flask import Flask, render_template\nfrom dotenv import find_dotenv, load_dotenv\nfrom telethon import TelegramClient\nfrom telethon.tl.types import (\n    MessageMediaPhoto,\n    MessageMediaDocument,\n    MessageMediaWebPage,\n    WebPageEmpty,\n    WebPage\n)\n\nimport os\nimport asyncio\nimport threading\nimport traceback\nimport json\n\n# Initialize the Flask app in the global scope\napp = Flask(__name__)\n\n\nclass ChannelViewer:\n    def __init__(self):\n        self.channel_username = 'onlinerby'  # Replace with the target channel's username\n        self.messages = []\n        self.messages_lock = threading.Lock()\n        self.load_environment_variables()\n\n        # Store API credentials\n        self.api_id = os.getenv('API_ID')\n        self.api_hash = os.getenv('API_HASH')\n\n        # Initialize variables\n        self.last_message_id = 0  # To keep track of the last processed message ID\n\n        # Load existing messages from file\n        self.load_messages()\n\n        # Start the background thread\n        self.start_fetching_messages()\n\n    def load_environment_variables(self):\n        \"\"\"\n        Load environment variables from a .env file.\n        \"\"\"\n        try:\n            dotenv_path = find_dotenv()\n            if not dotenv_path:\n                raise FileNotFoundError(\".env file not found\")\n            load_dotenv(dotenv_path)\n            print(f\"Environment variables loaded from {dotenv_path}\")\n        except Exception as e:\n            print(f\"Error loading .env file: {e}\")\n            raise\n\n    def load_messages(self):\n        \"\"\"\n        Load messages from 'messages.json' if it exists.\n        \"\"\"\n        try:\n            with open('messages.json', 'r', encoding='utf-8') as f:\n                self.messages = json.load(f)\n            if self.messages:\n                # Update last_message_id with the highest message ID\n                self.last_message_id = max(msg['id'] for msg in self.messages)\n            print(f\"Loaded {len(self.messages)} messages from messages.json.\")\n        except FileNotFoundError:\n            print(\"messages.json not found. Starting with an empty message list.\")\n        except Exception as e:\n            print(f\"Error loading messages: {e}\")\n\n    def save_messages(self):\n        \"\"\"\n        Save messages to 'messages.json'.\n        \"\"\"\n        try:\n            with open('messages.json', 'w', encoding='utf-8') as f:\n                json.dump(self.messages, f, ensure_ascii=False, indent=4)\n            print(f\"Saved {len(self.messages)} messages to messages.json.\")\n        except Exception as e:\n            print(f\"Error saving messages: {e}\")\n\n    def start_fetching_messages(self):\n        print('Starting background thread to fetch messages.')\n        fetch_thread = threading.Thread(target=self.fetch_messages)\n        fetch_thread.daemon = True  # Daemonize thread to exit when main program exits\n        fetch_thread.start()\n        print('Background thread started.')\n\n    def fetch_messages(self):\n        print('fetch_messages: Started fetching messages.')\n        # Set up a new event loop for this thread\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n\n        async def main():\n            try:\n                print('fetch_messages: Starting main function.')\n\n                # Initialize the Telegram client in this thread's event loop\n                self.client = TelegramClient('session_name', self.api_id, self.api_hash, loop=loop)\n\n                # Start the client (connect and authenticate)\n                await self.client.start()\n                print('Telegram client started in background thread.')\n\n                # Initialize variables\n                offset_id = 0  # Start from the latest message\n                limit = 50  # Number of messages to fetch in each batch\n\n                while True:\n                    print('Fetching new messages...')\n                    new_messages = []\n                    media_groups = {}\n\n                    # Fetch messages in batches\n                    messages = await self.client.get_messages(\n                        self.channel_username,\n                        limit=limit,\n                        offset_id=offset_id\n                    )\n\n                    if not messages:\n                        print('No new messages found.')\n                        await asyncio.sleep(5)  # Wait before checking again\n                        continue\n\n                    for message in reversed(messages):  # Process from oldest to newest\n                        print(f'Processing message ID {message.id}')\n                        message_data = {\n                            'id': message.id,\n                            'text': message.text or '',\n                            'date': message.date.strftime('%Y-%m-%d %H:%M:%S'),\n                            'sender': message.sender_id,\n                            'media': [],\n                            'media_type': None,\n                            'grouped_id': message.grouped_id,\n                        }\n\n                        # Check if the message has media\n                        if message.media:\n                            print(f'Message ID {message.id} has media.')\n                            # Ensure the directory exists\n                            media_dir = 'static/media/'\n                            os.makedirs(media_dir, exist_ok=True)\n\n                            # Initialize variables\n                            media_filename = None\n                            media_item = {}\n\n                            # Handle different media types\n                            if isinstance(message.media, MessageMediaPhoto):\n                                # For photos\n                                file_extension = '.jpg'\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded photo for message ID {message.id}: {media_filename}')\n                                else:\n                                    print(f'Photo for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'photo',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaDocument):\n                                # For documents (including videos, audio, etc.)\n                                file_extension = self.get_media_extension(message)\n                                media_filename = f\"{message.id}{file_extension}\"\n                                file_path = os.path.join(media_dir, media_filename)\n\n                                if not os.path.exists(file_path):\n                                    await message.download_media(file=file_path)\n                                    print(f'Downloaded document for message ID {message.id}: {media_filename}')\n                                else:\n                           print(f'Document for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'document',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaWebPage):\n                                # Handle web page previews\n                                print(f'Message ID {message.id} contains a web page preview.')\n                                webpage = message.media.webpage\n\n                                if isinstance(webpage, WebPage):\n                                    # Full web page preview\n                                    message_data['webpage'] = {\n                                        'url': webpage.url,\n                                        'title': getattr(webpage, 'title', ''),\n                                        'description': getattr(webpage, 'description', '')\n                                    }\n                                    print(\n                                        f\"Extracted webpage info for message ID {message.id}: {message_data['webpage']}\")\n                                elif isinstance(webpage, WebPageEmpty):\n                                    # Empty web page preview\n                                    print(f'Message ID {message.id} contains an empty web page preview.')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n                                else:\n                                    # Other web page types\n                                    print(\n                                        f'Message ID {message.id} contains an unsupported web page type: {type(webpage)}')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n\n                                # Add to new_messages and skip further processing\n                                new_messages.append(message_data)\n                                continue  # Skip to next message\n\n                            else:\n                                # Unsupported media type\n                                print(f'Message ID {message.id} has unsupported media type: {type(message.media)}')\n                                continue  # Skip this message\n\n                            # Update message data\n                            if media_item:\n                                message_data['media'].append(media_item)\n                                message_data['media_type'] = media_item['media_type']\n\n                        # Group messages by grouped_id if they are part of a media group\n                        if message.grouped_id:\n                            print(f'Message ID {message.id} is part of group {message.grouped_id}')\n                            if message.grouped_id not in media_groups:\n                                # First message in the group; store the text (caption) if available\n                                media_groups[message.grouped_id] = message_data\n                            else:\n                                # Append media to existing group\n                                existing_message = media_groups[message.grouped_id]\n                                existing_message['media'].extend(message_data['media'])\n                                # If the existing message doesn't have text, and current message has text, update it\n                                if not existing_message['text'] and message_data['text']:\n                                    existing_message['text'] = message_data['text']\n                                    print(\n                                        f'Updated text for media group {message.grouped_id}: \"{message_data[\"text\"]}\"')\n                        else:\n                            # Not part of a media group, add as individual message\n                            new_messages.append(message_data)\n\n                        # Update last_message_id\n                        if message.id > self.last_message_id:\n                            self.last_message_id = message.id\n\n                        # Update offset_id for the next batch\n                        offset_id = message.id\n\n                    # Add grouped messages to new_messages\n                    new_messages.extend(media_groups.values())\n\n                    # Sort messages by date (optional)\n                    new_messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    # Update the shared messages list\n                    with self.messages_lock:\n                        self.messages.extend(new_messages)\n                        # Remove duplicates based on message ID\n                        self.messages = list({msg['id']: msg for msg in self.messages}.values())\n                        # Sort messages after merging\n                        self.messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    print(f'Fetched and processed {len(new_messages)} new messages.')\n\n                    # Save messages to file\n                    self.save_messages()\n\n                    # Yield control to the event loop\n                    await asyncio.sleep(1)  # Adjust sleep time as needed\n\n            except Exception as e:\n                print(f'An error occurred in fetch_messages: {e}')\n                traceback.print_exc()\n\n        # Run the async function in the event loop\n        try:\n            loop.run_until_complete(main())\n        finally:\n            # Properly disconnect the client\n            self.client.disconnect()\n            loop.close()\n\n    def get_media_extension(self, message):\n        \"\"\"\n        Get the file extension for the media.\n        \"\"\"\n        if message.photo:\n            return '.jpg'\n        elif message.video:\n            return '.mp4'\n        elif message.document:\n            # Get the extension from the mime type or file name\n            mime_type = message.document.mime_type\n            if mime_type == 'image/jpeg':\n                return '.jpg'\n            elif mime_type == 'image/png':\n                return '.png'\n            elif mime_type == 'video/mp4':\n                return '.mp4'\n            else:\n                # Extract extension from file name\n                if message.file and message.file.name:\n                    return os.path.splitext(message.file.name)[1]\n                else:\n                    return ''\n        else:\n            return ''\n\n    def get_channel_messages(self):\n        with self.messages_lock:\n            return self.messages.copy()\n\n\n# Instantiate the ChannelViewer class\nviewer = ChannelViewer()\n\n\n@app.route('/')\ndef index():\n    print('Received request for /')\n    messages = viewer.get_channel_messages()\n    print(f\"Number of messages to display: {len(messages)}\")\n    return render_template('index.html', messages=messages)\n\n\nif __name__ == '__main__':\n    app.run(debug=True, use_reloader=False)                  # Append text to media\n                            print('Message ID {message.id} has text.')",
        "suffix": "                      print(f'Document for message ID {message.id} already exists: {media_filename}')\n\n                                media_item = {\n                                    'file_path': file_path,\n                                    'media_type': 'document',\n                                    'media_filename': media_filename\n                                }\n\n                            elif isinstance(message.media, MessageMediaWebPage):\n                                # Handle web page previews\n                                print(f'Message ID {message.id} contains a web page preview.')\n                                webpage = message.media.webpage\n\n                                if isinstance(webpage, WebPage):\n                                    # Full web page preview\n                                    message_data['webpage'] = {\n                                        'url': webpage.url,\n                                        'title': getattr(webpage, 'title', ''),\n                                        'description': getattr(webpage, 'description', '')\n                                    }\n                                    print(\n                                        f\"Extracted webpage info for message ID {message.id}: {message_data['webpage']}\")\n                                elif isinstance(webpage, WebPageEmpty):\n                                    # Empty web page preview\n                                    print(f'Message ID {message.id} contains an empty web page preview.')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n                                else:\n                                    # Other web page types\n                                    print(\n                                        f'Message ID {message.id} contains an unsupported web page type: {type(webpage)}')\n                                    message_data['webpage'] = {\n                                        'url': '',\n                                        'title': '',\n                                        'description': ''\n                                    }\n\n                                # Add to new_messages and skip further processing\n                                new_messages.append(message_data)\n                                continue  # Skip to next message\n\n                            else:\n                                # Unsupported media type\n                                print(f'Message ID {message.id} has unsupported media type: {type(message.media)}')\n                                continue  # Skip this message\n\n                            # Update message data\n                            if media_item:\n                                message_data['media'].append(media_item)\n                                message_data['media_type'] = media_item['media_type']\n\n                        # Group messages by grouped_id if they are part of a media group\n                        if message.grouped_id:\n                            print(f'Message ID {message.id} is part of group {message.grouped_id}')\n                            if message.grouped_id not in media_groups:\n                                # First message in the group; store the text (caption) if available\n                                media_groups[message.grouped_id] = message_data\n                            else:\n                                # Append media to existing group\n                                existing_message = media_groups[message.grouped_id]\n                                existing_message['media'].extend(message_data['media'])\n                                # If the existing message doesn't have text, and current message has text, update it\n                                if not existing_message['text'] and message_data['text']:\n                                    existing_message['text'] = message_data['text']\n                                    print(\n                                        f'Updated text for media group {message.grouped_id}: \"{message_data[\"text\"]}\"')\n                        else:\n                            # Not part of a media group, add as individual message\n                            new_messages.append(message_data)\n\n                        # Update last_message_id\n                        if message.id > self.last_message_id:\n                            self.last_message_id = message.id\n\n                        # Update offset_id for the next batch\n                        offset_id = message.id\n\n                    # Add grouped messages to new_messages\n                    new_messages.extend(media_groups.values())\n\n                    # Sort messages by date (optional)\n                    new_messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    # Update the shared messages list\n                    with self.messages_lock:\n                        self.messages.extend(new_messages)\n                        # Remove duplicates based on message ID\n                        self.messages = list({msg['id']: msg for msg in self.messages}.values())\n                        # Sort messages after merging\n                        self.messages.sort(key=lambda x: x['date'], reverse=True)\n\n                    print(f'Fetched and processed {len(new_messages)} new messages.')\n\n                    # Save messages to file\n                    self.save_messages()\n\n                    # Yield control to the event loop\n                    await asyncio.sleep(1)  # Adjust sleep time as needed\n\n            except Exception as e:\n                print(f'An error occurred in fetch_messages: {e}')\n                traceback.print_exc()\n\n        # Run the async function in the event loop\n        try:\n            loop.run_until_complete(main())\n        finally:\n            # Properly disconnect the client\n            self.client.disconnect()\n            loop.close()\n\n    def get_media_extension(self, message):\n        \"\"\"\n        Get the file extension for the media.\n        \"\"\"\n        if message.photo:\n            return '.jpg'\n        elif message.video:\n            return '.mp4'\n        elif message.document:\n            # Get the extension from the mime type or file name\n            mime_type = message.document.mime_type\n            if mime_type == 'image/jpeg':\n                return '.jpg'\n            elif mime_type == 'image/png':\n                return '.png'\n            elif mime_type == 'video/mp4':\n                return '.mp4'\n            else:\n                # Extract extension from file name\n                if message.file and message.file.name:\n                    return os.path.splitext(message.file.name)[1]\n                else:\n                    return ''\n        else:\n            return ''\n\n    def get_channel_messages(self):\n        with self.messages_lock:\n            return self.messages.copy()\n\n\n# Instantiate the ChannelViewer class\nviewer = ChannelViewer()\n\n\n@app.route('/')\ndef index():\n    print('Received request for /')\n    messages = viewer.get_channel_messages()\n    print(f\"Number of messages to display: {len(messages)}\")\n    return render_template('index.html', messages=messages)\n\n\nif __name__ == '__main__':\n    app.run(debug=True, use_reloader=False)",
        "label": "incorrect",
        "metrics": {
            "exact_match": 0,
            "chrf_score": 0.0,
            "bleu_score": 0.0,
            "rougeL_score": 0,
            "levenshtein_ratio": 0.06034193764666851
        }
    }
]